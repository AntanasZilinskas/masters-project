#!/bin/bash
#PBS -N everest_ablation_hpo
#PBS -l walltime=12:00:00
#PBS -l select=1:ncpus=8:mem=32gb:ngpus=1:gpu_type=RTX6000
#PBS -j oe
#PBS -J 1-35

# EVEREST Ablation Study - EXACT HPO Pattern
# Uses the exact same environment setup and execution pattern as working HPO

echo "üî¨ EVEREST Ablation Study - Job ${PBS_ARRAY_INDEX}/35"
echo "Node: $(hostname)"
echo "Date: $(date)"
echo "Working directory: $PBS_O_WORKDIR"

# Initialize conda (EXACT same as HPO)
source ~/miniforge3/etc/profile.d/conda.sh

# Change to submission directory (EXACT same as HPO)
cd $PBS_O_WORKDIR

# Verify we're in the right directory (EXACT same as HPO)
echo "Working directory: $(pwd)"
echo "Contents: $(ls -la | head -5)"

# Activate conda environment (EXACT same as HPO)
conda activate everest_env

# Set environment variables for GPU (EXACT same as HPO)
export CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES
export PYTHONPATH=$PBS_O_WORKDIR:$PYTHONPATH

echo "Array job ${PBS_ARRAY_INDEX}: Running ablation experiments"
echo "Using GPU: $CUDA_VISIBLE_DEVICES"
echo "Conda environment: $CONDA_DEFAULT_ENV"
echo "Python path: $PYTHONPATH"
echo "Python executable: $(which python)"
echo "Python version: $(python --version)"

# Validate GPU availability - CRITICAL for ablation (EXACT same as HPO)
echo "Validating GPU..."
python -c "
import torch
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f'‚úÖ GPU available: {gpu_name}')
else:
    print('‚ùå GPU not available - ablation cannot proceed')
    exit(1)
"

if [ $? -ne 0 ]; then
    echo "‚ùå GPU validation failed - terminating job"
    exit 1
fi

# Validate data availability (EXACT same as HPO)
echo "Validating data availability..."
python -c "
import sys
from pathlib import Path
project_root = Path.cwd()
sys.path.insert(0, str(project_root))
from models.utils import get_training_data, get_testing_data
X_train, y_train = get_training_data('72', 'M5')
X_test, y_test = get_testing_data('72', 'M5')
if X_train is None or y_train is None:
    print('‚ùå Training data not found')
    exit(1)
if X_test is None or y_test is None:
    print('‚ùå Testing data not found')
    exit(1)
print(f'‚úÖ Data validated: {len(X_train)} train, {len(X_test)} test samples')
"

if [ $? -ne 0 ]; then
    echo "‚ùå Data validation failed - terminating job"
    exit 1
fi

# Define experiment mapping (35 component ablations: 7 variants √ó 5 seeds)
declare -a variants=("full_model" "no_evidential" "no_evt" "mean_pool" "cross_entropy" "no_precursor" "fp32_training")
declare -a seeds=(0 1 2 3 4)

# Calculate variant and seed from array index
variant_idx=$(( (PBS_ARRAY_INDEX - 1) / 5 ))
seed_idx=$(( (PBS_ARRAY_INDEX - 1) % 5 ))

variant=${variants[$variant_idx]}
seed=${seeds[$seed_idx]}

echo "üéØ Experiment ${PBS_ARRAY_INDEX}/35: ${variant} (seed ${seed})"

# Run ablation using EXACT HPO pattern
echo "Starting ablation experiment..."
python models/ablation/run_ablation_exact_hpo.py \
    --variant $variant \
    --seed $seed

# Check exit status
if [ $? -eq 0 ]; then
    echo "‚úÖ Experiment ${PBS_ARRAY_INDEX} completed successfully"
    echo "   Variant: $variant"
    echo "   Seed: $seed"
    echo "   Completed at: $(date)"
else
    echo "‚ùå Experiment ${PBS_ARRAY_INDEX} failed"
    echo "   Variant: $variant"
    echo "   Seed: $seed"
    echo "   Failed at: $(date)"
    exit 1
fi

echo "üèÅ Job ${PBS_ARRAY_INDEX} finished at $(date)" 