#!/bin/bash
#PBS -N everest_ablation_seq_opt
#PBS -l walltime=48:00:00
#PBS -l select=1:ncpus=16:mem=64gb:ngpus=1
#PBS -q v1_gpu72
#PBS -j oe
#PBS -o logs/ablation_sequential_opt_${PBS_JOBID}.log

# EVEREST Ablation Study - Optimized Sequential Execution
# This script runs multiple experiments in parallel on a single GPU
# Uses GPU memory sharing and process parallelization

# Load environment
module load anaconda3/personal
source activate everest_env

# Set up paths
cd $PBS_O_WORKDIR
export PYTHONPATH="${PBS_O_WORKDIR}:${PYTHONPATH}"

# Create logs directory
mkdir -p logs
mkdir -p models/ablation/results

echo "=== EVEREST Ablation Study - Optimized Sequential ==="
echo "Job ID: $PBS_JOBID"
echo "Node: $(hostname)"
echo "Working Directory: $(pwd)"
echo "GPU Devices: $CUDA_VISIBLE_DEVICES"
echo "CPUs: 16"
echo "Memory: 64GB"
echo "Start Time: $(date)"
echo "Walltime: 48 hours"
echo ""

# Check GPU memory
nvidia-smi
echo ""

# Define experiment configurations with updated hyperparameters
VARIANTS=("full_model" "no_evidential" "no_evt" "mean_pool" "cross_entropy" "no_precursor" "fp32_training")
SEEDS=(0 1 2 3 4)  # All 5 seeds for full statistical power

# Configuration for parallel execution
MAX_PARALLEL=3  # Run 3 experiments in parallel on single GPU
BATCH_SIZE_REDUCED=512  # Reduce batch size to fit multiple models in GPU memory

# Track progress
TOTAL_EXPERIMENTS=$((${#VARIANTS[@]} * ${#SEEDS[@]}))
CURRENT_EXP=0

echo "üìä Optimized Experiment Plan:"
echo "   Variants: ${#VARIANTS[@]} (${VARIANTS[*]})"
echo "   Seeds: ${#SEEDS[@]} (${SEEDS[*]})"
echo "   Total experiments: $TOTAL_EXPERIMENTS"
echo "   Parallel processes: $MAX_PARALLEL"
echo "   Reduced batch size: $BATCH_SIZE_REDUCED (for memory sharing)"
echo "   Updated hyperparameters: embed_dim=64, num_blocks=8"
echo ""

# Create experiment queue
EXPERIMENTS=()
for variant in "${VARIANTS[@]}"; do
    for seed in "${SEEDS[@]}"; do
        EXPERIMENTS+=("$variant:$seed")
    done
done

# Function to run single experiment with reduced batch size
run_experiment() {
    local variant=$1
    local seed=$2
    local exp_num=$3
    local process_id=$4
    
    echo "üî¨ [P$process_id] [$exp_num/$TOTAL_EXPERIMENTS] Starting experiment:"
    echo "   Variant: $variant"
    echo "   Seed: $seed"
    echo "   Process: $process_id"
    echo "   Time: $(date)"
    
    # Set GPU memory fraction for this process
    export CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mps-$process_id
    export CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log-$process_id
    
    # Run the experiment with timeout, reduced batch size, and memory optimization
    timeout 7200 python -m ablation.trainer \
        --variant $variant \
        --seed $seed \
        --batch-size $BATCH_SIZE_REDUCED \
        --memory-efficient
    
    local exit_code=$?
    
    if [ $exit_code -eq 0 ]; then
        echo "   ‚úÖ [P$process_id] Completed successfully"
    elif [ $exit_code -eq 124 ]; then
        echo "   ‚è∞ [P$process_id] Timeout after 2 hours"
    else
        echo "   ‚ùå [P$process_id] Failed with exit code $exit_code"
    fi
    
    echo "   [P$process_id] Finished at $(date)"
    echo ""
    
    return $exit_code
}

# Parallel batch execution
start_time=$(date +%s)
failed_experiments=()
completed_experiments=()

echo "üöÄ Starting optimized parallel execution..."
echo ""

# Process experiments in batches of MAX_PARALLEL
for ((batch_start=0; batch_start<TOTAL_EXPERIMENTS; batch_start+=MAX_PARALLEL)); do
    batch_end=$((batch_start + MAX_PARALLEL - 1))
    if [ $batch_end -ge $TOTAL_EXPERIMENTS ]; then
        batch_end=$((TOTAL_EXPERIMENTS - 1))
    fi
    
    batch_size=$((batch_end - batch_start + 1))
    echo "üì¶ Batch $((batch_start/MAX_PARALLEL + 1)): Running experiments $((batch_start + 1))-$((batch_end + 1)) in parallel"
    
    # Start parallel processes for this batch
    pids=()
    for ((i=batch_start; i<=batch_end; i++)); do
        IFS=':' read -r variant seed <<< "${EXPERIMENTS[$i]}"
        process_id=$((i % MAX_PARALLEL))
        
        run_experiment $variant $seed $((i + 1)) $process_id &
        pids+=($!)
    done
    
    # Wait for all processes in this batch to complete
    for pid in "${pids[@]}"; do
        wait $pid
        if [ $? -eq 0 ]; then
            ((CURRENT_EXP++))
        else
            failed_experiments+=("${EXPERIMENTS[$((batch_start + ${#pids[@]} - 1))]}")
        fi
    done
    
    # Brief pause between batches to let GPU memory clear
    echo "‚è∏Ô∏è  Batch completed. Cooling down for 60 seconds..."
    sleep 60
    
    # Check remaining walltime
    elapsed=$(($(date +%s) - start_time))
    remaining=$((172800 - elapsed))  # 48 hours = 172800 seconds
    
    if [ $remaining -lt 14400 ]; then  # Less than 4 hours
        echo "‚ö†Ô∏è  Less than 4 hours remaining, stopping early"
        echo "   Completed: $CURRENT_EXP/$TOTAL_EXPERIMENTS experiments"
        break
    fi
    
    echo "‚è±Ô∏è  Progress: $CURRENT_EXP/$TOTAL_EXPERIMENTS | Remaining walltime: $((remaining/3600))h"
    echo ""
done

# Summary
total_time=$(($(date +%s) - start_time))
echo ""
echo "üéâ Optimized sequential execution completed!"
echo "   Total experiments attempted: $CURRENT_EXP"
echo "   Total time: $((total_time/3600))h $((total_time%3600/60))m"
echo "   Average time per experiment: $((total_time/CURRENT_EXP/60)) minutes"
echo "   Parallel efficiency: $MAX_PARALLEL processes per GPU"

if [ ${#failed_experiments[@]} -gt 0 ]; then
    echo "   ‚ùå Failed experiments: ${failed_experiments[*]}"
else
    echo "   ‚úÖ All experiments completed successfully"
fi

echo ""
echo "üìä GPU Memory Optimization:"
echo "   Reduced batch size: $BATCH_SIZE_REDUCED"
echo "   Parallel processes: $MAX_PARALLEL"
echo "   Memory sharing: Enabled"

echo ""
echo "üìã Next steps:"
echo "   1. Check results: ls models/ablation/results/"
echo "   2. Run analysis: python run_updated_ablation.py --analysis-only"
echo "   3. Compare with single-process approach"
echo ""
echo "End Time: $(date)" 