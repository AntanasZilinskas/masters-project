{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85acd3d4-3270-46c9-a5ac-0cb075790d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:33:35.837900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-15 16:33:35.837986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-15 16:33:35.940990: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-15 16:33:36.133468: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-15 16:33:49.431039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-15 16:34:03.525939: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: TensorFlow GPU device not found.\n",
      "TensorFlow backend version: 2.15.0\n",
      "SUCCESS: PyTorch found GPU: Quadro RTX 6000\n",
      "PyTorch CUDA version: 12.6\n",
      "PyTorch version: 2.7.0+cu126\n",
      "Python version: 3.11.12\n",
      "\n",
      "🚀 Training model for flare class C with 48h window\n",
      "Epoch 1/300 - loss: 0.0011 - acc: 0.6851 - tss: 0.3730 - gamma: 0.00\n",
      "Epoch 2/300 - loss: 0.0010 - acc: 0.7002 - tss: 0.4037 - gamma: 0.04\n",
      "Epoch 3/300 - loss: 0.0010 - acc: 0.7173 - tss: 0.4395 - gamma: 0.08\n",
      "Epoch 4/300 - loss: 0.0009 - acc: 0.7360 - tss: 0.4774 - gamma: 0.12\n",
      "Epoch 5/300 - loss: 0.0008 - acc: 0.7542 - tss: 0.5139 - gamma: 0.16\n",
      "Epoch 6/300 - loss: 0.0008 - acc: 0.7709 - tss: 0.5473 - gamma: 0.20\n",
      "Epoch 7/300 - loss: 0.0007 - acc: 0.7869 - tss: 0.5789 - gamma: 0.24\n",
      "Epoch 8/300 - loss: 0.0006 - acc: 0.8016 - tss: 0.6080 - gamma: 0.28\n",
      "Epoch 9/300 - loss: 0.0006 - acc: 0.8153 - tss: 0.6349 - gamma: 0.32\n",
      "Epoch 10/300 - loss: 0.0005 - acc: 0.8278 - tss: 0.6593 - gamma: 0.36\n",
      "Epoch 11/300 - loss: 0.0005 - acc: 0.8381 - tss: 0.6795 - gamma: 0.40\n",
      "Epoch 12/300 - loss: 0.0005 - acc: 0.8479 - tss: 0.6990 - gamma: 0.44\n",
      "Epoch 13/300 - loss: 0.0004 - acc: 0.8557 - tss: 0.7143 - gamma: 0.48\n",
      "Epoch 14/300 - loss: 0.0004 - acc: 0.8629 - tss: 0.7285 - gamma: 0.52\n",
      "Epoch 15/300 - loss: 0.0004 - acc: 0.8689 - tss: 0.7404 - gamma: 0.56\n",
      "Epoch 16/300 - loss: 0.0004 - acc: 0.8745 - tss: 0.7514 - gamma: 0.60\n",
      "Epoch 17/300 - loss: 0.0003 - acc: 0.8801 - tss: 0.7626 - gamma: 0.64\n",
      "Epoch 18/300 - loss: 0.0003 - acc: 0.8844 - tss: 0.7710 - gamma: 0.68\n",
      "Epoch 19/300 - loss: 0.0003 - acc: 0.8888 - tss: 0.7797 - gamma: 0.72\n",
      "Epoch 20/300 - loss: 0.0003 - acc: 0.8925 - tss: 0.7868 - gamma: 0.76\n",
      "Epoch 21/300 - loss: 0.0002 - acc: 0.8972 - tss: 0.7964 - gamma: 0.80\n",
      "Epoch 22/300 - loss: 0.0002 - acc: 0.8999 - tss: 0.8015 - gamma: 0.84\n",
      "Epoch 23/300 - loss: 0.0002 - acc: 0.9029 - tss: 0.8076 - gamma: 0.88\n",
      "Epoch 24/300 - loss: 0.0002 - acc: 0.9044 - tss: 0.8105 - gamma: 0.92\n",
      "Epoch 25/300 - loss: 0.0002 - acc: 0.9078 - tss: 0.8171 - gamma: 0.96\n",
      "Epoch 26/300 - loss: 0.0002 - acc: 0.9096 - tss: 0.8208 - gamma: 1.00\n",
      "Epoch 27/300 - loss: 0.0002 - acc: 0.9126 - tss: 0.8267 - gamma: 1.04\n",
      "Epoch 28/300 - loss: 0.0002 - acc: 0.9143 - tss: 0.8299 - gamma: 1.08\n",
      "Epoch 29/300 - loss: 0.0002 - acc: 0.9159 - tss: 0.8331 - gamma: 1.12\n",
      "Epoch 30/300 - loss: 0.0002 - acc: 0.9182 - tss: 0.8377 - gamma: 1.16\n",
      "Epoch 31/300 - loss: 0.0001 - acc: 0.9196 - tss: 0.8405 - gamma: 1.20\n",
      "Epoch 32/300 - loss: 0.0001 - acc: 0.9217 - tss: 0.8446 - gamma: 1.24\n",
      "Epoch 33/300 - loss: 0.0001 - acc: 0.9231 - tss: 0.8473 - gamma: 1.28\n",
      "Epoch 34/300 - loss: 0.0001 - acc: 0.9243 - tss: 0.8497 - gamma: 1.32\n",
      "Epoch 35/300 - loss: 0.0001 - acc: 0.9257 - tss: 0.8524 - gamma: 1.36\n",
      "Epoch 36/300 - loss: 0.0001 - acc: 0.9278 - tss: 0.8566 - gamma: 1.40\n",
      "Epoch 37/300 - loss: 0.0001 - acc: 0.9286 - tss: 0.8580 - gamma: 1.44\n",
      "Epoch 38/300 - loss: 0.0001 - acc: 0.9297 - tss: 0.8601 - gamma: 1.48\n",
      "Epoch 39/300 - loss: 0.0001 - acc: 0.9307 - tss: 0.8623 - gamma: 1.52\n",
      "Epoch 40/300 - loss: 0.0001 - acc: 0.9322 - tss: 0.8652 - gamma: 1.56\n",
      "Epoch 41/300 - loss: 0.0001 - acc: 0.9351 - tss: 0.8710 - gamma: 1.60\n",
      "Epoch 42/300 - loss: 0.0001 - acc: 0.9356 - tss: 0.8719 - gamma: 1.64\n",
      "Epoch 43/300 - loss: 0.0001 - acc: 0.9359 - tss: 0.8725 - gamma: 1.68\n",
      "Epoch 44/300 - loss: 0.0001 - acc: 0.9367 - tss: 0.8741 - gamma: 1.72\n",
      "Epoch 45/300 - loss: 0.0001 - acc: 0.9372 - tss: 0.8750 - gamma: 1.76\n",
      "Epoch 46/300 - loss: 0.0001 - acc: 0.9387 - tss: 0.8780 - gamma: 1.80\n",
      "Epoch 47/300 - loss: 0.0001 - acc: 0.9399 - tss: 0.8803 - gamma: 1.84\n",
      "Epoch 48/300 - loss: 0.0001 - acc: 0.9407 - tss: 0.8818 - gamma: 1.88\n",
      "Epoch 49/300 - loss: 0.0001 - acc: 0.9412 - tss: 0.8829 - gamma: 1.92\n",
      "Epoch 50/300 - loss: 0.0001 - acc: 0.9420 - tss: 0.8845 - gamma: 1.96\n",
      "Epoch 51/300 - loss: 0.0001 - acc: 0.9427 - tss: 0.8859 - gamma: 2.00\n",
      "Epoch 52/300 - loss: 0.0001 - acc: 0.9429 - tss: 0.8863 - gamma: 2.00\n",
      "Epoch 53/300 - loss: 0.0001 - acc: 0.9439 - tss: 0.8882 - gamma: 2.00\n",
      "Epoch 54/300 - loss: 0.0001 - acc: 0.9443 - tss: 0.8891 - gamma: 2.00\n",
      "Epoch 55/300 - loss: 0.0001 - acc: 0.9450 - tss: 0.8904 - gamma: 2.00\n",
      "Epoch 56/300 - loss: 0.0001 - acc: 0.9459 - tss: 0.8922 - gamma: 2.00\n",
      "Epoch 57/300 - loss: 0.0001 - acc: 0.9466 - tss: 0.8935 - gamma: 2.00\n",
      "Epoch 58/300 - loss: 0.0001 - acc: 0.9467 - tss: 0.8938 - gamma: 2.00\n",
      "Epoch 59/300 - loss: 0.0001 - acc: 0.9475 - tss: 0.8954 - gamma: 2.00\n",
      "Epoch 60/300 - loss: 0.0001 - acc: 0.9481 - tss: 0.8964 - gamma: 2.00\n",
      "Epoch 61/300 - loss: 0.0001 - acc: 0.9479 - tss: 0.8962 - gamma: 2.00\n",
      "Epoch 62/300 - loss: 0.0001 - acc: 0.9492 - tss: 0.8988 - gamma: 2.00\n",
      "Epoch 63/300 - loss: 0.0001 - acc: 0.9494 - tss: 0.8992 - gamma: 2.00\n",
      "Epoch 64/300 - loss: 0.0001 - acc: 0.9500 - tss: 0.9003 - gamma: 2.00\n",
      "Epoch 65/300 - loss: 0.0001 - acc: 0.9506 - tss: 0.9014 - gamma: 2.00\n",
      "Epoch 66/300 - loss: 0.0001 - acc: 0.9508 - tss: 0.9020 - gamma: 2.00\n",
      "Epoch 67/300 - loss: 0.0001 - acc: 0.9517 - tss: 0.9037 - gamma: 2.00\n",
      "Epoch 68/300 - loss: 0.0001 - acc: 0.9523 - tss: 0.9049 - gamma: 2.00\n",
      "Epoch 69/300 - loss: 0.0001 - acc: 0.9521 - tss: 0.9044 - gamma: 2.00\n",
      "Epoch 70/300 - loss: 0.0001 - acc: 0.9530 - tss: 0.9062 - gamma: 2.00\n",
      "Epoch 71/300 - loss: 0.0001 - acc: 0.9531 - tss: 0.9064 - gamma: 2.00\n",
      "Epoch 72/300 - loss: 0.0001 - acc: 0.9536 - tss: 0.9073 - gamma: 2.00\n",
      "Epoch 73/300 - loss: 0.0001 - acc: 0.9546 - tss: 0.9094 - gamma: 2.00\n",
      "Epoch 74/300 - loss: 0.0001 - acc: 0.9551 - tss: 0.9103 - gamma: 2.00\n",
      "Epoch 75/300 - loss: 0.0001 - acc: 0.9549 - tss: 0.9100 - gamma: 2.00\n",
      "Epoch 76/300 - loss: 0.0001 - acc: 0.9551 - tss: 0.9104 - gamma: 2.00\n",
      "Epoch 77/300 - loss: 0.0001 - acc: 0.9557 - tss: 0.9116 - gamma: 2.00\n",
      "Epoch 78/300 - loss: 0.0000 - acc: 0.9561 - tss: 0.9123 - gamma: 2.00\n",
      "Epoch 79/300 - loss: 0.0000 - acc: 0.9559 - tss: 0.9120 - gamma: 2.00\n",
      "Epoch 80/300 - loss: 0.0000 - acc: 0.9569 - tss: 0.9140 - gamma: 2.00\n",
      "Epoch 81/300 - loss: 0.0000 - acc: 0.9569 - tss: 0.9138 - gamma: 2.00\n",
      "Epoch 82/300 - loss: 0.0000 - acc: 0.9575 - tss: 0.9152 - gamma: 2.00\n",
      "Epoch 83/300 - loss: 0.0000 - acc: 0.9580 - tss: 0.9162 - gamma: 2.00\n",
      "Epoch 84/300 - loss: 0.0000 - acc: 0.9580 - tss: 0.9162 - gamma: 2.00\n",
      "Epoch 85/300 - loss: 0.0000 - acc: 0.9585 - tss: 0.9171 - gamma: 2.00\n",
      "Epoch 86/300 - loss: 0.0000 - acc: 0.9583 - tss: 0.9167 - gamma: 2.00\n",
      "Epoch 87/300 - loss: 0.0000 - acc: 0.9591 - tss: 0.9184 - gamma: 2.00\n",
      "Epoch 88/300 - loss: 0.0000 - acc: 0.9593 - tss: 0.9187 - gamma: 2.00\n",
      "Epoch 89/300 - loss: 0.0000 - acc: 0.9596 - tss: 0.9193 - gamma: 2.00\n",
      "Epoch 90/300 - loss: 0.0000 - acc: 0.9592 - tss: 0.9185 - gamma: 2.00\n",
      "Epoch 91/300 - loss: 0.0000 - acc: 0.9599 - tss: 0.9198 - gamma: 2.00\n",
      "Epoch 92/300 - loss: 0.0000 - acc: 0.9600 - tss: 0.9200 - gamma: 2.00\n",
      "Epoch 93/300 - loss: 0.0000 - acc: 0.9604 - tss: 0.9209 - gamma: 2.00\n",
      "Epoch 94/300 - loss: 0.0000 - acc: 0.9611 - tss: 0.9223 - gamma: 2.00\n",
      "Epoch 95/300 - loss: 0.0000 - acc: 0.9610 - tss: 0.9221 - gamma: 2.00\n",
      "Epoch 96/300 - loss: 0.0000 - acc: 0.9608 - tss: 0.9216 - gamma: 2.00\n",
      "Epoch 97/300 - loss: 0.0000 - acc: 0.9612 - tss: 0.9225 - gamma: 2.00\n",
      "Epoch 98/300 - loss: 0.0000 - acc: 0.9617 - tss: 0.9236 - gamma: 2.00\n",
      "Epoch 99/300 - loss: 0.0000 - acc: 0.9617 - tss: 0.9234 - gamma: 2.00\n",
      "Epoch 100/300 - loss: 0.0000 - acc: 0.9623 - tss: 0.9246 - gamma: 2.00\n",
      "Epoch 101/300 - loss: 0.0000 - acc: 0.9626 - tss: 0.9253 - gamma: 2.00\n",
      "Epoch 102/300 - loss: 0.0000 - acc: 0.9627 - tss: 0.9253 - gamma: 2.00\n",
      "Epoch 103/300 - loss: 0.0000 - acc: 0.9628 - tss: 0.9257 - gamma: 2.00\n",
      "Epoch 104/300 - loss: 0.0000 - acc: 0.9628 - tss: 0.9256 - gamma: 2.00\n",
      "Epoch 105/300 - loss: 0.0000 - acc: 0.9631 - tss: 0.9263 - gamma: 2.00\n",
      "Epoch 106/300 - loss: 0.0000 - acc: 0.9633 - tss: 0.9266 - gamma: 2.00\n",
      "Epoch 107/300 - loss: 0.0000 - acc: 0.9639 - tss: 0.9278 - gamma: 2.00\n",
      "Epoch 108/300 - loss: 0.0000 - acc: 0.9638 - tss: 0.9276 - gamma: 2.00\n",
      "Epoch 109/300 - loss: 0.0000 - acc: 0.9637 - tss: 0.9275 - gamma: 2.00\n",
      "Epoch 110/300 - loss: 0.0000 - acc: 0.9641 - tss: 0.9282 - gamma: 2.00\n",
      "Epoch 111/300 - loss: 0.0000 - acc: 0.9644 - tss: 0.9288 - gamma: 2.00\n",
      "Epoch 112/300 - loss: 0.0000 - acc: 0.9647 - tss: 0.9295 - gamma: 2.00\n",
      "Epoch 113/300 - loss: 0.0000 - acc: 0.9649 - tss: 0.9299 - gamma: 2.00\n",
      "Epoch 114/300 - loss: 0.0000 - acc: 0.9654 - tss: 0.9308 - gamma: 2.00\n",
      "Epoch 115/300 - loss: 0.0000 - acc: 0.9653 - tss: 0.9306 - gamma: 2.00\n",
      "Epoch 116/300 - loss: 0.0000 - acc: 0.9650 - tss: 0.9301 - gamma: 2.00\n",
      "Epoch 117/300 - loss: 0.0000 - acc: 0.9654 - tss: 0.9309 - gamma: 2.00\n",
      "Epoch 118/300 - loss: 0.0000 - acc: 0.9655 - tss: 0.9309 - gamma: 2.00\n",
      "Epoch 119/300 - loss: 0.0000 - acc: 0.9657 - tss: 0.9314 - gamma: 2.00\n",
      "Epoch 120/300 - loss: 0.0000 - acc: 0.9661 - tss: 0.9321 - gamma: 2.00\n",
      "Epoch 121/300 - loss: 0.0000 - acc: 0.9661 - tss: 0.9323 - gamma: 2.00\n",
      "Epoch 122/300 - loss: 0.0000 - acc: 0.9661 - tss: 0.9322 - gamma: 2.00\n",
      "Epoch 123/300 - loss: 0.0000 - acc: 0.9663 - tss: 0.9326 - gamma: 2.00\n",
      "Epoch 124/300 - loss: 0.0000 - acc: 0.9666 - tss: 0.9334 - gamma: 2.00\n",
      "Epoch 125/300 - loss: 0.0000 - acc: 0.9671 - tss: 0.9341 - gamma: 2.00\n",
      "Epoch 126/300 - loss: 0.0000 - acc: 0.9667 - tss: 0.9334 - gamma: 2.00\n",
      "Epoch 127/300 - loss: 0.0000 - acc: 0.9670 - tss: 0.9340 - gamma: 2.00\n",
      "Epoch 128/300 - loss: 0.0000 - acc: 0.9673 - tss: 0.9345 - gamma: 2.00\n",
      "Epoch 129/300 - loss: 0.0000 - acc: 0.9673 - tss: 0.9345 - gamma: 2.00\n",
      "Epoch 130/300 - loss: 0.0000 - acc: 0.9674 - tss: 0.9348 - gamma: 2.00\n",
      "Epoch 131/300 - loss: 0.0000 - acc: 0.9677 - tss: 0.9355 - gamma: 2.00\n",
      "Epoch 132/300 - loss: 0.0000 - acc: 0.9673 - tss: 0.9346 - gamma: 2.00\n",
      "Epoch 133/300 - loss: 0.0000 - acc: 0.9677 - tss: 0.9355 - gamma: 2.00\n",
      "Epoch 134/300 - loss: 0.0000 - acc: 0.9678 - tss: 0.9357 - gamma: 2.00\n",
      "Epoch 135/300 - loss: 0.0000 - acc: 0.9679 - tss: 0.9357 - gamma: 2.00\n",
      "Epoch 136/300 - loss: 0.0000 - acc: 0.9684 - tss: 0.9369 - gamma: 2.00\n",
      "Epoch 137/300 - loss: 0.0000 - acc: 0.9683 - tss: 0.9367 - gamma: 2.00\n",
      "Epoch 138/300 - loss: 0.0000 - acc: 0.9681 - tss: 0.9361 - gamma: 2.00\n",
      "Epoch 139/300 - loss: 0.0000 - acc: 0.9685 - tss: 0.9370 - gamma: 2.00\n",
      "Epoch 140/300 - loss: 0.0000 - acc: 0.9687 - tss: 0.9374 - gamma: 2.00\n",
      "Epoch 141/300 - loss: 0.0000 - acc: 0.9689 - tss: 0.9377 - gamma: 2.00\n",
      "Epoch 142/300 - loss: 0.0000 - acc: 0.9685 - tss: 0.9369 - gamma: 2.00\n",
      "Epoch 143/300 - loss: 0.0000 - acc: 0.9693 - tss: 0.9386 - gamma: 2.00\n",
      "Epoch 144/300 - loss: 0.0000 - acc: 0.9693 - tss: 0.9387 - gamma: 2.00\n",
      "Epoch 145/300 - loss: 0.0000 - acc: 0.9692 - tss: 0.9385 - gamma: 2.00\n",
      "Epoch 146/300 - loss: 0.0000 - acc: 0.9693 - tss: 0.9386 - gamma: 2.00\n",
      "Epoch 147/300 - loss: 0.0000 - acc: 0.9694 - tss: 0.9388 - gamma: 2.00\n",
      "Epoch 148/300 - loss: 0.0000 - acc: 0.9691 - tss: 0.9382 - gamma: 2.00\n",
      "Epoch 149/300 - loss: 0.0000 - acc: 0.9697 - tss: 0.9393 - gamma: 2.00\n",
      "Epoch 150/300 - loss: 0.0000 - acc: 0.9696 - tss: 0.9391 - gamma: 2.00\n",
      "Epoch 151/300 - loss: 0.0000 - acc: 0.9699 - tss: 0.9397 - gamma: 2.00\n",
      "Epoch 152/300 - loss: 0.0000 - acc: 0.9698 - tss: 0.9397 - gamma: 2.00\n",
      "Epoch 153/300 - loss: 0.0000 - acc: 0.9701 - tss: 0.9402 - gamma: 2.00\n",
      "Epoch 154/300 - loss: 0.0000 - acc: 0.9700 - tss: 0.9400 - gamma: 2.00\n",
      "Epoch 155/300 - loss: 0.0000 - acc: 0.9699 - tss: 0.9397 - gamma: 2.00\n",
      "Epoch 156/300 - loss: 0.0000 - acc: 0.9705 - tss: 0.9411 - gamma: 2.00\n",
      "Epoch 157/300 - loss: 0.0000 - acc: 0.9702 - tss: 0.9404 - gamma: 2.00\n",
      "Epoch 158/300 - loss: 0.0000 - acc: 0.9706 - tss: 0.9412 - gamma: 2.00\n",
      "Epoch 159/300 - loss: 0.0000 - acc: 0.9703 - tss: 0.9405 - gamma: 2.00\n",
      "Epoch 160/300 - loss: 0.0000 - acc: 0.9704 - tss: 0.9408 - gamma: 2.00\n",
      "Epoch 161/300 - loss: 0.0000 - acc: 0.9711 - tss: 0.9422 - gamma: 2.00\n",
      "Epoch 162/300 - loss: 0.0000 - acc: 0.9705 - tss: 0.9410 - gamma: 2.00\n",
      "Epoch 163/300 - loss: 0.0000 - acc: 0.9711 - tss: 0.9422 - gamma: 2.00\n",
      "Epoch 164/300 - loss: 0.0000 - acc: 0.9710 - tss: 0.9420 - gamma: 2.00\n",
      "Epoch 165/300 - loss: 0.0000 - acc: 0.9712 - tss: 0.9423 - gamma: 2.00\n",
      "Epoch 166/300 - loss: 0.0000 - acc: 0.9714 - tss: 0.9428 - gamma: 2.00\n",
      "Epoch 167/300 - loss: 0.0000 - acc: 0.9710 - tss: 0.9419 - gamma: 2.00\n",
      "Epoch 168/300 - loss: 0.0000 - acc: 0.9713 - tss: 0.9425 - gamma: 2.00\n",
      "Epoch 169/300 - loss: 0.0000 - acc: 0.9715 - tss: 0.9429 - gamma: 2.00\n",
      "Epoch 170/300 - loss: 0.0000 - acc: 0.9715 - tss: 0.9429 - gamma: 2.00\n",
      "Epoch 171/300 - loss: 0.0000 - acc: 0.9715 - tss: 0.9430 - gamma: 2.00\n",
      "Epoch 172/300 - loss: 0.0000 - acc: 0.9718 - tss: 0.9435 - gamma: 2.00\n",
      "Epoch 173/300 - loss: 0.0000 - acc: 0.9716 - tss: 0.9432 - gamma: 2.00\n",
      "Epoch 174/300 - loss: 0.0000 - acc: 0.9721 - tss: 0.9441 - gamma: 2.00\n",
      "Epoch 175/300 - loss: 0.0000 - acc: 0.9719 - tss: 0.9439 - gamma: 2.00\n",
      "Epoch 176/300 - loss: 0.0000 - acc: 0.9720 - tss: 0.9440 - gamma: 2.00\n",
      "Epoch 177/300 - loss: 0.0000 - acc: 0.9723 - tss: 0.9446 - gamma: 2.00\n",
      "Epoch 178/300 - loss: 0.0000 - acc: 0.9724 - tss: 0.9448 - gamma: 2.00\n",
      "Epoch 179/300 - loss: 0.0000 - acc: 0.9726 - tss: 0.9452 - gamma: 2.00\n",
      "Epoch 180/300 - loss: 0.0000 - acc: 0.9725 - tss: 0.9449 - gamma: 2.00\n",
      "Epoch 181/300 - loss: 0.0000 - acc: 0.9722 - tss: 0.9443 - gamma: 2.00\n",
      "Epoch 182/300 - loss: 0.0000 - acc: 0.9727 - tss: 0.9453 - gamma: 2.00\n",
      "Epoch 183/300 - loss: 0.0000 - acc: 0.9724 - tss: 0.9448 - gamma: 2.00\n",
      "Epoch 184/300 - loss: 0.0000 - acc: 0.9726 - tss: 0.9452 - gamma: 2.00\n",
      "Epoch 185/300 - loss: 0.0000 - acc: 0.9727 - tss: 0.9453 - gamma: 2.00\n",
      "Epoch 186/300 - loss: 0.0000 - acc: 0.9728 - tss: 0.9456 - gamma: 2.00\n",
      "Epoch 187/300 - loss: 0.0000 - acc: 0.9727 - tss: 0.9453 - gamma: 2.00\n",
      "Epoch 188/300 - loss: 0.0000 - acc: 0.9732 - tss: 0.9463 - gamma: 2.00\n",
      "Epoch 189/300 - loss: 0.0000 - acc: 0.9731 - tss: 0.9461 - gamma: 2.00\n",
      "Epoch 190/300 - loss: 0.0000 - acc: 0.9732 - tss: 0.9464 - gamma: 2.00\n",
      "Epoch 191/300 - loss: 0.0000 - acc: 0.9728 - tss: 0.9455 - gamma: 2.00\n",
      "Epoch 192/300 - loss: 0.0000 - acc: 0.9734 - tss: 0.9467 - gamma: 2.00\n",
      "Epoch 193/300 - loss: 0.0000 - acc: 0.9734 - tss: 0.9467 - gamma: 2.00\n",
      "Epoch 194/300 - loss: 0.0000 - acc: 0.9734 - tss: 0.9468 - gamma: 2.00\n",
      "Epoch 195/300 - loss: 0.0000 - acc: 0.9735 - tss: 0.9469 - gamma: 2.00\n",
      "Epoch 196/300 - loss: 0.0000 - acc: 0.9731 - tss: 0.9462 - gamma: 2.00\n",
      "Epoch 197/300 - loss: 0.0000 - acc: 0.9733 - tss: 0.9466 - gamma: 2.00\n",
      "Epoch 198/300 - loss: 0.0000 - acc: 0.9732 - tss: 0.9463 - gamma: 2.00\n",
      "Epoch 199/300 - loss: 0.0000 - acc: 0.9737 - tss: 0.9473 - gamma: 2.00\n",
      "Epoch 200/300 - loss: 0.0000 - acc: 0.9738 - tss: 0.9475 - gamma: 2.00\n",
      "Epoch 201/300 - loss: 0.0000 - acc: 0.9740 - tss: 0.9479 - gamma: 2.00\n",
      "Epoch 202/300 - loss: 0.0000 - acc: 0.9738 - tss: 0.9475 - gamma: 2.00\n",
      "Epoch 203/300 - loss: 0.0000 - acc: 0.9736 - tss: 0.9471 - gamma: 2.00\n",
      "Epoch 204/300 - loss: 0.0000 - acc: 0.9743 - tss: 0.9486 - gamma: 2.00\n",
      "Epoch 205/300 - loss: 0.0000 - acc: 0.9741 - tss: 0.9482 - gamma: 2.00\n",
      "Epoch 206/300 - loss: 0.0000 - acc: 0.9737 - tss: 0.9474 - gamma: 2.00\n",
      "Epoch 207/300 - loss: 0.0000 - acc: 0.9740 - tss: 0.9480 - gamma: 2.00\n",
      "Epoch 208/300 - loss: 0.0000 - acc: 0.9743 - tss: 0.9486 - gamma: 2.00\n",
      "Epoch 209/300 - loss: 0.0000 - acc: 0.9746 - tss: 0.9490 - gamma: 2.00\n",
      "Epoch 210/300 - loss: 0.0000 - acc: 0.9740 - tss: 0.9478 - gamma: 2.00\n",
      "Epoch 211/300 - loss: 0.0000 - acc: 0.9743 - tss: 0.9486 - gamma: 2.00\n",
      "Epoch 212/300 - loss: 0.0000 - acc: 0.9746 - tss: 0.9491 - gamma: 2.00\n",
      "Epoch 213/300 - loss: 0.0000 - acc: 0.9745 - tss: 0.9490 - gamma: 2.00\n",
      "Epoch 214/300 - loss: 0.0000 - acc: 0.9744 - tss: 0.9488 - gamma: 2.00\n",
      "Epoch 215/300 - loss: 0.0000 - acc: 0.9745 - tss: 0.9490 - gamma: 2.00\n",
      "Epoch 216/300 - loss: 0.0000 - acc: 0.9748 - tss: 0.9495 - gamma: 2.00\n",
      "Epoch 217/300 - loss: 0.0000 - acc: 0.9749 - tss: 0.9497 - gamma: 2.00\n",
      "Epoch 218/300 - loss: 0.0000 - acc: 0.9750 - tss: 0.9499 - gamma: 2.00\n",
      "Epoch 219/300 - loss: 0.0000 - acc: 0.9751 - tss: 0.9501 - gamma: 2.00\n",
      "Epoch 220/300 - loss: 0.0000 - acc: 0.9747 - tss: 0.9494 - gamma: 2.00\n",
      "Epoch 221/300 - loss: 0.0000 - acc: 0.9747 - tss: 0.9493 - gamma: 2.00\n",
      "Epoch 222/300 - loss: 0.0000 - acc: 0.9750 - tss: 0.9500 - gamma: 2.00\n",
      "Epoch 223/300 - loss: 0.0000 - acc: 0.9751 - tss: 0.9502 - gamma: 2.00\n",
      "Epoch 224/300 - loss: 0.0000 - acc: 0.9751 - tss: 0.9501 - gamma: 2.00\n",
      "Epoch 225/300 - loss: 0.0000 - acc: 0.9748 - tss: 0.9495 - gamma: 2.00\n",
      "Epoch 226/300 - loss: 0.0000 - acc: 0.9755 - tss: 0.9510 - gamma: 2.00\n",
      "Epoch 227/300 - loss: 0.0000 - acc: 0.9747 - tss: 0.9494 - gamma: 2.00\n",
      "Epoch 228/300 - loss: 0.0000 - acc: 0.9750 - tss: 0.9500 - gamma: 2.00\n",
      "Epoch 229/300 - loss: 0.0000 - acc: 0.9752 - tss: 0.9503 - gamma: 2.00\n",
      "Epoch 230/300 - loss: 0.0000 - acc: 0.9754 - tss: 0.9507 - gamma: 2.00\n",
      "Epoch 231/300 - loss: 0.0000 - acc: 0.9753 - tss: 0.9505 - gamma: 2.00\n",
      "Epoch 232/300 - loss: 0.0000 - acc: 0.9752 - tss: 0.9504 - gamma: 2.00\n",
      "Epoch 233/300 - loss: 0.0000 - acc: 0.9756 - tss: 0.9512 - gamma: 2.00\n",
      "Epoch 234/300 - loss: 0.0000 - acc: 0.9752 - tss: 0.9504 - gamma: 2.00\n",
      "Epoch 235/300 - loss: 0.0000 - acc: 0.9756 - tss: 0.9512 - gamma: 2.00\n",
      "Epoch 236/300 - loss: 0.0000 - acc: 0.9756 - tss: 0.9511 - gamma: 2.00\n",
      "Epoch 237/300 - loss: 0.0000 - acc: 0.9759 - tss: 0.9517 - gamma: 2.00\n",
      "Epoch 238/300 - loss: 0.0000 - acc: 0.9755 - tss: 0.9509 - gamma: 2.00\n",
      "Epoch 239/300 - loss: 0.0000 - acc: 0.9757 - tss: 0.9514 - gamma: 2.00\n",
      "Epoch 240/300 - loss: 0.0000 - acc: 0.9758 - tss: 0.9516 - gamma: 2.00\n",
      "Epoch 241/300 - loss: 0.0000 - acc: 0.9758 - tss: 0.9516 - gamma: 2.00\n",
      "Epoch 242/300 - loss: 0.0000 - acc: 0.9762 - tss: 0.9524 - gamma: 2.00\n",
      "Epoch 243/300 - loss: 0.0000 - acc: 0.9757 - tss: 0.9515 - gamma: 2.00\n",
      "Epoch 244/300 - loss: 0.0000 - acc: 0.9762 - tss: 0.9523 - gamma: 2.00\n",
      "Epoch 245/300 - loss: 0.0000 - acc: 0.9763 - tss: 0.9525 - gamma: 2.00\n",
      "Epoch 246/300 - loss: 0.0000 - acc: 0.9760 - tss: 0.9520 - gamma: 2.00\n",
      "Epoch 247/300 - loss: 0.0000 - acc: 0.9761 - tss: 0.9521 - gamma: 2.00\n",
      "Epoch 248/300 - loss: 0.0000 - acc: 0.9762 - tss: 0.9524 - gamma: 2.00\n",
      "Epoch 249/300 - loss: 0.0000 - acc: 0.9760 - tss: 0.9519 - gamma: 2.00\n",
      "Epoch 250/300 - loss: 0.0000 - acc: 0.9762 - tss: 0.9524 - gamma: 2.00\n",
      "Epoch 251/300 - loss: 0.0000 - acc: 0.9761 - tss: 0.9522 - gamma: 2.00\n",
      "Epoch 252/300 - loss: 0.0000 - acc: 0.9763 - tss: 0.9525 - gamma: 2.00\n",
      "Epoch 253/300 - loss: 0.0000 - acc: 0.9762 - tss: 0.9524 - gamma: 2.00\n",
      "Epoch 254/300 - loss: 0.0000 - acc: 0.9762 - tss: 0.9523 - gamma: 2.00\n",
      "Epoch 255/300 - loss: 0.0000 - acc: 0.9765 - tss: 0.9530 - gamma: 2.00\n",
      "Epoch 256/300 - loss: 0.0000 - acc: 0.9764 - tss: 0.9528 - gamma: 2.00\n",
      "Epoch 257/300 - loss: 0.0000 - acc: 0.9765 - tss: 0.9529 - gamma: 2.00\n",
      "Epoch 258/300 - loss: 0.0000 - acc: 0.9767 - tss: 0.9534 - gamma: 2.00\n",
      "Epoch 259/300 - loss: 0.0000 - acc: 0.9765 - tss: 0.9531 - gamma: 2.00\n",
      "Epoch 260/300 - loss: 0.0000 - acc: 0.9763 - tss: 0.9526 - gamma: 2.00\n",
      "Epoch 261/300 - loss: 0.0000 - acc: 0.9764 - tss: 0.9527 - gamma: 2.00\n",
      "Epoch 262/300 - loss: 0.0000 - acc: 0.9763 - tss: 0.9525 - gamma: 2.00\n",
      "Epoch 263/300 - loss: 0.0000 - acc: 0.9767 - tss: 0.9534 - gamma: 2.00\n",
      "Epoch 264/300 - loss: 0.0000 - acc: 0.9767 - tss: 0.9532 - gamma: 2.00\n",
      "Epoch 265/300 - loss: 0.0000 - acc: 0.9765 - tss: 0.9530 - gamma: 2.00\n",
      "Epoch 266/300 - loss: 0.0000 - acc: 0.9765 - tss: 0.9530 - gamma: 2.00\n",
      "Epoch 267/300 - loss: 0.0000 - acc: 0.9770 - tss: 0.9539 - gamma: 2.00\n",
      "Epoch 268/300 - loss: 0.0000 - acc: 0.9766 - tss: 0.9531 - gamma: 2.00\n",
      "Epoch 269/300 - loss: 0.0000 - acc: 0.9767 - tss: 0.9535 - gamma: 2.00\n",
      "Epoch 270/300 - loss: 0.0000 - acc: 0.9770 - tss: 0.9540 - gamma: 2.00\n",
      "Epoch 271/300 - loss: 0.0000 - acc: 0.9766 - tss: 0.9532 - gamma: 2.00\n",
      "Epoch 272/300 - loss: 0.0000 - acc: 0.9770 - tss: 0.9539 - gamma: 2.00\n",
      "Epoch 273/300 - loss: 0.0000 - acc: 0.9769 - tss: 0.9537 - gamma: 2.00\n",
      "Epoch 274/300 - loss: 0.0000 - acc: 0.9769 - tss: 0.9538 - gamma: 2.00\n",
      "Epoch 275/300 - loss: 0.0000 - acc: 0.9771 - tss: 0.9542 - gamma: 2.00\n",
      "Epoch 276/300 - loss: 0.0000 - acc: 0.9773 - tss: 0.9545 - gamma: 2.00\n",
      "Epoch 277/300 - loss: 0.0000 - acc: 0.9769 - tss: 0.9537 - gamma: 2.00\n",
      "Epoch 278/300 - loss: 0.0000 - acc: 0.9770 - tss: 0.9539 - gamma: 2.00\n",
      "Epoch 279/300 - loss: 0.0000 - acc: 0.9773 - tss: 0.9544 - gamma: 2.00\n",
      "Epoch 280/300 - loss: 0.0000 - acc: 0.9772 - tss: 0.9543 - gamma: 2.00\n",
      "Epoch 281/300 - loss: 0.0000 - acc: 0.9775 - tss: 0.9549 - gamma: 2.00\n",
      "Epoch 282/300 - loss: 0.0000 - acc: 0.9774 - tss: 0.9548 - gamma: 2.00\n",
      "Epoch 283/300 - loss: 0.0000 - acc: 0.9774 - tss: 0.9548 - gamma: 2.00\n",
      "Epoch 284/300 - loss: 0.0000 - acc: 0.9772 - tss: 0.9544 - gamma: 2.00\n",
      "Epoch 285/300 - loss: 0.0000 - acc: 0.9776 - tss: 0.9551 - gamma: 2.00\n",
      "Epoch 286/300 - loss: 0.0000 - acc: 0.9774 - tss: 0.9547 - gamma: 2.00\n",
      "Epoch 287/300 - loss: 0.0000 - acc: 0.9775 - tss: 0.9550 - gamma: 2.00\n",
      "Epoch 288/300 - loss: 0.0000 - acc: 0.9775 - tss: 0.9549 - gamma: 2.00\n",
      "Epoch 289/300 - loss: 0.0000 - acc: 0.9777 - tss: 0.9554 - gamma: 2.00\n",
      "Epoch 290/300 - loss: 0.0000 - acc: 0.9774 - tss: 0.9547 - gamma: 2.00\n",
      "Epoch 291/300 - loss: 0.0000 - acc: 0.9775 - tss: 0.9550 - gamma: 2.00\n",
      "Epoch 292/300 - loss: 0.0000 - acc: 0.9775 - tss: 0.9549 - gamma: 2.00\n",
      "Epoch 293/300 - loss: 0.0000 - acc: 0.9775 - tss: 0.9549 - gamma: 2.00\n",
      "Epoch 294/300 - loss: 0.0000 - acc: 0.9778 - tss: 0.9555 - gamma: 2.00\n",
      "Epoch 295/300 - loss: 0.0000 - acc: 0.9778 - tss: 0.9555 - gamma: 2.00\n",
      "Epoch 296/300 - loss: 0.0000 - acc: 0.9777 - tss: 0.9554 - gamma: 2.00\n",
      "Epoch 297/300 - loss: 0.0000 - acc: 0.9776 - tss: 0.9551 - gamma: 2.00\n",
      "Epoch 298/300 - loss: 0.0000 - acc: 0.9780 - tss: 0.9559 - gamma: 2.00\n",
      "Epoch 299/300 - loss: 0.0000 - acc: 0.9778 - tss: 0.9554 - gamma: 2.00\n",
      "Epoch 300/300 - loss: 0.0000 - acc: 0.9780 - tss: 0.9559 - gamma: 2.00\n",
      "Model saved to models/EVEREST-v1.3-C-48h\n",
      "✅ Best weights and metadata stored in: models/EVEREST-v1.3-C-48h\n",
      "------------------------------------------------------------\n",
      "🚀 Training model for flare class C with 72h window\n",
      "Epoch 1/300 - loss: 0.0011 - acc: 0.6806 - tss: 0.3649 - gamma: 0.00\n",
      "Epoch 2/300 - loss: 0.0010 - acc: 0.6947 - tss: 0.3931 - gamma: 0.04\n",
      "Epoch 3/300 - loss: 0.0010 - acc: 0.7145 - tss: 0.4336 - gamma: 0.08\n",
      "Epoch 4/300 - loss: 0.0009 - acc: 0.7356 - tss: 0.4758 - gamma: 0.12\n",
      "Epoch 5/300 - loss: 0.0008 - acc: 0.7540 - tss: 0.5121 - gamma: 0.16\n",
      "Epoch 6/300 - loss: 0.0007 - acc: 0.7746 - tss: 0.5533 - gamma: 0.20\n",
      "Epoch 7/300 - loss: 0.0007 - acc: 0.7929 - tss: 0.5898 - gamma: 0.24\n",
      "Epoch 8/300 - loss: 0.0006 - acc: 0.8079 - tss: 0.6196 - gamma: 0.28\n",
      "Epoch 9/300 - loss: 0.0006 - acc: 0.8209 - tss: 0.6453 - gamma: 0.32\n",
      "Epoch 10/300 - loss: 0.0005 - acc: 0.8315 - tss: 0.6662 - gamma: 0.36\n",
      "Epoch 11/300 - loss: 0.0005 - acc: 0.8412 - tss: 0.6856 - gamma: 0.40\n",
      "Epoch 12/300 - loss: 0.0005 - acc: 0.8490 - tss: 0.7010 - gamma: 0.44\n",
      "Epoch 13/300 - loss: 0.0004 - acc: 0.8559 - tss: 0.7147 - gamma: 0.48\n",
      "Epoch 14/300 - loss: 0.0004 - acc: 0.8625 - tss: 0.7276 - gamma: 0.52\n",
      "Epoch 15/300 - loss: 0.0004 - acc: 0.8678 - tss: 0.7382 - gamma: 0.56\n",
      "Epoch 16/300 - loss: 0.0004 - acc: 0.8734 - tss: 0.7492 - gamma: 0.60\n",
      "Epoch 17/300 - loss: 0.0003 - acc: 0.8776 - tss: 0.7575 - gamma: 0.64\n",
      "Epoch 18/300 - loss: 0.0003 - acc: 0.8823 - tss: 0.7668 - gamma: 0.68\n",
      "Epoch 19/300 - loss: 0.0003 - acc: 0.8861 - tss: 0.7742 - gamma: 0.72\n",
      "Epoch 20/300 - loss: 0.0003 - acc: 0.8896 - tss: 0.7813 - gamma: 0.76\n",
      "Epoch 21/300 - loss: 0.0002 - acc: 0.8942 - tss: 0.7902 - gamma: 0.80\n",
      "Epoch 22/300 - loss: 0.0002 - acc: 0.8964 - tss: 0.7946 - gamma: 0.84\n",
      "Epoch 23/300 - loss: 0.0002 - acc: 0.8986 - tss: 0.7990 - gamma: 0.88\n",
      "Epoch 24/300 - loss: 0.0002 - acc: 0.9015 - tss: 0.8047 - gamma: 0.92\n",
      "Epoch 25/300 - loss: 0.0002 - acc: 0.9040 - tss: 0.8096 - gamma: 0.96\n",
      "Epoch 26/300 - loss: 0.0002 - acc: 0.9063 - tss: 0.8142 - gamma: 1.00\n",
      "Epoch 27/300 - loss: 0.0002 - acc: 0.9084 - tss: 0.8182 - gamma: 1.04\n",
      "Epoch 28/300 - loss: 0.0002 - acc: 0.9107 - tss: 0.8228 - gamma: 1.08\n",
      "Epoch 29/300 - loss: 0.0002 - acc: 0.9122 - tss: 0.8258 - gamma: 1.12\n",
      "Epoch 30/300 - loss: 0.0002 - acc: 0.9144 - tss: 0.8302 - gamma: 1.16\n",
      "Epoch 31/300 - loss: 0.0002 - acc: 0.9159 - tss: 0.8331 - gamma: 1.20\n",
      "Epoch 32/300 - loss: 0.0001 - acc: 0.9174 - tss: 0.8361 - gamma: 1.24\n",
      "Epoch 33/300 - loss: 0.0001 - acc: 0.9192 - tss: 0.8395 - gamma: 1.28\n",
      "Epoch 34/300 - loss: 0.0001 - acc: 0.9200 - tss: 0.8412 - gamma: 1.32\n",
      "Epoch 35/300 - loss: 0.0001 - acc: 0.9221 - tss: 0.8452 - gamma: 1.36\n",
      "Epoch 36/300 - loss: 0.0001 - acc: 0.9236 - tss: 0.8482 - gamma: 1.40\n",
      "Epoch 37/300 - loss: 0.0001 - acc: 0.9248 - tss: 0.8506 - gamma: 1.44\n",
      "Epoch 38/300 - loss: 0.0001 - acc: 0.9257 - tss: 0.8524 - gamma: 1.48\n",
      "Epoch 39/300 - loss: 0.0001 - acc: 0.9268 - tss: 0.8546 - gamma: 1.52\n",
      "Epoch 40/300 - loss: 0.0001 - acc: 0.9277 - tss: 0.8562 - gamma: 1.56\n",
      "Epoch 41/300 - loss: 0.0001 - acc: 0.9302 - tss: 0.8613 - gamma: 1.60\n",
      "Epoch 42/300 - loss: 0.0001 - acc: 0.9303 - tss: 0.8613 - gamma: 1.64\n",
      "Epoch 43/300 - loss: 0.0001 - acc: 0.9311 - tss: 0.8630 - gamma: 1.68\n",
      "Epoch 44/300 - loss: 0.0001 - acc: 0.9317 - tss: 0.8642 - gamma: 1.72\n",
      "Epoch 45/300 - loss: 0.0001 - acc: 0.9333 - tss: 0.8674 - gamma: 1.76\n",
      "Epoch 46/300 - loss: 0.0001 - acc: 0.9339 - tss: 0.8685 - gamma: 1.80\n",
      "Epoch 47/300 - loss: 0.0001 - acc: 0.9351 - tss: 0.8708 - gamma: 1.84\n",
      "Epoch 48/300 - loss: 0.0001 - acc: 0.9356 - tss: 0.8720 - gamma: 1.88\n",
      "Epoch 49/300 - loss: 0.0001 - acc: 0.9364 - tss: 0.8735 - gamma: 1.92\n",
      "Epoch 50/300 - loss: 0.0001 - acc: 0.9371 - tss: 0.8749 - gamma: 1.96\n",
      "Epoch 51/300 - loss: 0.0001 - acc: 0.9384 - tss: 0.8774 - gamma: 2.00\n",
      "Epoch 52/300 - loss: 0.0001 - acc: 0.9383 - tss: 0.8772 - gamma: 2.00\n",
      "Epoch 53/300 - loss: 0.0001 - acc: 0.9386 - tss: 0.8779 - gamma: 2.00\n",
      "Epoch 54/300 - loss: 0.0001 - acc: 0.9393 - tss: 0.8792 - gamma: 2.00\n",
      "Epoch 55/300 - loss: 0.0001 - acc: 0.9398 - tss: 0.8802 - gamma: 2.00\n",
      "Epoch 56/300 - loss: 0.0001 - acc: 0.9405 - tss: 0.8816 - gamma: 2.00\n",
      "Epoch 57/300 - loss: 0.0001 - acc: 0.9416 - tss: 0.8837 - gamma: 2.00\n",
      "Epoch 58/300 - loss: 0.0001 - acc: 0.9424 - tss: 0.8854 - gamma: 2.00\n",
      "Epoch 59/300 - loss: 0.0001 - acc: 0.9426 - tss: 0.8858 - gamma: 2.00\n",
      "Epoch 60/300 - loss: 0.0001 - acc: 0.9435 - tss: 0.8875 - gamma: 2.00\n",
      "Epoch 61/300 - loss: 0.0001 - acc: 0.9438 - tss: 0.8880 - gamma: 2.00\n",
      "Epoch 62/300 - loss: 0.0001 - acc: 0.9446 - tss: 0.8896 - gamma: 2.00\n",
      "Epoch 63/300 - loss: 0.0001 - acc: 0.9444 - tss: 0.8892 - gamma: 2.00\n",
      "Epoch 64/300 - loss: 0.0001 - acc: 0.9455 - tss: 0.8914 - gamma: 2.00\n",
      "Epoch 65/300 - loss: 0.0001 - acc: 0.9458 - tss: 0.8921 - gamma: 2.00\n",
      "Epoch 66/300 - loss: 0.0001 - acc: 0.9463 - tss: 0.8929 - gamma: 2.00\n",
      "Epoch 67/300 - loss: 0.0001 - acc: 0.9471 - tss: 0.8945 - gamma: 2.00\n",
      "Epoch 68/300 - loss: 0.0001 - acc: 0.9475 - tss: 0.8955 - gamma: 2.00\n",
      "Epoch 69/300 - loss: 0.0001 - acc: 0.9479 - tss: 0.8961 - gamma: 2.00\n",
      "Epoch 70/300 - loss: 0.0001 - acc: 0.9482 - tss: 0.8968 - gamma: 2.00\n",
      "Epoch 71/300 - loss: 0.0001 - acc: 0.9488 - tss: 0.8980 - gamma: 2.00\n",
      "Epoch 72/300 - loss: 0.0001 - acc: 0.9492 - tss: 0.8987 - gamma: 2.00\n",
      "Epoch 73/300 - loss: 0.0001 - acc: 0.9493 - tss: 0.8990 - gamma: 2.00\n",
      "Epoch 74/300 - loss: 0.0001 - acc: 0.9504 - tss: 0.9012 - gamma: 2.00\n",
      "Epoch 75/300 - loss: 0.0001 - acc: 0.9503 - tss: 0.9010 - gamma: 2.00\n",
      "Epoch 76/300 - loss: 0.0001 - acc: 0.9509 - tss: 0.9022 - gamma: 2.00\n",
      "Epoch 77/300 - loss: 0.0001 - acc: 0.9510 - tss: 0.9022 - gamma: 2.00\n",
      "Epoch 78/300 - loss: 0.0001 - acc: 0.9517 - tss: 0.9037 - gamma: 2.00\n",
      "Epoch 79/300 - loss: 0.0001 - acc: 0.9518 - tss: 0.9039 - gamma: 2.00\n",
      "Epoch 80/300 - loss: 0.0001 - acc: 0.9522 - tss: 0.9046 - gamma: 2.00\n",
      "Epoch 81/300 - loss: 0.0001 - acc: 0.9527 - tss: 0.9057 - gamma: 2.00\n",
      "Epoch 82/300 - loss: 0.0001 - acc: 0.9531 - tss: 0.9065 - gamma: 2.00\n",
      "Epoch 83/300 - loss: 0.0001 - acc: 0.9533 - tss: 0.9069 - gamma: 2.00\n",
      "Epoch 84/300 - loss: 0.0001 - acc: 0.9539 - tss: 0.9080 - gamma: 2.00\n",
      "Epoch 85/300 - loss: 0.0001 - acc: 0.9539 - tss: 0.9080 - gamma: 2.00\n",
      "Epoch 86/300 - loss: 0.0001 - acc: 0.9544 - tss: 0.9091 - gamma: 2.00\n",
      "Epoch 87/300 - loss: 0.0001 - acc: 0.9546 - tss: 0.9094 - gamma: 2.00\n",
      "Epoch 88/300 - loss: 0.0001 - acc: 0.9552 - tss: 0.9107 - gamma: 2.00\n",
      "Epoch 89/300 - loss: 0.0001 - acc: 0.9552 - tss: 0.9106 - gamma: 2.00\n",
      "Epoch 90/300 - loss: 0.0001 - acc: 0.9557 - tss: 0.9117 - gamma: 2.00\n",
      "Epoch 91/300 - loss: 0.0000 - acc: 0.9564 - tss: 0.9131 - gamma: 2.00\n",
      "Epoch 92/300 - loss: 0.0000 - acc: 0.9561 - tss: 0.9124 - gamma: 2.00\n",
      "Epoch 93/300 - loss: 0.0000 - acc: 0.9567 - tss: 0.9136 - gamma: 2.00\n",
      "Epoch 94/300 - loss: 0.0000 - acc: 0.9569 - tss: 0.9139 - gamma: 2.00\n",
      "Epoch 95/300 - loss: 0.0000 - acc: 0.9570 - tss: 0.9142 - gamma: 2.00\n",
      "Epoch 96/300 - loss: 0.0000 - acc: 0.9571 - tss: 0.9143 - gamma: 2.00\n",
      "Epoch 97/300 - loss: 0.0000 - acc: 0.9572 - tss: 0.9146 - gamma: 2.00\n",
      "Epoch 98/300 - loss: 0.0000 - acc: 0.9578 - tss: 0.9158 - gamma: 2.00\n",
      "Epoch 99/300 - loss: 0.0000 - acc: 0.9583 - tss: 0.9167 - gamma: 2.00\n",
      "Epoch 100/300 - loss: 0.0000 - acc: 0.9585 - tss: 0.9173 - gamma: 2.00\n",
      "Epoch 101/300 - loss: 0.0000 - acc: 0.9584 - tss: 0.9170 - gamma: 2.00\n",
      "Epoch 102/300 - loss: 0.0000 - acc: 0.9587 - tss: 0.9175 - gamma: 2.00\n",
      "Epoch 103/300 - loss: 0.0000 - acc: 0.9594 - tss: 0.9189 - gamma: 2.00\n",
      "Epoch 104/300 - loss: 0.0000 - acc: 0.9593 - tss: 0.9188 - gamma: 2.00\n",
      "Epoch 105/300 - loss: 0.0000 - acc: 0.9595 - tss: 0.9191 - gamma: 2.00\n",
      "Epoch 106/300 - loss: 0.0000 - acc: 0.9592 - tss: 0.9186 - gamma: 2.00\n",
      "Epoch 107/300 - loss: 0.0000 - acc: 0.9599 - tss: 0.9200 - gamma: 2.00\n",
      "Epoch 108/300 - loss: 0.0000 - acc: 0.9603 - tss: 0.9207 - gamma: 2.00\n",
      "Epoch 109/300 - loss: 0.0000 - acc: 0.9604 - tss: 0.9210 - gamma: 2.00\n",
      "Epoch 110/300 - loss: 0.0000 - acc: 0.9604 - tss: 0.9209 - gamma: 2.00\n",
      "Epoch 111/300 - loss: 0.0000 - acc: 0.9606 - tss: 0.9214 - gamma: 2.00\n",
      "Epoch 112/300 - loss: 0.0000 - acc: 0.9608 - tss: 0.9218 - gamma: 2.00\n",
      "Epoch 113/300 - loss: 0.0000 - acc: 0.9613 - tss: 0.9228 - gamma: 2.00\n",
      "Epoch 114/300 - loss: 0.0000 - acc: 0.9612 - tss: 0.9225 - gamma: 2.00\n",
      "Epoch 115/300 - loss: 0.0000 - acc: 0.9618 - tss: 0.9238 - gamma: 2.00\n",
      "Epoch 116/300 - loss: 0.0000 - acc: 0.9615 - tss: 0.9231 - gamma: 2.00\n",
      "Epoch 117/300 - loss: 0.0000 - acc: 0.9621 - tss: 0.9243 - gamma: 2.00\n",
      "Epoch 118/300 - loss: 0.0000 - acc: 0.9621 - tss: 0.9243 - gamma: 2.00\n",
      "Epoch 119/300 - loss: 0.0000 - acc: 0.9624 - tss: 0.9248 - gamma: 2.00\n",
      "Epoch 120/300 - loss: 0.0000 - acc: 0.9624 - tss: 0.9250 - gamma: 2.00\n",
      "Epoch 121/300 - loss: 0.0000 - acc: 0.9630 - tss: 0.9261 - gamma: 2.00\n",
      "Epoch 122/300 - loss: 0.0000 - acc: 0.9628 - tss: 0.9258 - gamma: 2.00\n",
      "Epoch 123/300 - loss: 0.0000 - acc: 0.9629 - tss: 0.9258 - gamma: 2.00\n",
      "Epoch 124/300 - loss: 0.0000 - acc: 0.9632 - tss: 0.9265 - gamma: 2.00\n",
      "Epoch 125/300 - loss: 0.0000 - acc: 0.9631 - tss: 0.9262 - gamma: 2.00\n",
      "Epoch 126/300 - loss: 0.0000 - acc: 0.9634 - tss: 0.9269 - gamma: 2.00\n",
      "Epoch 127/300 - loss: 0.0000 - acc: 0.9639 - tss: 0.9280 - gamma: 2.00\n",
      "Epoch 128/300 - loss: 0.0000 - acc: 0.9639 - tss: 0.9279 - gamma: 2.00\n",
      "Epoch 129/300 - loss: 0.0000 - acc: 0.9639 - tss: 0.9278 - gamma: 2.00\n",
      "Epoch 130/300 - loss: 0.0000 - acc: 0.9645 - tss: 0.9290 - gamma: 2.00\n",
      "Epoch 131/300 - loss: 0.0000 - acc: 0.9643 - tss: 0.9288 - gamma: 2.00\n",
      "Epoch 132/300 - loss: 0.0000 - acc: 0.9644 - tss: 0.9289 - gamma: 2.00\n",
      "Epoch 133/300 - loss: 0.0000 - acc: 0.9646 - tss: 0.9292 - gamma: 2.00\n",
      "Epoch 134/300 - loss: 0.0000 - acc: 0.9645 - tss: 0.9291 - gamma: 2.00\n",
      "Epoch 135/300 - loss: 0.0000 - acc: 0.9647 - tss: 0.9296 - gamma: 2.00\n",
      "Epoch 136/300 - loss: 0.0000 - acc: 0.9650 - tss: 0.9300 - gamma: 2.00\n",
      "Epoch 137/300 - loss: 0.0000 - acc: 0.9648 - tss: 0.9298 - gamma: 2.00\n",
      "Epoch 138/300 - loss: 0.0000 - acc: 0.9652 - tss: 0.9305 - gamma: 2.00\n",
      "Epoch 139/300 - loss: 0.0000 - acc: 0.9655 - tss: 0.9311 - gamma: 2.00\n",
      "Epoch 140/300 - loss: 0.0000 - acc: 0.9653 - tss: 0.9306 - gamma: 2.00\n",
      "Epoch 141/300 - loss: 0.0000 - acc: 0.9654 - tss: 0.9308 - gamma: 2.00\n",
      "Epoch 142/300 - loss: 0.0000 - acc: 0.9663 - tss: 0.9327 - gamma: 2.00\n",
      "Epoch 143/300 - loss: 0.0000 - acc: 0.9661 - tss: 0.9322 - gamma: 2.00\n",
      "Epoch 144/300 - loss: 0.0000 - acc: 0.9658 - tss: 0.9317 - gamma: 2.00\n",
      "Epoch 145/300 - loss: 0.0000 - acc: 0.9662 - tss: 0.9326 - gamma: 2.00\n",
      "Epoch 146/300 - loss: 0.0000 - acc: 0.9664 - tss: 0.9328 - gamma: 2.00\n",
      "Epoch 147/300 - loss: 0.0000 - acc: 0.9663 - tss: 0.9327 - gamma: 2.00\n",
      "Epoch 148/300 - loss: 0.0000 - acc: 0.9666 - tss: 0.9333 - gamma: 2.00\n",
      "Epoch 149/300 - loss: 0.0000 - acc: 0.9665 - tss: 0.9331 - gamma: 2.00\n",
      "Epoch 150/300 - loss: 0.0000 - acc: 0.9667 - tss: 0.9336 - gamma: 2.00\n",
      "Epoch 151/300 - loss: 0.0000 - acc: 0.9671 - tss: 0.9342 - gamma: 2.00\n",
      "Epoch 152/300 - loss: 0.0000 - acc: 0.9672 - tss: 0.9344 - gamma: 2.00\n",
      "Epoch 153/300 - loss: 0.0000 - acc: 0.9671 - tss: 0.9343 - gamma: 2.00\n",
      "Epoch 154/300 - loss: 0.0000 - acc: 0.9674 - tss: 0.9349 - gamma: 2.00\n",
      "Epoch 155/300 - loss: 0.0000 - acc: 0.9673 - tss: 0.9347 - gamma: 2.00\n",
      "Epoch 156/300 - loss: 0.0000 - acc: 0.9676 - tss: 0.9352 - gamma: 2.00\n",
      "Epoch 157/300 - loss: 0.0000 - acc: 0.9673 - tss: 0.9347 - gamma: 2.00\n",
      "Epoch 158/300 - loss: 0.0000 - acc: 0.9673 - tss: 0.9346 - gamma: 2.00\n",
      "Epoch 159/300 - loss: 0.0000 - acc: 0.9674 - tss: 0.9348 - gamma: 2.00\n",
      "Epoch 160/300 - loss: 0.0000 - acc: 0.9681 - tss: 0.9362 - gamma: 2.00\n",
      "Epoch 161/300 - loss: 0.0000 - acc: 0.9681 - tss: 0.9362 - gamma: 2.00\n",
      "Epoch 162/300 - loss: 0.0000 - acc: 0.9682 - tss: 0.9365 - gamma: 2.00\n",
      "Epoch 163/300 - loss: 0.0000 - acc: 0.9677 - tss: 0.9354 - gamma: 2.00\n",
      "Epoch 164/300 - loss: 0.0000 - acc: 0.9683 - tss: 0.9367 - gamma: 2.00\n",
      "Epoch 165/300 - loss: 0.0000 - acc: 0.9680 - tss: 0.9361 - gamma: 2.00\n",
      "Epoch 166/300 - loss: 0.0000 - acc: 0.9681 - tss: 0.9363 - gamma: 2.00\n",
      "Epoch 167/300 - loss: 0.0000 - acc: 0.9686 - tss: 0.9372 - gamma: 2.00\n",
      "Epoch 168/300 - loss: 0.0000 - acc: 0.9686 - tss: 0.9372 - gamma: 2.00\n",
      "Epoch 169/300 - loss: 0.0000 - acc: 0.9686 - tss: 0.9373 - gamma: 2.00\n",
      "Epoch 170/300 - loss: 0.0000 - acc: 0.9688 - tss: 0.9377 - gamma: 2.00\n",
      "Epoch 171/300 - loss: 0.0000 - acc: 0.9691 - tss: 0.9382 - gamma: 2.00\n",
      "Epoch 172/300 - loss: 0.0000 - acc: 0.9691 - tss: 0.9382 - gamma: 2.00\n",
      "Epoch 173/300 - loss: 0.0000 - acc: 0.9691 - tss: 0.9383 - gamma: 2.00\n",
      "Epoch 174/300 - loss: 0.0000 - acc: 0.9690 - tss: 0.9381 - gamma: 2.00\n",
      "Epoch 175/300 - loss: 0.0000 - acc: 0.9695 - tss: 0.9391 - gamma: 2.00\n",
      "Epoch 176/300 - loss: 0.0000 - acc: 0.9694 - tss: 0.9389 - gamma: 2.00\n",
      "Epoch 177/300 - loss: 0.0000 - acc: 0.9696 - tss: 0.9392 - gamma: 2.00\n",
      "Epoch 178/300 - loss: 0.0000 - acc: 0.9689 - tss: 0.9378 - gamma: 2.00\n",
      "Epoch 179/300 - loss: 0.0000 - acc: 0.9694 - tss: 0.9388 - gamma: 2.00\n",
      "Epoch 180/300 - loss: 0.0000 - acc: 0.9699 - tss: 0.9399 - gamma: 2.00\n",
      "Epoch 181/300 - loss: 0.0000 - acc: 0.9697 - tss: 0.9395 - gamma: 2.00\n",
      "Epoch 182/300 - loss: 0.0000 - acc: 0.9697 - tss: 0.9395 - gamma: 2.00\n",
      "Epoch 183/300 - loss: 0.0000 - acc: 0.9699 - tss: 0.9399 - gamma: 2.00\n",
      "Epoch 184/300 - loss: 0.0000 - acc: 0.9701 - tss: 0.9401 - gamma: 2.00\n",
      "Epoch 185/300 - loss: 0.0000 - acc: 0.9701 - tss: 0.9403 - gamma: 2.00\n",
      "Epoch 186/300 - loss: 0.0000 - acc: 0.9702 - tss: 0.9404 - gamma: 2.00\n",
      "Epoch 187/300 - loss: 0.0000 - acc: 0.9700 - tss: 0.9399 - gamma: 2.00\n",
      "Epoch 188/300 - loss: 0.0000 - acc: 0.9702 - tss: 0.9404 - gamma: 2.00\n",
      "Epoch 189/300 - loss: 0.0000 - acc: 0.9700 - tss: 0.9401 - gamma: 2.00\n",
      "Epoch 190/300 - loss: 0.0000 - acc: 0.9701 - tss: 0.9403 - gamma: 2.00\n",
      "Epoch 191/300 - loss: 0.0000 - acc: 0.9702 - tss: 0.9404 - gamma: 2.00\n",
      "Epoch 192/300 - loss: 0.0000 - acc: 0.9704 - tss: 0.9408 - gamma: 2.00\n",
      "Epoch 193/300 - loss: 0.0000 - acc: 0.9708 - tss: 0.9416 - gamma: 2.00\n",
      "Epoch 194/300 - loss: 0.0000 - acc: 0.9706 - tss: 0.9413 - gamma: 2.00\n",
      "Epoch 195/300 - loss: 0.0000 - acc: 0.9707 - tss: 0.9414 - gamma: 2.00\n",
      "Epoch 196/300 - loss: 0.0000 - acc: 0.9707 - tss: 0.9415 - gamma: 2.00\n",
      "Epoch 197/300 - loss: 0.0000 - acc: 0.9710 - tss: 0.9421 - gamma: 2.00\n",
      "Epoch 198/300 - loss: 0.0000 - acc: 0.9711 - tss: 0.9423 - gamma: 2.00\n",
      "Epoch 199/300 - loss: 0.0000 - acc: 0.9714 - tss: 0.9428 - gamma: 2.00\n",
      "Epoch 200/300 - loss: 0.0000 - acc: 0.9707 - tss: 0.9414 - gamma: 2.00\n",
      "Epoch 201/300 - loss: 0.0000 - acc: 0.9714 - tss: 0.9428 - gamma: 2.00\n",
      "Epoch 202/300 - loss: 0.0000 - acc: 0.9714 - tss: 0.9428 - gamma: 2.00\n",
      "Epoch 203/300 - loss: 0.0000 - acc: 0.9712 - tss: 0.9424 - gamma: 2.00\n",
      "Epoch 204/300 - loss: 0.0000 - acc: 0.9715 - tss: 0.9431 - gamma: 2.00\n",
      "Epoch 205/300 - loss: 0.0000 - acc: 0.9712 - tss: 0.9424 - gamma: 2.00\n",
      "Epoch 206/300 - loss: 0.0000 - acc: 0.9715 - tss: 0.9431 - gamma: 2.00\n",
      "Epoch 207/300 - loss: 0.0000 - acc: 0.9716 - tss: 0.9432 - gamma: 2.00\n",
      "Epoch 208/300 - loss: 0.0000 - acc: 0.9715 - tss: 0.9430 - gamma: 2.00\n",
      "Epoch 209/300 - loss: 0.0000 - acc: 0.9720 - tss: 0.9441 - gamma: 2.00\n",
      "Epoch 210/300 - loss: 0.0000 - acc: 0.9714 - tss: 0.9428 - gamma: 2.00\n",
      "Epoch 211/300 - loss: 0.0000 - acc: 0.9716 - tss: 0.9433 - gamma: 2.00\n",
      "Epoch 212/300 - loss: 0.0000 - acc: 0.9721 - tss: 0.9443 - gamma: 2.00\n",
      "Epoch 213/300 - loss: 0.0000 - acc: 0.9720 - tss: 0.9440 - gamma: 2.00\n",
      "Epoch 214/300 - loss: 0.0000 - acc: 0.9719 - tss: 0.9438 - gamma: 2.00\n",
      "Epoch 215/300 - loss: 0.0000 - acc: 0.9723 - tss: 0.9446 - gamma: 2.00\n",
      "Epoch 216/300 - loss: 0.0000 - acc: 0.9721 - tss: 0.9442 - gamma: 2.00\n",
      "Epoch 217/300 - loss: 0.0000 - acc: 0.9721 - tss: 0.9443 - gamma: 2.00\n",
      "Epoch 218/300 - loss: 0.0000 - acc: 0.9724 - tss: 0.9448 - gamma: 2.00\n",
      "Epoch 219/300 - loss: 0.0000 - acc: 0.9723 - tss: 0.9447 - gamma: 2.00\n",
      "Epoch 220/300 - loss: 0.0000 - acc: 0.9726 - tss: 0.9452 - gamma: 2.00\n",
      "Epoch 221/300 - loss: 0.0000 - acc: 0.9723 - tss: 0.9445 - gamma: 2.00\n",
      "Epoch 222/300 - loss: 0.0000 - acc: 0.9728 - tss: 0.9455 - gamma: 2.00\n",
      "Epoch 223/300 - loss: 0.0000 - acc: 0.9727 - tss: 0.9453 - gamma: 2.00\n",
      "Epoch 224/300 - loss: 0.0000 - acc: 0.9726 - tss: 0.9452 - gamma: 2.00\n",
      "Epoch 225/300 - loss: 0.0000 - acc: 0.9727 - tss: 0.9454 - gamma: 2.00\n",
      "Epoch 226/300 - loss: 0.0000 - acc: 0.9726 - tss: 0.9451 - gamma: 2.00\n",
      "Epoch 227/300 - loss: 0.0000 - acc: 0.9728 - tss: 0.9455 - gamma: 2.00\n",
      "Epoch 228/300 - loss: 0.0000 - acc: 0.9728 - tss: 0.9457 - gamma: 2.00\n",
      "Epoch 229/300 - loss: 0.0000 - acc: 0.9732 - tss: 0.9464 - gamma: 2.00\n",
      "Epoch 230/300 - loss: 0.0000 - acc: 0.9729 - tss: 0.9458 - gamma: 2.00\n",
      "Epoch 231/300 - loss: 0.0000 - acc: 0.9735 - tss: 0.9469 - gamma: 2.00\n",
      "Epoch 232/300 - loss: 0.0000 - acc: 0.9730 - tss: 0.9461 - gamma: 2.00\n",
      "Epoch 233/300 - loss: 0.0000 - acc: 0.9731 - tss: 0.9462 - gamma: 2.00\n",
      "Epoch 234/300 - loss: 0.0000 - acc: 0.9730 - tss: 0.9461 - gamma: 2.00\n",
      "Epoch 235/300 - loss: 0.0000 - acc: 0.9734 - tss: 0.9467 - gamma: 2.00\n",
      "Epoch 236/300 - loss: 0.0000 - acc: 0.9735 - tss: 0.9471 - gamma: 2.00\n",
      "Epoch 237/300 - loss: 0.0000 - acc: 0.9731 - tss: 0.9463 - gamma: 2.00\n",
      "Epoch 238/300 - loss: 0.0000 - acc: 0.9731 - tss: 0.9461 - gamma: 2.00\n",
      "Epoch 239/300 - loss: 0.0000 - acc: 0.9735 - tss: 0.9471 - gamma: 2.00\n",
      "Epoch 240/300 - loss: 0.0000 - acc: 0.9732 - tss: 0.9464 - gamma: 2.00\n",
      "Epoch 241/300 - loss: 0.0000 - acc: 0.9735 - tss: 0.9470 - gamma: 2.00\n",
      "Epoch 242/300 - loss: 0.0000 - acc: 0.9738 - tss: 0.9476 - gamma: 2.00\n",
      "Epoch 243/300 - loss: 0.0000 - acc: 0.9732 - tss: 0.9465 - gamma: 2.00\n",
      "Epoch 244/300 - loss: 0.0000 - acc: 0.9736 - tss: 0.9473 - gamma: 2.00\n",
      "Epoch 245/300 - loss: 0.0000 - acc: 0.9737 - tss: 0.9475 - gamma: 2.00\n",
      "Epoch 246/300 - loss: 0.0000 - acc: 0.9738 - tss: 0.9476 - gamma: 2.00\n",
      "Epoch 247/300 - loss: 0.0000 - acc: 0.9738 - tss: 0.9477 - gamma: 2.00\n",
      "Epoch 248/300 - loss: 0.0000 - acc: 0.9738 - tss: 0.9475 - gamma: 2.00\n",
      "Epoch 249/300 - loss: 0.0000 - acc: 0.9738 - tss: 0.9476 - gamma: 2.00\n",
      "Epoch 250/300 - loss: 0.0000 - acc: 0.9737 - tss: 0.9475 - gamma: 2.00\n",
      "Epoch 251/300 - loss: 0.0000 - acc: 0.9737 - tss: 0.9474 - gamma: 2.00\n",
      "Epoch 252/300 - loss: 0.0000 - acc: 0.9736 - tss: 0.9472 - gamma: 2.00\n",
      "Epoch 253/300 - loss: 0.0000 - acc: 0.9742 - tss: 0.9484 - gamma: 2.00\n",
      "Epoch 254/300 - loss: 0.0000 - acc: 0.9740 - tss: 0.9481 - gamma: 2.00\n",
      "Epoch 255/300 - loss: 0.0000 - acc: 0.9742 - tss: 0.9485 - gamma: 2.00\n",
      "Epoch 256/300 - loss: 0.0000 - acc: 0.9741 - tss: 0.9482 - gamma: 2.00\n",
      "Epoch 257/300 - loss: 0.0000 - acc: 0.9741 - tss: 0.9483 - gamma: 2.00\n",
      "Epoch 258/300 - loss: 0.0000 - acc: 0.9742 - tss: 0.9485 - gamma: 2.00\n",
      "Epoch 259/300 - loss: 0.0000 - acc: 0.9742 - tss: 0.9485 - gamma: 2.00\n",
      "Epoch 260/300 - loss: 0.0000 - acc: 0.9743 - tss: 0.9486 - gamma: 2.00\n",
      "Epoch 261/300 - loss: 0.0000 - acc: 0.9744 - tss: 0.9487 - gamma: 2.00\n",
      "Epoch 262/300 - loss: 0.0000 - acc: 0.9743 - tss: 0.9486 - gamma: 2.00\n",
      "Epoch 263/300 - loss: 0.0000 - acc: 0.9741 - tss: 0.9483 - gamma: 2.00\n",
      "Epoch 264/300 - loss: 0.0000 - acc: 0.9743 - tss: 0.9487 - gamma: 2.00\n",
      "Epoch 265/300 - loss: 0.0000 - acc: 0.9744 - tss: 0.9488 - gamma: 2.00\n",
      "Epoch 266/300 - loss: 0.0000 - acc: 0.9748 - tss: 0.9497 - gamma: 2.00\n",
      "Epoch 267/300 - loss: 0.0000 - acc: 0.9747 - tss: 0.9493 - gamma: 2.00\n",
      "Epoch 268/300 - loss: 0.0000 - acc: 0.9748 - tss: 0.9496 - gamma: 2.00\n",
      "Epoch 269/300 - loss: 0.0000 - acc: 0.9748 - tss: 0.9495 - gamma: 2.00\n",
      "Epoch 270/300 - loss: 0.0000 - acc: 0.9745 - tss: 0.9490 - gamma: 2.00\n",
      "Epoch 271/300 - loss: 0.0000 - acc: 0.9749 - tss: 0.9498 - gamma: 2.00\n",
      "Epoch 272/300 - loss: 0.0000 - acc: 0.9747 - tss: 0.9495 - gamma: 2.00\n",
      "Epoch 273/300 - loss: 0.0000 - acc: 0.9744 - tss: 0.9488 - gamma: 2.00\n",
      "Epoch 274/300 - loss: 0.0000 - acc: 0.9749 - tss: 0.9499 - gamma: 2.00\n",
      "Epoch 275/300 - loss: 0.0000 - acc: 0.9751 - tss: 0.9503 - gamma: 2.00\n",
      "Epoch 276/300 - loss: 0.0000 - acc: 0.9750 - tss: 0.9501 - gamma: 2.00\n",
      "Epoch 277/300 - loss: 0.0000 - acc: 0.9749 - tss: 0.9498 - gamma: 2.00\n",
      "Epoch 278/300 - loss: 0.0000 - acc: 0.9749 - tss: 0.9498 - gamma: 2.00\n",
      "Epoch 279/300 - loss: 0.0000 - acc: 0.9748 - tss: 0.9497 - gamma: 2.00\n",
      "Epoch 280/300 - loss: 0.0000 - acc: 0.9750 - tss: 0.9501 - gamma: 2.00\n",
      "Epoch 281/300 - loss: 0.0000 - acc: 0.9752 - tss: 0.9504 - gamma: 2.00\n",
      "Epoch 282/300 - loss: 0.0000 - acc: 0.9753 - tss: 0.9505 - gamma: 2.00\n",
      "Epoch 283/300 - loss: 0.0000 - acc: 0.9751 - tss: 0.9503 - gamma: 2.00\n",
      "Epoch 284/300 - loss: 0.0000 - acc: 0.9755 - tss: 0.9510 - gamma: 2.00\n",
      "Epoch 285/300 - loss: 0.0000 - acc: 0.9751 - tss: 0.9503 - gamma: 2.00\n",
      "Epoch 286/300 - loss: 0.0000 - acc: 0.9755 - tss: 0.9511 - gamma: 2.00\n",
      "Epoch 287/300 - loss: 0.0000 - acc: 0.9754 - tss: 0.9507 - gamma: 2.00\n",
      "Epoch 288/300 - loss: 0.0000 - acc: 0.9754 - tss: 0.9509 - gamma: 2.00\n",
      "Epoch 289/300 - loss: 0.0000 - acc: 0.9756 - tss: 0.9512 - gamma: 2.00\n",
      "Epoch 290/300 - loss: 0.0000 - acc: 0.9751 - tss: 0.9502 - gamma: 2.00\n",
      "Epoch 291/300 - loss: 0.0000 - acc: 0.9756 - tss: 0.9511 - gamma: 2.00\n",
      "Epoch 292/300 - loss: 0.0000 - acc: 0.9753 - tss: 0.9506 - gamma: 2.00\n",
      "Epoch 293/300 - loss: 0.0000 - acc: 0.9757 - tss: 0.9514 - gamma: 2.00\n",
      "Epoch 294/300 - loss: 0.0000 - acc: 0.9758 - tss: 0.9516 - gamma: 2.00\n",
      "Epoch 295/300 - loss: 0.0000 - acc: 0.9756 - tss: 0.9512 - gamma: 2.00\n",
      "Epoch 296/300 - loss: 0.0000 - acc: 0.9756 - tss: 0.9512 - gamma: 2.00\n",
      "Epoch 297/300 - loss: 0.0000 - acc: 0.9757 - tss: 0.9514 - gamma: 2.00\n",
      "Epoch 298/300 - loss: 0.0000 - acc: 0.9755 - tss: 0.9511 - gamma: 2.00\n",
      "Epoch 299/300 - loss: 0.0000 - acc: 0.9759 - tss: 0.9519 - gamma: 2.00\n",
      "Epoch 300/300 - loss: 0.0000 - acc: 0.9760 - tss: 0.9520 - gamma: 2.00\n",
      "Model saved to models/EVEREST-v1.2-C-72h\n",
      "✅ Best weights and metadata stored in: models/EVEREST-v1.2-C-72h\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training RET+ Models for Solar Flare Prediction (M5 × 72)\n",
    "\n",
    "from solarknowledge_ret_plus import RETPlusWrapper\n",
    "from utils import get_training_data\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "flare_classes = [\"C\"]         # Only M5 for now, \"C\", \"M\", \"M5\"\n",
    "time_windows = [\"48\", \"72\"]          # 72-hour window, \"24\", \"48\", \"72\"\n",
    "input_shape = (10, 9)\n",
    "epochs = 300\n",
    "batch_size = 512\n",
    "\n",
    "# --- Loop over class × horizon ---\n",
    "for flare_class in flare_classes:\n",
    "    for time_window in time_windows:\n",
    "        print(f\"🚀 Training model for flare class {flare_class} with {time_window}h window\")\n",
    "\n",
    "        # Load & prepare training data\n",
    "        X_train, y_train = get_training_data(str(time_window), flare_class)\n",
    "\n",
    "        # Initialize wrapper and train (this will early-stop, save best weights + metadata, and return the model dir)\n",
    "        model = RETPlusWrapper(input_shape)\n",
    "        model_dir = model.train(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            flare_class=flare_class,\n",
    "            time_window=time_window\n",
    "        )\n",
    "\n",
    "        # Report where everything landed\n",
    "        print(f\"✅ Best weights and metadata stored in: {model_dir}\")\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2382e69c-4ef5-4295-ad4d-85ee51281e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 11:54:57.290390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-16 11:54:57.290464: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-16 11:54:57.291542: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-16 11:54:57.298583: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-16 11:55:10.387367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-16 11:55:23.724801: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: TensorFlow GPU device not found.\n",
      "TensorFlow backend version: 2.15.0\n",
      "SUCCESS: PyTorch found GPU: Quadro RTX 6000\n",
      "PyTorch CUDA version: 12.6\n",
      "PyTorch version: 2.7.0+cu126\n",
      "Python version: 3.11.12\n",
      "\n",
      "\n",
      "🔍 Testing EVEREST on M5-class, 24h horizon\n",
      "Using model: models/EVEREST-v4.5-M5-24h/model_weights.pt\n",
      "Confusion matrix:\n",
      " [[47596    75]\n",
      " [   52    52]]\n",
      "Accuracy:  0.9973\n",
      "Precision: 0.4094\n",
      "Recall:    0.5000\n",
      "TSS:       0.4984\n",
      "\n",
      "🔍 Testing EVEREST on M5-class, 48h horizon\n",
      "Using model: models/EVEREST-v1.0-M5-48h/model_weights.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RETPlusModel:\n\tsize mismatch for pos.pe: copying a param with shape torch.Size([1, 10, 128]) from checkpoint, the shape in current model is torch.Size([1, 100, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Load model and weights\u001b[39;00m\n\u001b[32m     47\u001b[39m model = RETPlusWrapper(input_shape)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[32m     51\u001b[39m probs = model.predict_proba(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/masters-project/models/solarknowledge_ret_plus.py:655\u001b[39m, in \u001b[36mRETPlusWrapper.load\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# self.model.load_state_dict(torch.load(path, map_location=device))\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/everest_env/lib/python3.11/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for RETPlusModel:\n\tsize mismatch for pos.pe: copying a param with shape torch.Size([1, 10, 128]) from checkpoint, the shape in current model is torch.Size([1, 100, 128])."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from solarknowledge_ret_plus import RETPlusWrapper\n",
    "from utils import get_testing_data\n",
    "\n",
    "# Constants\n",
    "input_shape = (100, 9)\n",
    "threshold = 0.5\n",
    "base_dir = \"models\"\n",
    "flare_classes = [\"M5\"]\n",
    "horizons = [\"24\", \"48\", \"72\"]\n",
    "\n",
    "# Version extraction regex\n",
    "version_pattern = re.compile(r\"EVEREST-v([\\d.]+)-([A-Z0-9]+)-(\\d+)h\")\n",
    "\n",
    "def get_latest_model_path(flare_class, time_window):\n",
    "    candidates = []\n",
    "    for dirname in os.listdir(base_dir):\n",
    "        match = version_pattern.fullmatch(dirname)\n",
    "        if match:\n",
    "            version, fclass, thours = match.groups()\n",
    "            if fclass == flare_class and thours == time_window:\n",
    "                candidates.append((tuple(map(int, version.split(\".\"))), dirname))\n",
    "    if not candidates:\n",
    "        return None\n",
    "    latest = sorted(candidates)[-1][1]\n",
    "    return os.path.join(base_dir, latest, \"model_weights.pt\")\n",
    "\n",
    "# Iterate through flare × horizon\n",
    "for flare_class in flare_classes:\n",
    "    for time_window in horizons:\n",
    "        model_path = get_latest_model_path(flare_class, time_window)\n",
    "        if not model_path or not os.path.exists(model_path):\n",
    "            print(f\"⚠️ No model found for {flare_class}-{time_window}h.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n🔍 Testing EVEREST on {flare_class}-class, {time_window}h horizon\")\n",
    "        print(f\"Using model: {model_path}\")\n",
    "\n",
    "        # Load test data\n",
    "        X_test, y_test = get_testing_data(time_window, flare_class)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        # Load model and weights\n",
    "        model = RETPlusWrapper(input_shape)\n",
    "        model.load(model_path)\n",
    "\n",
    "        # Predict\n",
    "        probs = model.predict_proba(X_test)\n",
    "        y_pred = (probs >= threshold).astype(int).squeeze()\n",
    "\n",
    "        # Metrics\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        tss = rec + cm[0,0] / (cm[0,0] + cm[0,1] + 1e-8) - 1\n",
    "\n",
    "        # Output\n",
    "        print(\"Confusion matrix:\\n\", cm)\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall:    {rec:.4f}\")\n",
    "        print(f\"TSS:       {tss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbd96f-4661-46d8-af7f-fcb80cbf90ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EVEREST Environment",
   "language": "python",
   "name": "everest_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
