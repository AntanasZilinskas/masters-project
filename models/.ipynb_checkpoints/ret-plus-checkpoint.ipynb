{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acd3d4-3270-46c9-a5ac-0cb075790d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 15:46:24.247075: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-11 15:46:24.247164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-11 15:46:24.400959: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-11 15:46:24.537811: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-11 15:46:37.087685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-11 15:46:50.635413: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: GPU device not found.\n",
      "Python version: 3.11.12\n",
      "Tensorflow bakcend version: 2.15.0\n",
      "\n",
      "ðŸš€ Training model for flare class M with 24h window\n",
      "Epoch 1/300 - loss: 0.1543 - acc: 0.9412 - tss: 0.0094 - gamma: 0.00\n",
      "Epoch 2/300 - loss: 0.1371 - acc: 0.9419 - tss: 0.0317 - gamma: 0.04\n",
      "Epoch 3/300 - loss: 0.1239 - acc: 0.9425 - tss: 0.0628 - gamma: 0.08\n",
      "Epoch 4/300 - loss: 0.1113 - acc: 0.9445 - tss: 0.1340 - gamma: 0.12\n",
      "Epoch 5/300 - loss: 0.1004 - acc: 0.9467 - tss: 0.1852 - gamma: 0.16\n",
      "Epoch 6/300 - loss: 0.0908 - acc: 0.9490 - tss: 0.2432 - gamma: 0.20\n",
      "Epoch 7/300 - loss: 0.0808 - acc: 0.9527 - tss: 0.3457 - gamma: 0.24\n",
      "Epoch 8/300 - loss: 0.0724 - acc: 0.9561 - tss: 0.4110 - gamma: 0.28\n",
      "Epoch 9/300 - loss: 0.0654 - acc: 0.9587 - tss: 0.4662 - gamma: 0.32\n",
      "Epoch 10/300 - loss: 0.0594 - acc: 0.9618 - tss: 0.5158 - gamma: 0.36\n",
      "Epoch 11/300 - loss: 0.0541 - acc: 0.9639 - tss: 0.5508 - gamma: 0.40\n",
      "Epoch 12/300 - loss: 0.0500 - acc: 0.9659 - tss: 0.5874 - gamma: 0.44\n",
      "Epoch 13/300 - loss: 0.0459 - acc: 0.9673 - tss: 0.6084 - gamma: 0.48\n",
      "Epoch 14/300 - loss: 0.0428 - acc: 0.9690 - tss: 0.6290 - gamma: 0.52\n",
      "Epoch 15/300 - loss: 0.0397 - acc: 0.9705 - tss: 0.6520 - gamma: 0.56\n",
      "Epoch 16/300 - loss: 0.0373 - acc: 0.9714 - tss: 0.6693 - gamma: 0.60\n",
      "Epoch 17/300 - loss: 0.0347 - acc: 0.9723 - tss: 0.6787 - gamma: 0.64\n",
      "Epoch 18/300 - loss: 0.0326 - acc: 0.9737 - tss: 0.7014 - gamma: 0.68\n",
      "Epoch 19/300 - loss: 0.0306 - acc: 0.9745 - tss: 0.7105 - gamma: 0.72\n",
      "Epoch 20/300 - loss: 0.0291 - acc: 0.9748 - tss: 0.7182 - gamma: 0.76\n",
      "Epoch 21/300 - loss: 0.0276 - acc: 0.9756 - tss: 0.7304 - gamma: 0.80\n",
      "Epoch 22/300 - loss: 0.0261 - acc: 0.9763 - tss: 0.7407 - gamma: 0.84\n",
      "Epoch 23/300 - loss: 0.0247 - acc: 0.9771 - tss: 0.7449 - gamma: 0.88\n",
      "Epoch 24/300 - loss: 0.0236 - acc: 0.9775 - tss: 0.7534 - gamma: 0.92\n",
      "Epoch 25/300 - loss: 0.0223 - acc: 0.9780 - tss: 0.7589 - gamma: 0.96\n",
      "Epoch 26/300 - loss: 0.0214 - acc: 0.9785 - tss: 0.7634 - gamma: 1.00\n",
      "Epoch 27/300 - loss: 0.0204 - acc: 0.9789 - tss: 0.7719 - gamma: 1.04\n",
      "Epoch 28/300 - loss: 0.0195 - acc: 0.9794 - tss: 0.7754 - gamma: 1.08\n",
      "Epoch 29/300 - loss: 0.0188 - acc: 0.9796 - tss: 0.7769 - gamma: 1.12\n",
      "Epoch 30/300 - loss: 0.0181 - acc: 0.9800 - tss: 0.7816 - gamma: 1.16\n",
      "Epoch 31/300 - loss: 0.0171 - acc: 0.9804 - tss: 0.7874 - gamma: 1.20\n",
      "Epoch 32/300 - loss: 0.0164 - acc: 0.9806 - tss: 0.7913 - gamma: 1.24\n",
      "Epoch 33/300 - loss: 0.0159 - acc: 0.9807 - tss: 0.7958 - gamma: 1.28\n",
      "Epoch 34/300 - loss: 0.0150 - acc: 0.9816 - tss: 0.8036 - gamma: 1.32\n",
      "Epoch 35/300 - loss: 0.0146 - acc: 0.9817 - tss: 0.8054 - gamma: 1.36\n",
      "Epoch 36/300 - loss: 0.0140 - acc: 0.9822 - tss: 0.8117 - gamma: 1.40\n",
      "Epoch 37/300 - loss: 0.0136 - acc: 0.9820 - tss: 0.8099 - gamma: 1.44\n",
      "Epoch 38/300 - loss: 0.0131 - acc: 0.9823 - tss: 0.8129 - gamma: 1.48\n",
      "Epoch 39/300 - loss: 0.0124 - acc: 0.9829 - tss: 0.8221 - gamma: 1.52\n",
      "Epoch 40/300 - loss: 0.0120 - acc: 0.9829 - tss: 0.8194 - gamma: 1.56\n",
      "Epoch 41/300 - loss: 0.0115 - acc: 0.9833 - tss: 0.8257 - gamma: 1.60\n",
      "Epoch 42/300 - loss: 0.0112 - acc: 0.9832 - tss: 0.8254 - gamma: 1.64\n",
      "Epoch 43/300 - loss: 0.0108 - acc: 0.9835 - tss: 0.8307 - gamma: 1.68\n",
      "Epoch 44/300 - loss: 0.0105 - acc: 0.9835 - tss: 0.8271 - gamma: 1.72\n",
      "Epoch 45/300 - loss: 0.0100 - acc: 0.9840 - tss: 0.8317 - gamma: 1.76\n",
      "Epoch 46/300 - loss: 0.0096 - acc: 0.9839 - tss: 0.8325 - gamma: 1.80\n",
      "Epoch 47/300 - loss: 0.0095 - acc: 0.9842 - tss: 0.8340 - gamma: 1.84\n",
      "Epoch 48/300 - loss: 0.0090 - acc: 0.9845 - tss: 0.8398 - gamma: 1.88\n",
      "Epoch 49/300 - loss: 0.0087 - acc: 0.9846 - tss: 0.8407 - gamma: 1.92\n",
      "Epoch 50/300 - loss: 0.0085 - acc: 0.9845 - tss: 0.8402 - gamma: 1.96\n",
      "Epoch 51/300 - loss: 0.0082 - acc: 0.9849 - tss: 0.8438 - gamma: 2.00\n",
      "Epoch 52/300 - loss: 0.0081 - acc: 0.9849 - tss: 0.8409 - gamma: 2.00\n",
      "Epoch 53/300 - loss: 0.0081 - acc: 0.9852 - tss: 0.8476 - gamma: 2.00\n",
      "Epoch 54/300 - loss: 0.0081 - acc: 0.9851 - tss: 0.8463 - gamma: 2.00\n",
      "Epoch 55/300 - loss: 0.0079 - acc: 0.9852 - tss: 0.8478 - gamma: 2.00\n",
      "Epoch 56/300 - loss: 0.0078 - acc: 0.9852 - tss: 0.8485 - gamma: 2.00\n",
      "Epoch 57/300 - loss: 0.0080 - acc: 0.9850 - tss: 0.8448 - gamma: 2.00\n",
      "Epoch 58/300 - loss: 0.0078 - acc: 0.9856 - tss: 0.8531 - gamma: 2.00\n",
      "Epoch 59/300 - loss: 0.0078 - acc: 0.9855 - tss: 0.8517 - gamma: 2.00\n",
      "Epoch 60/300 - loss: 0.0076 - acc: 0.9858 - tss: 0.8571 - gamma: 2.00\n",
      "Epoch 61/300 - loss: 0.0077 - acc: 0.9857 - tss: 0.8508 - gamma: 2.00\n",
      "Epoch 62/300 - loss: 0.0076 - acc: 0.9861 - tss: 0.8611 - gamma: 2.00\n",
      "Epoch 63/300 - loss: 0.0076 - acc: 0.9859 - tss: 0.8559 - gamma: 2.00\n",
      "Epoch 64/300 - loss: 0.0075 - acc: 0.9862 - tss: 0.8602 - gamma: 2.00\n",
      "Epoch 65/300 - loss: 0.0075 - acc: 0.9863 - tss: 0.8615 - gamma: 2.00\n",
      "Epoch 66/300 - loss: 0.0073 - acc: 0.9865 - tss: 0.8634 - gamma: 2.00\n",
      "Epoch 67/300 - loss: 0.0073 - acc: 0.9865 - tss: 0.8629 - gamma: 2.00\n",
      "Epoch 68/300 - loss: 0.0073 - acc: 0.9866 - tss: 0.8597 - gamma: 2.00\n",
      "Epoch 69/300 - loss: 0.0072 - acc: 0.9867 - tss: 0.8640 - gamma: 2.00\n",
      "Epoch 70/300 - loss: 0.0072 - acc: 0.9868 - tss: 0.8678 - gamma: 2.00\n",
      "Epoch 71/300 - loss: 0.0072 - acc: 0.9870 - tss: 0.8687 - gamma: 2.00\n",
      "Epoch 72/300 - loss: 0.0072 - acc: 0.9868 - tss: 0.8671 - gamma: 2.00\n",
      "Epoch 73/300 - loss: 0.0070 - acc: 0.9872 - tss: 0.8677 - gamma: 2.00\n",
      "Epoch 74/300 - loss: 0.0070 - acc: 0.9874 - tss: 0.8734 - gamma: 2.00\n",
      "Epoch 75/300 - loss: 0.0069 - acc: 0.9873 - tss: 0.8702 - gamma: 2.00\n",
      "Epoch 76/300 - loss: 0.0070 - acc: 0.9874 - tss: 0.8689 - gamma: 2.00\n",
      "Epoch 77/300 - loss: 0.0068 - acc: 0.9876 - tss: 0.8744 - gamma: 2.00\n",
      "Epoch 78/300 - loss: 0.0067 - acc: 0.9877 - tss: 0.8749 - gamma: 2.00\n",
      "Epoch 79/300 - loss: 0.0067 - acc: 0.9876 - tss: 0.8735 - gamma: 2.00\n",
      "Epoch 80/300 - loss: 0.0067 - acc: 0.9876 - tss: 0.8713 - gamma: 2.00\n",
      "Epoch 81/300 - loss: 0.0067 - acc: 0.9876 - tss: 0.8759 - gamma: 2.00\n",
      "Epoch 82/300 - loss: 0.0066 - acc: 0.9879 - tss: 0.8780 - gamma: 2.00\n",
      "Epoch 83/300 - loss: 0.0066 - acc: 0.9878 - tss: 0.8752 - gamma: 2.00\n",
      "Epoch 84/300 - loss: 0.0066 - acc: 0.9877 - tss: 0.8741 - gamma: 2.00\n",
      "Epoch 85/300 - loss: 0.0066 - acc: 0.9880 - tss: 0.8756 - gamma: 2.00\n",
      "Epoch 86/300 - loss: 0.0066 - acc: 0.9876 - tss: 0.8755 - gamma: 2.00\n",
      "Epoch 87/300 - loss: 0.0066 - acc: 0.9879 - tss: 0.8798 - gamma: 2.00\n",
      "Epoch 88/300 - loss: 0.0066 - acc: 0.9882 - tss: 0.8813 - gamma: 2.00\n",
      "Epoch 89/300 - loss: 0.0066 - acc: 0.9880 - tss: 0.8799 - gamma: 2.00\n",
      "Epoch 90/300 - loss: 0.0065 - acc: 0.9885 - tss: 0.8824 - gamma: 2.00\n",
      "Epoch 91/300 - loss: 0.0064 - acc: 0.9883 - tss: 0.8815 - gamma: 2.00\n",
      "Epoch 92/300 - loss: 0.0065 - acc: 0.9882 - tss: 0.8828 - gamma: 2.00\n",
      "Epoch 93/300 - loss: 0.0064 - acc: 0.9886 - tss: 0.8844 - gamma: 2.00\n",
      "Epoch 94/300 - loss: 0.0063 - acc: 0.9885 - tss: 0.8853 - gamma: 2.00\n",
      "Epoch 95/300 - loss: 0.0064 - acc: 0.9885 - tss: 0.8851 - gamma: 2.00\n",
      "Epoch 96/300 - loss: 0.0063 - acc: 0.9887 - tss: 0.8847 - gamma: 2.00\n",
      "Epoch 97/300 - loss: 0.0063 - acc: 0.9886 - tss: 0.8849 - gamma: 2.00\n",
      "Epoch 98/300 - loss: 0.0063 - acc: 0.9889 - tss: 0.8885 - gamma: 2.00\n",
      "Epoch 99/300 - loss: 0.0063 - acc: 0.9888 - tss: 0.8860 - gamma: 2.00\n",
      "Epoch 100/300 - loss: 0.0063 - acc: 0.9887 - tss: 0.8815 - gamma: 2.00\n",
      "Epoch 101/300 - loss: 0.0062 - acc: 0.9889 - tss: 0.8885 - gamma: 2.00\n",
      "Epoch 102/300 - loss: 0.0062 - acc: 0.9887 - tss: 0.8875 - gamma: 2.00\n",
      "Epoch 103/300 - loss: 0.0061 - acc: 0.9890 - tss: 0.8891 - gamma: 2.00\n",
      "Epoch 104/300 - loss: 0.0060 - acc: 0.9892 - tss: 0.8918 - gamma: 2.00\n",
      "Epoch 112/300 - loss: 0.0059 - acc: 0.9896 - tss: 0.8954 - gamma: 2.00\n",
      "Epoch 113/300 - loss: 0.0059 - acc: 0.9894 - tss: 0.8935 - gamma: 2.00\n",
      "Epoch 114/300 - loss: 0.0059 - acc: 0.9896 - tss: 0.8955 - gamma: 2.00\n",
      "Epoch 115/300 - loss: 0.0058 - acc: 0.9895 - tss: 0.8951 - gamma: 2.00\n",
      "Epoch 116/300 - loss: 0.0057 - acc: 0.9898 - tss: 0.8948 - gamma: 2.00\n",
      "Epoch 117/300 - loss: 0.0057 - acc: 0.9898 - tss: 0.8979 - gamma: 2.00\n",
      "Epoch 118/300 - loss: 0.0057 - acc: 0.9896 - tss: 0.8946 - gamma: 2.00\n",
      "Epoch 119/300 - loss: 0.0056 - acc: 0.9896 - tss: 0.8951 - gamma: 2.00\n",
      "Epoch 120/300 - loss: 0.0059 - acc: 0.9896 - tss: 0.8934 - gamma: 2.00\n",
      "Epoch 121/300 - loss: 0.0057 - acc: 0.9896 - tss: 0.8948 - gamma: 2.00\n",
      "Epoch 122/300 - loss: 0.0057 - acc: 0.9896 - tss: 0.8943 - gamma: 2.00\n",
      "Epoch 123/300 - loss: 0.0056 - acc: 0.9900 - tss: 0.8974 - gamma: 2.00\n",
      "Epoch 124/300 - loss: 0.0056 - acc: 0.9898 - tss: 0.8956 - gamma: 2.00\n",
      "Epoch 125/300 - loss: 0.0055 - acc: 0.9901 - tss: 0.9018 - gamma: 2.00\n",
      "Epoch 126/300 - loss: 0.0056 - acc: 0.9899 - tss: 0.8962 - gamma: 2.00\n",
      "Epoch 127/300 - loss: 0.0056 - acc: 0.9899 - tss: 0.8974 - gamma: 2.00\n",
      "Epoch 128/300 - loss: 0.0056 - acc: 0.9900 - tss: 0.8982 - gamma: 2.00\n",
      "Epoch 129/300 - loss: 0.0055 - acc: 0.9899 - tss: 0.8971 - gamma: 2.00\n",
      "Epoch 130/300 - loss: 0.0057 - acc: 0.9898 - tss: 0.8964 - gamma: 2.00\n",
      "Epoch 131/300 - loss: 0.0055 - acc: 0.9900 - tss: 0.8991 - gamma: 2.00\n",
      "Epoch 132/300 - loss: 0.0054 - acc: 0.9903 - tss: 0.9029 - gamma: 2.00\n",
      "Epoch 133/300 - loss: 0.0055 - acc: 0.9903 - tss: 0.9015 - gamma: 2.00\n",
      "Epoch 134/300 - loss: 0.0054 - acc: 0.9903 - tss: 0.9015 - gamma: 2.00\n",
      "Epoch 135/300 - loss: 0.0057 - acc: 0.9900 - tss: 0.8991 - gamma: 2.00\n",
      "Epoch 136/300 - loss: 0.0055 - acc: 0.9904 - tss: 0.9044 - gamma: 2.00\n",
      "Epoch 137/300 - loss: 0.0054 - acc: 0.9902 - tss: 0.8996 - gamma: 2.00\n",
      "Epoch 138/300 - loss: 0.0054 - acc: 0.9903 - tss: 0.9035 - gamma: 2.00\n",
      "Epoch 139/300 - loss: 0.0056 - acc: 0.9899 - tss: 0.8992 - gamma: 2.00\n",
      "Epoch 140/300 - loss: 0.0054 - acc: 0.9903 - tss: 0.9020 - gamma: 2.00\n",
      "Epoch 141/300 - loss: 0.0052 - acc: 0.9907 - tss: 0.9040 - gamma: 2.00\n",
      "Epoch 142/300 - loss: 0.0054 - acc: 0.9904 - tss: 0.9024 - gamma: 2.00\n",
      "Epoch 143/300 - loss: 0.0054 - acc: 0.9905 - tss: 0.9030 - gamma: 2.00\n",
      "Epoch 144/300 - loss: 0.0054 - acc: 0.9904 - tss: 0.9030 - gamma: 2.00\n",
      "Epoch 145/300 - loss: 0.0053 - acc: 0.9905 - tss: 0.9040 - gamma: 2.00\n",
      "Epoch 146/300 - loss: 0.0053 - acc: 0.9907 - tss: 0.9055 - gamma: 2.00\n",
      "Epoch 147/300 - loss: 0.0053 - acc: 0.9906 - tss: 0.9044 - gamma: 2.00\n",
      "Epoch 148/300 - loss: 0.0052 - acc: 0.9906 - tss: 0.9070 - gamma: 2.00\n",
      "Epoch 149/300 - loss: 0.0052 - acc: 0.9907 - tss: 0.9054 - gamma: 2.00\n",
      "Epoch 150/300 - loss: 0.0052 - acc: 0.9907 - tss: 0.9048 - gamma: 2.00\n",
      "Epoch 151/300 - loss: 0.0053 - acc: 0.9906 - tss: 0.9043 - gamma: 2.00\n",
      "Epoch 152/300 - loss: 0.0051 - acc: 0.9910 - tss: 0.9096 - gamma: 2.00\n",
      "Epoch 153/300 - loss: 0.0052 - acc: 0.9907 - tss: 0.9072 - gamma: 2.00\n",
      "Epoch 154/300 - loss: 0.0052 - acc: 0.9908 - tss: 0.9064 - gamma: 2.00\n",
      "Epoch 155/300 - loss: 0.0052 - acc: 0.9908 - tss: 0.9074 - gamma: 2.00\n",
      "Epoch 156/300 - loss: 0.0052 - acc: 0.9908 - tss: 0.9062 - gamma: 2.00\n",
      "Epoch 157/300 - loss: 0.0051 - acc: 0.9910 - tss: 0.9088 - gamma: 2.00\n",
      "Epoch 158/300 - loss: 0.0052 - acc: 0.9909 - tss: 0.9083 - gamma: 2.00\n",
      "Epoch 159/300 - loss: 0.0051 - acc: 0.9908 - tss: 0.9059 - gamma: 2.00\n",
      "Epoch 160/300 - loss: 0.0051 - acc: 0.9910 - tss: 0.9092 - gamma: 2.00\n",
      "Epoch 161/300 - loss: 0.0052 - acc: 0.9909 - tss: 0.9084 - gamma: 2.00\n",
      "Epoch 162/300 - loss: 0.0051 - acc: 0.9909 - tss: 0.9094 - gamma: 2.00\n",
      "Early stopping triggered at epoch 162. Restoring best model from epoch 152.\n",
      "Model saved to models/SolarKnowledge-v2.1-M-24h\n",
      "Model saved to models/SolarKnowledge-vretplus_weights_M_24.pt-M-24h\n",
      "âœ… Saved model to retplus_weights_M_24.pt\n",
      "------------------------------------------------------------\n",
      "ðŸš€ Training model for flare class M with 48h window\n",
      "Epoch 1/300 - loss: 0.1394 - acc: 0.9469 - tss: 0.0055 - gamma: 0.00\n",
      "Epoch 2/300 - loss: 0.1211 - acc: 0.9480 - tss: 0.0293 - gamma: 0.04\n",
      "Epoch 3/300 - loss: 0.1075 - acc: 0.9500 - tss: 0.1030 - gamma: 0.08\n",
      "Epoch 4/300 - loss: 0.0953 - acc: 0.9527 - tss: 0.1653 - gamma: 0.12\n",
      "Epoch 10/300 - loss: 0.0503 - acc: 0.9674 - tss: 0.5184 - gamma: 0.36\n",
      "Epoch 11/300 - loss: 0.0467 - acc: 0.9689 - tss: 0.5546 - gamma: 0.40\n",
      "Epoch 12/300 - loss: 0.0431 - acc: 0.9705 - tss: 0.5866 - gamma: 0.44\n",
      "Epoch 13/300 - loss: 0.0390 - acc: 0.9727 - tss: 0.6285 - gamma: 0.48\n",
      "Epoch 14/300 - loss: 0.0360 - acc: 0.9740 - tss: 0.6506 - gamma: 0.52\n",
      "Epoch 15/300 - loss: 0.0332 - acc: 0.9753 - tss: 0.6747 - gamma: 0.56\n",
      "Epoch 16/300 - loss: 0.0311 - acc: 0.9760 - tss: 0.6926 - gamma: 0.60\n",
      "Epoch 17/300 - loss: 0.0291 - acc: 0.9770 - tss: 0.7086 - gamma: 0.64\n",
      "Epoch 18/300 - loss: 0.0277 - acc: 0.9778 - tss: 0.7188 - gamma: 0.68\n",
      "Epoch 19/300 - loss: 0.0257 - acc: 0.9788 - tss: 0.7353 - gamma: 0.72\n",
      "Epoch 20/300 - loss: 0.0242 - acc: 0.9795 - tss: 0.7460 - gamma: 0.76\n",
      "Epoch 21/300 - loss: 0.0229 - acc: 0.9802 - tss: 0.7571 - gamma: 0.80\n",
      "Epoch 22/300 - loss: 0.0218 - acc: 0.9804 - tss: 0.7629 - gamma: 0.84\n",
      "Epoch 23/300 - loss: 0.0209 - acc: 0.9810 - tss: 0.7694 - gamma: 0.88\n",
      "Epoch 24/300 - loss: 0.0197 - acc: 0.9816 - tss: 0.7765 - gamma: 0.92\n",
      "Epoch 25/300 - loss: 0.0189 - acc: 0.9818 - tss: 0.7824 - gamma: 0.96\n",
      "Epoch 26/300 - loss: 0.0179 - acc: 0.9822 - tss: 0.7859 - gamma: 1.00\n",
      "Epoch 27/300 - loss: 0.0172 - acc: 0.9825 - tss: 0.7884 - gamma: 1.04\n",
      "Epoch 28/300 - loss: 0.0165 - acc: 0.9828 - tss: 0.7926 - gamma: 1.08\n",
      "Epoch 29/300 - loss: 0.0158 - acc: 0.9832 - tss: 0.7994 - gamma: 1.12\n",
      "Epoch 30/300 - loss: 0.0152 - acc: 0.9834 - tss: 0.8030 - gamma: 1.16\n",
      "Epoch 31/300 - loss: 0.0145 - acc: 0.9838 - tss: 0.8092 - gamma: 1.20\n",
      "Epoch 32/300 - loss: 0.0139 - acc: 0.9841 - tss: 0.8120 - gamma: 1.24\n",
      "Epoch 33/300 - loss: 0.0134 - acc: 0.9841 - tss: 0.8100 - gamma: 1.28\n",
      "Epoch 34/300 - loss: 0.0128 - acc: 0.9846 - tss: 0.8184 - gamma: 1.32\n",
      "Epoch 35/300 - loss: 0.0122 - acc: 0.9849 - tss: 0.8205 - gamma: 1.36\n",
      "Epoch 36/300 - loss: 0.0119 - acc: 0.9851 - tss: 0.8267 - gamma: 1.40\n",
      "Epoch 37/300 - loss: 0.0117 - acc: 0.9847 - tss: 0.8242 - gamma: 1.44\n",
      "Epoch 38/300 - loss: 0.0110 - acc: 0.9854 - tss: 0.8290 - gamma: 1.48\n",
      "Epoch 39/300 - loss: 0.0106 - acc: 0.9858 - tss: 0.8361 - gamma: 1.52\n",
      "Epoch 40/300 - loss: 0.0102 - acc: 0.9857 - tss: 0.8328 - gamma: 1.56\n",
      "Epoch 41/300 - loss: 0.0100 - acc: 0.9859 - tss: 0.8371 - gamma: 1.60\n",
      "Epoch 42/300 - loss: 0.0096 - acc: 0.9860 - tss: 0.8391 - gamma: 1.64\n",
      "Epoch 43/300 - loss: 0.0093 - acc: 0.9862 - tss: 0.8434 - gamma: 1.68\n",
      "Epoch 44/300 - loss: 0.0092 - acc: 0.9860 - tss: 0.8386 - gamma: 1.72\n",
      "Epoch 45/300 - loss: 0.0086 - acc: 0.9865 - tss: 0.8428 - gamma: 1.76\n",
      "Epoch 46/300 - loss: 0.0084 - acc: 0.9865 - tss: 0.8442 - gamma: 1.80\n",
      "Epoch 47/300 - loss: 0.0081 - acc: 0.9868 - tss: 0.8487 - gamma: 1.84\n",
      "Epoch 48/300 - loss: 0.0078 - acc: 0.9867 - tss: 0.8462 - gamma: 1.88\n",
      "Epoch 49/300 - loss: 0.0075 - acc: 0.9869 - tss: 0.8475 - gamma: 1.92\n",
      "Epoch 50/300 - loss: 0.0074 - acc: 0.9869 - tss: 0.8485 - gamma: 1.96\n",
      "Epoch 51/300 - loss: 0.0072 - acc: 0.9868 - tss: 0.8462 - gamma: 2.00\n",
      "Epoch 52/300 - loss: 0.0070 - acc: 0.9873 - tss: 0.8543 - gamma: 2.00\n",
      "Epoch 53/300 - loss: 0.0070 - acc: 0.9871 - tss: 0.8560 - gamma: 2.00\n",
      "Epoch 54/300 - loss: 0.0068 - acc: 0.9875 - tss: 0.8594 - gamma: 2.00\n",
      "Epoch 55/300 - loss: 0.0069 - acc: 0.9874 - tss: 0.8584 - gamma: 2.00\n",
      "Epoch 56/300 - loss: 0.0069 - acc: 0.9876 - tss: 0.8597 - gamma: 2.00\n",
      "Epoch 57/300 - loss: 0.0069 - acc: 0.9875 - tss: 0.8583 - gamma: 2.00\n",
      "Epoch 58/300 - loss: 0.0069 - acc: 0.9875 - tss: 0.8590 - gamma: 2.00\n",
      "Epoch 59/300 - loss: 0.0066 - acc: 0.9880 - tss: 0.8627 - gamma: 2.00\n",
      "Epoch 60/300 - loss: 0.0067 - acc: 0.9881 - tss: 0.8619 - gamma: 2.00\n",
      "Epoch 61/300 - loss: 0.0066 - acc: 0.9880 - tss: 0.8655 - gamma: 2.00\n",
      "Epoch 62/300 - loss: 0.0066 - acc: 0.9883 - tss: 0.8642 - gamma: 2.00\n",
      "Epoch 63/300 - loss: 0.0065 - acc: 0.9883 - tss: 0.8686 - gamma: 2.00\n",
      "Epoch 64/300 - loss: 0.0065 - acc: 0.9882 - tss: 0.8678 - gamma: 2.00\n",
      "Epoch 65/300 - loss: 0.0065 - acc: 0.9883 - tss: 0.8694 - gamma: 2.00\n",
      "Epoch 66/300 - loss: 0.0065 - acc: 0.9883 - tss: 0.8662 - gamma: 2.00\n",
      "Epoch 67/300 - loss: 0.0064 - acc: 0.9886 - tss: 0.8713 - gamma: 2.00\n",
      "Epoch 68/300 - loss: 0.0064 - acc: 0.9884 - tss: 0.8700 - gamma: 2.00\n",
      "Epoch 69/300 - loss: 0.0063 - acc: 0.9887 - tss: 0.8705 - gamma: 2.00\n",
      "Epoch 70/300 - loss: 0.0063 - acc: 0.9885 - tss: 0.8688 - gamma: 2.00\n",
      "Epoch 71/300 - loss: 0.0062 - acc: 0.9891 - tss: 0.8759 - gamma: 2.00\n",
      "Epoch 72/300 - loss: 0.0062 - acc: 0.9890 - tss: 0.8753 - gamma: 2.00\n",
      "Epoch 73/300 - loss: 0.0062 - acc: 0.9889 - tss: 0.8768 - gamma: 2.00\n",
      "Epoch 74/300 - loss: 0.0061 - acc: 0.9891 - tss: 0.8811 - gamma: 2.00\n",
      "Epoch 75/300 - loss: 0.0062 - acc: 0.9890 - tss: 0.8768 - gamma: 2.00\n",
      "Epoch 76/300 - loss: 0.0061 - acc: 0.9891 - tss: 0.8771 - gamma: 2.00\n",
      "Epoch 77/300 - loss: 0.0060 - acc: 0.9894 - tss: 0.8790 - gamma: 2.00\n",
      "Epoch 78/300 - loss: 0.0060 - acc: 0.9894 - tss: 0.8796 - gamma: 2.00\n",
      "Epoch 79/300 - loss: 0.0060 - acc: 0.9894 - tss: 0.8831 - gamma: 2.00\n",
      "Epoch 80/300 - loss: 0.0060 - acc: 0.9893 - tss: 0.8806 - gamma: 2.00\n",
      "Epoch 81/300 - loss: 0.0059 - acc: 0.9897 - tss: 0.8841 - gamma: 2.00\n",
      "Epoch 82/300 - loss: 0.0059 - acc: 0.9897 - tss: 0.8858 - gamma: 2.00\n",
      "Epoch 83/300 - loss: 0.0059 - acc: 0.9897 - tss: 0.8826 - gamma: 2.00\n",
      "Epoch 84/300 - loss: 0.0059 - acc: 0.9897 - tss: 0.8844 - gamma: 2.00\n",
      "Epoch 85/300 - loss: 0.0058 - acc: 0.9897 - tss: 0.8837 - gamma: 2.00\n",
      "Epoch 86/300 - loss: 0.0058 - acc: 0.9898 - tss: 0.8839 - gamma: 2.00\n",
      "Epoch 87/300 - loss: 0.0058 - acc: 0.9898 - tss: 0.8879 - gamma: 2.00\n",
      "Epoch 88/300 - loss: 0.0057 - acc: 0.9898 - tss: 0.8851 - gamma: 2.00\n"
     ]
    }
   ],
   "source": [
    "# Training RET+ Models for Solar Flare Prediction (C, M, M5 Ã— 24, 48, 72)\n",
    "\n",
    "from solarknowledge_ret_plus import RETPlusWrapper\n",
    "from utils import get_training_data, supported_flare_class\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "flare_classes = [\"M\"] # C, and M5 taken out temporarily\n",
    "time_windows = [\"48\", \"72\"] # M has already been trained on 24hrs\n",
    "input_shape = (10, 9)\n",
    "epochs = 300\n",
    "batch_size = 512\n",
    "\n",
    "# --- Loop over all class Ã— horizon combinations ---\n",
    "for flare_class in flare_classes:\n",
    "    for time_window in time_windows:\n",
    "        print(f\"ðŸš€ Training model for flare class {flare_class} with {time_window}h window\")\n",
    "\n",
    "        # Path to save the model\n",
    "        model_path = f\"retplus_weights_{flare_class}_{time_window}.pt\"\n",
    "\n",
    "        # Load & prepare training data\n",
    "        X_train, y_train = get_training_data(time_window, flare_class)\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        # Initialize and train model\n",
    "        model = RETPlusWrapper(input_shape)\n",
    "        model.train(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "        # Save trained weights\n",
    "        model.save(model_path, flare_class, time_window)\n",
    "        print(f\"âœ… Saved model to {model_path}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382e69c-4ef5-4295-ad4d-85ee51281e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RET+ testing block\n",
    "\n",
    "from solarknowledge_ret_plus import RETPlusWrapper\n",
    "from utils import get_testing_data\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Config\n",
    "flare_class = \"M5\"\n",
    "time_window = \"72\"\n",
    "input_shape = (10, 9)\n",
    "model_path = f\"retplus_weights_{flare_class}_{time_window}.pt\"\n",
    "mc_passes = 30\n",
    "threshold = 0.5\n",
    "\n",
    "# Load test data\n",
    "X_test, y_test = get_training_data(time_window, flare_class)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Load model\n",
    "model = RETPlusWrapper(input_shape)\n",
    "model.load(model_path)\n",
    "\n",
    "# MC prediction\n",
    "probs = model.predict_proba(X_test)\n",
    "y_pred = (probs >= threshold).astype(int).squeeze()\n",
    "\n",
    "# Metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "tss = rec + cm[0,0] / (cm[0,0] + cm[0,1] + 1e-8) - 1\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"TSS:       {tss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbd96f-4661-46d8-af7f-fcb80cbf90ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EVEREST Environment",
   "language": "python",
   "name": "everest_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
