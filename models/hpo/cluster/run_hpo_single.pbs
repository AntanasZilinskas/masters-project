#!/bin/bash
#PBS -l select=1:ncpus=8:mem=64gb:ngpus=1:gpu_type=L40S
#PBS -l walltime=24:00:00
#PBS -N hpo_single
#PBS -o hpo_single_${FLARE_CLASS}_${TIME_WINDOW}.out
#PBS -e hpo_single_${FLARE_CLASS}_${TIME_WINDOW}.err

# Load required modules
module load tools/prod
module load Python/3.12.3-GCCcore-13.3.0
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1

# Change to submission directory
cd $PBS_O_WORKDIR

# Activate virtual environment
source venv_hpo/bin/activate

# Set environment variables for GPU
export CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES
export TORCH_CUDA_ARCH_LIST="8.9"  # For L40S GPU

# Copy data to local storage if large datasets
# Uncomment and modify if you have large datasets
# echo "Copying data to $TMPDIR..."
# cp -r data/ $TMPDIR/
# export DATA_PATH=$TMPDIR/data

# Default values if not set as environment variables
FLARE_CLASS=${FLARE_CLASS:-"M"}
TIME_WINDOW=${TIME_WINDOW:-24}
MAX_TRIALS=${MAX_TRIALS:-166}

echo "Starting HPO optimization for ${FLARE_CLASS} class, ${TIME_WINDOW}h window"
echo "Using GPU: $CUDA_VISIBLE_DEVICES"
echo "Max trials: $MAX_TRIALS"

# Run HPO optimization
python models/hpo/run_hpo.py \
    --target single \
    --flare-class $FLARE_CLASS \
    --time-window $TIME_WINDOW \
    --max-trials $MAX_TRIALS \
    --timeout 82800 \
    --study-name "hpo_${FLARE_CLASS}_${TIME_WINDOW}h_$(date +%Y%m%d_%H%M%S)" \
    --output-dir results/hpo_${FLARE_CLASS}_${TIME_WINDOW}h

# Copy results back if using TMPDIR
# if [ -n "$DATA_PATH" ]; then
#     echo "Copying results back..."
#     cp -r results/ $PBS_O_WORKDIR/
# fi

echo "HPO optimization completed for ${FLARE_CLASS} class, ${TIME_WINDOW}h window" 