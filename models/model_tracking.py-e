'''
Model Tracking and Management for SolarKnowledge

This module provides tools for tracking model versions, saving metadata,
generating model cards, and maintaining a structured model directory.
'''

import os
import json
import csv
import shutil
import subprocess
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf

# Ensure the models/trained_models directory exists
os.makedirs("models/trained_models", exist_ok=True)

def create_model_dir(version, flare_class, time_window):
    """Create a standardized model directory structure."""
    model_dir = f"models/trained_models/SolarKnowledge-v{version}-{flare_class}-{time_window}h"
    os.makedirs(model_dir, exist_ok=True)
    return model_dir

def get_git_info():
    """Get information about the current Git repository."""
    git_info = {
        "commit": "unknown",
        "branch": "unknown"
    }
    
    try:
            # Check if git is installed and we're in a git repository
        import subprocess
        
        # Get current commit hash
        process = subprocess.run(
            ["git", "rev-parse", "HEAD"],
            capture_output=True,
            text=True,
            check=False
        )
        if process.returncode == 0:
            git_info["commit"] = process.stdout.strip()
        
        # Get current branch
        process = subprocess.run(
            ["git", "rev-parse", "--abbrev-ref", "HEAD"],
            capture_output=True,
            text=True,
            check=False
        )
        if process.returncode == 0:
            git_info["branch"] = process.stdout.strip()
            
    except Exception as e:
        print(f"Error getting git info: {e}")
    
    return git_info

def save_model_with_metadata(model, metrics, hyperparams, history, version, flare_class, time_window, description=None):
    """
    Save model weights along with performance metrics, hyperparameters, and history.
    
    Args:
        model: Trained model object
        metrics: Dictionary of performance metrics
        hyperparams: Dictionary of hyperparameters
        history: Training history object
        version: Model version string/number
        flare_class: Flare class string (e.g., "M5")
        time_window: Time window in hours
        description: Optional model description
        
    Returns:
        Path to saved model directory
    """
    # Create directory structure for trained models
    model_dir = os.path.join("models", "trained_models", f"{model.model_name}-v{version}-{flare_class}-{time_window}h")
    os.makedirs(model_dir, exist_ok=True)
    
    # Save model weights
    model.save_weights(flare_class, model_dir)
    
    # Convert history object to dictionary if it's not already
    if not isinstance(history, dict) and hasattr(history, 'history'):
        history_dict = history.history
    else:
        history_dict = history
    
    # Get git information
    git_info = get_git_info()
    
    # Determine model architecture details
    architecture = {
        "name": model.model_name,
        "input_shape": list(model.model.input_shape[1:]) if model.model.input_shape else None,
        "num_params": model.model.count_params(),
        "precision": str(tf.keras.mixed_precision.global_policy())
    }
    
    # Create metadata with all information
    metadata = {
        "version": version,
        "timestamp": datetime.now().isoformat(),
        "model_name": model.model_name,
        "flare_class": flare_class,
        "time_window": time_window,
        "description": description or f"Model for {flare_class}-class flares with {time_window}h window",
        "hyperparameters": hyperparams,
        "performance": metrics,
        "git_info": git_info,
        "architecture": architecture,
        "history_keys": list(history_dict.keys()) if history_dict else []
    }
    
    # Save metadata to JSON file
    with open(os.path.join(model_dir, "metadata.json"), "w") as f:
        json.dump(metadata, f, indent=2)
    
    # Save history data separately (can be large)
    if history_dict:
        np.save(os.path.join(model_dir, "history.npy"), history_dict)
        
        # Also save as CSV for better compatibility
        save_training_history(history_dict, model_dir)
    
    # Generate model card
    generate_model_card(metadata, metrics, model_dir)
    
    return model_dir

def save_training_history(history, model_dir):
    """
    Save training history as CSV and generate learning curves plot.
    
    Args:
        history: Training history dictionary or History object
        model_dir: Directory to save the files
    """
    # Convert to dictionary if it's a History object
    if not isinstance(history, dict) and hasattr(history, 'history'):
        history = history.history
    
    # Skip if history is empty
    if not history:
        print("No training history to save")
        return
    
    # Find minimum length across all history entries
    min_epochs = min(len(value) for value in history.values())
    
        plt.figure(figsize=(12, 5))
	# Save as CSV
	try:
		with open(os.path.join(model_dir, "training_history.csv"), "w", newline="") as f:
			writer = csv.writer(f)
			# Write header
			writer.writerow(["epoch"] + list(history.keys()))
			# Write data - only up to the minimum length
			for epoch in range(min_epochs):
				writer.writerow([epoch] + [history[k][epoch] for k in history.keys()])
			print(f"Saved training history to {os.path.join(model_dir, "training_history.csv")}")
	except Exception as e:
		print(f"Error saving training history CSV: {e}")
        timestamp = datetime.fromisoformat(metadata["timestamp"]).strftime("%Y-%m-%d %H:%M")
        
        # Get model name, flare class and time window
        model_name = metadata.get("model_name", "EVEREST")
        flare_class = metadata.get("flare_class", "")
        time_window = metadata.get("time_window", "")
        
        # Format metrics for display (limit to 4 decimal places)
        metrics_text = ""
        for metric, value in metadata.get("performance", {}).items():
            if isinstance(value, (float, int)):
                metrics_text += f"- **{metric}**: {value:.4f}\n"
            else:
                metrics_text += f"- **{metric}**: {value}\n"
        
        # Get architecture info
        architecture = metadata.get("architecture", {})
        num_params = architecture.get("num_params", 0)
        precision = architecture.get("precision", "float32")
        input_shape = architecture.get("input_shape", [])
        
        # Create the model card content
        model_card = f"""# {model_name} Model v{metadata['version']}

## Overview
- **Created**: {timestamp}
- **Type**: Solar flare prediction model
- **Target**: {flare_class}-class flares
- **Time Window**: {time_window} hours

## Description
{metadata.get('description', '')}

## Performance Metrics
{metrics_text}

## Training Details
- **Architecture**: {model_name} {'Transformer ' if 'SolarKnowledge' in model_name else ''}Model
- **Parameters**: {num_params:,}
- **Precision**: {precision}
"""
        
        # Add hyperparameters section
        model_card += "\n## Hyperparameters\n"
        for param, value in metadata.get('hyperparameters', {}).items():
            model_card += f"- **{param}**: {value}\n"
        
        # Add version control info
        git_info = metadata.get('git_info', {})
        model_card += f"""
## Version Control
- **Git Commit**: {git_info.get('commit', 'unknown')}
- **Git Branch**: {git_info.get('branch', 'unknown')}

## Usage
```python
from {model_name.lower()}_model import {model_name}

# Load the model
model = {model_name}()
model.load_model(
    input_shape={input_shape}, 
    flare_class="{flare_class}", 
    w_dir="{os.path.basename(model_dir)}"
)

# Make predictions
predictions = model.predict(X_test)
```
"""
        
        # Write model card to file
        with open(os.path.join(model_dir, "model_card.md"), "w") as f:
            f.write(model_card)
            
    except Exception as e:
        print(f"Error generating model card: {e}")
        # Create a simplified model card as fallback
        simple_card = f"# {model_name} Model v{metadata.get('version', 'unknown')}\n\n"
        simple_card += f"- **Flare Class**: {flare_class}\n"
        simple_card += f"- **Time Window**: {time_window} hours\n"
        
        with open(os.path.join(model_dir, "model_card.md"), "w") as f:
            f.write(simple_card)

def load_model_metadata(version, flare_class, time_window):
    """Load metadata for a specific model version."""
    model_dir = create_model_dir(version, flare_class, time_window)
    metadata_path = os.path.join(model_dir, "metadata.json")
    
    if not os.path.exists(metadata_path):
        raise FileNotFoundError(f"No metadata found for model v{version}-{flare_class}-{time_window}h")
    
    with open(metadata_path, "r") as f:
        return json.load(f)

def list_available_models():
    """List all available models in the models directory."""
    models_dir = "models/trained_models"
    try:
        model_dirs = [d for d in os.listdir(models_dir) if d.startswith("SolarKnowledge-v")]
        models = []
        
        for d in model_dirs:
            parts = d.split("-")
            if len(parts) >= 3:
                version = parts[1][1:]  # Remove 'v' prefix
                flare_class = parts[2]
                time_window = parts[3][:-1]  # Remove 'h' suffix
                
                metadata_path = os.path.join(models_dir, d, "metadata.json")
                if os.path.exists(metadata_path):
                    with open(metadata_path, "r") as f:
                        metadata = json.load(f)
                        
                    models.append({
                        "version": version,
                        "flare_class": flare_class,
                        "time_window": time_window,
                        "timestamp": metadata.get("timestamp", "unknown"),
                        "accuracy": metadata.get("performance", {}).get("accuracy", "unknown")
                    })
                else:
                    models.append({
                        "version": version,
                        "flare_class": flare_class,
                        "time_window": time_window,
                        "timestamp": "unknown",
                        "accuracy": "unknown"
                    })
                    
        return sorted(models, key=lambda x: (x["flare_class"], x["time_window"], x["version"]))
    except FileNotFoundError:
        return []

def plot_confusion_matrix(y_true, y_pred, model_dir, normalize=False):
    """
    Generate and save a confusion matrix visualization.
    
    Args:
        y_true: Ground truth labels
        y_pred: Predicted labels
        model_dir: Directory to save the plot
        normalize: Whether to normalize the confusion matrix
    """
    cm = confusion_matrix(y_true, y_pred)
    
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    
    classes = ["Negative", "Positive"]
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], fmt),
                    horizontalalignment="center",
                    color="white" if cm[i, j] > thresh else "black")
    
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    
    plt.savefig(os.path.join(model_dir, "confusion_matrix.png"), dpi=200)
    plt.close()

def compare_models(versions, flare_classes, time_windows):
    """
    Generate a comparison table of different model versions.
    
    Args:
        versions: List of version strings
        flare_classes: List of flare classes
        time_windows: List of time windows
    
    Returns:
        Markdown table comparing the models
    """
    headers = ["Version", "Flare Class", "Time Window", "Accuracy", "TSS", "Timestamp"]
    rows = []
    
    for v in versions:
        for fc in flare_classes:
            for tw in time_windows:
                try:
                    metadata = load_model_metadata(v, fc, tw)
                    performance = metadata.get("performance", {})
                    timestamp = datetime.fromisoformat(metadata["timestamp"]).strftime("%Y-%m-%d")
                    
                    rows.append([
                        v,
                        fc,
                        f"{tw}h",
                        f"{performance.get('accuracy', 'N/A'):.4f}" if isinstance(performance.get('accuracy'), float) else "N/A",
                        f"{performance.get('TSS', 'N/A'):.4f}" if isinstance(performance.get('TSS'), float) else "N/A",
                        timestamp
                    ])
                except FileNotFoundError:
                    rows.append([v, fc, f"{tw}h", "N/A", "N/A", "N/A"])
    
    # Create markdown table
    table = " | ".join(headers) + "\n"
    table += " | ".join(["---"] * len(headers)) + "\n"
    
    for row in rows:
        table += " | ".join(str(cell) for cell in row) + "\n"
    
    return table

def get_next_version(flare_class, time_window):
    """
    Determine the next available version number for a specific flare class and time window.
    
    Args:
        flare_class: Flare class (C, M, or M5)
        time_window: Time window (24, 48, or 72)
        
    Returns:
        Next available version number as a string (e.g., "1.0")
    """
    models_dir = "models/trained_models"
    try:
            # Find all model directories matching the pattern
        pattern = f"SolarKnowledge-v*-{flare_class}-{time_window}h"
        matching_dirs = []
        
        # Look through the models directory
        for d in os.listdir(models_dir):
            # Skip if not a directory
            if not os.path.isdir(os.path.join(models_dir, d)):
                continue
                
            # Check if the directory matches our pattern
            if d.startswith("SolarKnowledge-v") and d.endswith(f"-{flare_class}-{time_window}h"):
                matching_dirs.append(d)
        
        if not matching_dirs:
            return "1.0"  # First version
        
        # Extract version numbers from directory names
        versions = []
        for d in matching_dirs:
            parts = d.split("-")
            if len(parts) >= 2:
                v = parts[1][1:]  # Remove 'v' prefix
                try:
                        # Parse version numbers
                    if "." in v:
                        major, minor = v.split(".")
                        versions.append((int(major), int(minor)))
                    else:
                        versions.append((int(v), 0))
                except ValueError:
                    continue
        
        if not versions:
            return "1.0"  # Default if can't parse any versions
        
        # Find the highest version
        versions.sort(reverse=True)
        highest_major, highest_minor = versions[0]
        
        # Increment the minor version
        new_minor = highest_minor + 1
        
        # If minor version gets too high, increment major version
        if new_minor >= 10:
            return f"{highest_major + 1}.0"
        else:
            return f"{highest_major}.{new_minor}"
    except Exception as e:
        print(f"Error determining next version: {e}")
        return "1.0"  # Default to 1.0 if anything goes wrong

def get_latest_version(flare_class, time_window):
    """
    Get the latest available version for a specific flare class and time window.
    
    Args:
        flare_class: Flare class (C, M, or M5)
        time_window: Time window (24, 48, or 72)
        
    Returns:
        Latest version number as a string (e.g., "1.0") or None if no models exist
    """
    models_dir = "models/trained_models"
    next_version = get_next_version(flare_class, time_window)
    if next_version == "1.0":
        return None
    
    # Parse the next version to find the previous one
    if "." in next_version:
        major, minor = next_version.split(".")
        minor = int(minor)
        
        if minor > 0:
            return f"{major}.{minor - 1}"
        else:
            # Check if previous major version exists
            major = int(major)
            if major > 1:
                # Try to find the highest minor version of the previous major version
                prev_major = str(major - 1)
                for i in range(9, -1, -1):  # Check from 9 down to 0
                    version = f"{prev_major}.{i}"
                    if os.path.exists(os.path.join(models_dir, f"SolarKnowledge-v{version}-{flare_class}-{time_window}h")):
                        return version
                
                # If no minor version found, default to .0
                return f"{prev_major}.0"
    
    return "1.0"

if __name__ == "__main__":
    # Example usage
    models = list_available_models()
    if models:
        print("Available Models:")
        for model in models:
            print(f"v{model['version']} - {model['flare_class']} - {model['time_window']}h - Accuracy: {model['accuracy']}")
    else:
        print("No models found.") 