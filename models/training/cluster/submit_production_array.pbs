#!/bin/bash
#PBS -N everest_production
#PBS -l walltime=24:00:00
#PBS -l select=1:ncpus=8:mem=64gb:ngpus=1:gpu_type=L40S
#PBS -J 1-45
#PBS -j oe
#PBS -o logs/production_${PBS_ARRAY_INDEX}.log

# EVEREST Production Training - Array Job Submission
# This script runs individual production training experiments as array jobs

echo "EVEREST Production Training - Array Job"
echo "Job ID: $PBS_JOBID"
echo "Array Index: $PBS_ARRAY_INDEX"
echo "Node: $(hostname)"
echo "Started: $(date)"
echo "========================================"

# Navigate to project root and verify structure
cd $PBS_O_WORKDIR
cd ../../..  # Go up from cluster -> training -> models -> project_root
PROJECT_ROOT=$(pwd)
echo "Project root: $PROJECT_ROOT"

# Verify project structure
if [ ! -d "models/training" ]; then
    echo "Error: models/training/ directory not found"
    echo "Current directory: $(pwd)"
    echo "Contents: $(ls -la)"
    exit 1
fi

echo "Project structure verified"

# Set Python path
export PYTHONPATH="$PROJECT_ROOT:$PYTHONPATH"

# Initialize conda - try multiple initialization methods
if [ -f "$HOME/miniforge3/etc/profile.d/conda.sh" ]; then
    source "$HOME/miniforge3/etc/profile.d/conda.sh"
elif [ -f "$HOME/anaconda3/etc/profile.d/conda.sh" ]; then
    source "$HOME/anaconda3/etc/profile.d/conda.sh"
elif [ -f "$HOME/.bashrc" ]; then
    source "$HOME/.bashrc"
else
    echo "Warning: Could not find conda initialization script"
fi

# Activate conda environment
echo "Activating everest_env..."
conda activate everest_env

if [ $? -ne 0 ]; then
    echo "Failed to activate everest_env, trying alternative method..."
    module load anaconda3/personal 2>/dev/null || echo "Module load failed"
    source activate everest_env
    
    if [ $? -ne 0 ]; then
        echo "Failed to activate everest_env with alternative method"
        exit 1
    fi
fi

echo "Environment activated successfully"
echo "Conda environment: $CONDA_DEFAULT_ENV"
echo "Python executable: $(which python)"

# Validate GPU availability
echo "Validating GPU..."
python -c "
import torch
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f'‚úÖ GPU available: {gpu_name}')
    print(f'GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB')
else:
    print('‚ùå GPU not available - production training cannot proceed')
    exit(1)
"

if [ $? -ne 0 ]; then
    echo "‚ùå GPU validation failed - terminating job"
    exit 1
fi

# Test basic imports
echo "Testing imports..."
python -c "
try:
    import models.training
    print('‚úÖ Training module imports successful')
except ImportError as e:
    print(f'‚ùå Import failed: {e}')
    exit(1)
"

if [ $? -ne 0 ]; then
    echo "‚ùå Import validation failed - terminating job"
    exit 1
fi

# Create logs directory
mkdir -p logs

# Run the specific experiment for this array index
echo ""
echo "üè≠ Starting EVEREST Production Training"
echo "Array Index: ${PBS_ARRAY_INDEX}"
echo "GPU: $(nvidia-smi -L 2>/dev/null || echo 'GPU info unavailable')"
echo "Memory: $(free -h | head -2)"
echo ""

# Execute the training script in array mode
echo "Command: python models/training/run_production_training.py --mode array --array_index ${PBS_ARRAY_INDEX}"
python models/training/run_production_training.py \
    --mode array \
    --array_index ${PBS_ARRAY_INDEX}

# Check exit status
exit_code=$?

echo ""
echo "Experiment completed with exit code: $exit_code"
echo "Array Index: ${PBS_ARRAY_INDEX}"
echo "Finished: $(date)"

if [ $exit_code -eq 0 ]; then
    echo "‚úÖ Production training completed successfully"
else
    echo "‚ùå Production training failed"
fi

exit $exit_code 