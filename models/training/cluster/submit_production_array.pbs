#!/bin/bash
#PBS -N everest_production
#PBS -l walltime=24:00:00
#PBS -l select=1:ncpus=4:mem=24gb:ngpus=1
#PBS -J 1-45
#PBS -j oe
#PBS -o logs/production_${PBS_ARRAY_INDEX}.log

# EVEREST Production Training - Array Job Submission
# This script runs individual production training experiments as array jobs

echo "EVEREST Production Training - Array Job"
echo "Job ID: $PBS_JOBID"
echo "Array Index: $PBS_ARRAY_INDEX"
echo "Node: $(hostname)"
echo "Started: $(date)"
echo "========================================"

# Initialize conda
source ~/miniforge3/etc/profile.d/conda.sh

# Navigate to project root and verify structure
cd $PBS_O_WORKDIR
cd ../../..  # Go up from cluster -> training -> models -> project_root
PROJECT_ROOT=$(pwd)
echo "Project root: $PROJECT_ROOT"

# Verify we're in the right directory
echo "Working directory: $(pwd)"
echo "Contents: $(ls -la | head -5)"

# Activate conda environment
conda activate everest_env

# Set environment variables for GPU
export CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES
export PYTHONPATH="$PROJECT_ROOT:$PYTHONPATH"

echo "Using GPU: $CUDA_VISIBLE_DEVICES"
echo "Conda environment: $CONDA_DEFAULT_ENV"
echo "Python path: $PYTHONPATH"
echo "Python executable: $(which python)"
echo "Python version: $(python --version)"

# Test basic imports before running the main script
echo "Testing imports..."
python -c "import torch; print(f'PyTorch version: {torch.__version__}')"
python -c "import models.training; print('Training imports successful')"

# Validate GPU availability - CRITICAL for production training
echo "Validating GPU..."
python -c "
import torch
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f'✅ GPU available: {gpu_name}')
else:
    print('❌ GPU not available - production training cannot proceed')
    exit(1)
"

if [ $? -ne 0 ]; then
    echo "❌ GPU validation failed - terminating job"
    exit 1
fi

echo "Starting production training..."

# Monitor available resources
echo "Memory info: $(free -h | head -2)"
echo "Disk space: $(df -h . | tail -1)"
echo "GPU memory: $(nvidia-smi --query-gpu=memory.total,memory.used --format=csv,noheader,nounits || echo 'GPU info unavailable')"

# Create logs directory
mkdir -p logs

# Run the specific experiment for this array index
echo ""
echo "🏭 Starting EVEREST Production Training"
echo "Array Index: ${PBS_ARRAY_INDEX}"
echo "GPU: $(nvidia-smi -L 2>/dev/null || echo 'GPU info unavailable')"
echo "Memory: $(free -h | head -2)"
echo ""

# Execute the training script in array mode
python models/training/run_production_training.py \
    --mode array \
    --array_index ${PBS_ARRAY_INDEX}

echo "Completed production training for Array job ${PBS_ARRAY_INDEX}"

exit 0 