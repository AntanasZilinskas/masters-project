#!/bin/bash
#PBS -N test_production_training
#PBS -l walltime=2:00:00
#PBS -l select=1:ncpus=4:mem=24gb:ngpus=1
#PBS -j oe
#PBS -o test_production_training.log

# EVEREST Production Training - Test Script
# This script validates the production training setup before running the full array job

echo "üß™ EVEREST Production Training - Test Script"
echo "Job ID: $PBS_JOBID"
echo "Node: $(hostname)"
echo "Started: $(date)"
echo "============================================="

# Initialize conda
source ~/miniforge3/etc/profile.d/conda.sh

# Navigate to project root and verify structure
cd $PBS_O_WORKDIR
cd ../../..  # Go up from cluster -> training -> models -> project_root
PROJECT_ROOT=$(pwd)
echo "Project root: $PROJECT_ROOT"

# Verify we're in the right directory
echo "Working directory: $(pwd)"
echo "Contents: $(ls -la | head -5)"

# Activate conda environment
conda activate everest_env

# Set environment variables for GPU
export CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES
export PYTHONPATH="$PROJECT_ROOT:$PYTHONPATH"

echo "Using GPU: $CUDA_VISIBLE_DEVICES"
echo "Conda environment: $CONDA_DEFAULT_ENV"
echo "Python path: $PYTHONPATH"
echo "Python executable: $(which python)"
echo "Python version: $(python --version)"

# Comprehensive directory verification
echo ""
echo "üìÅ Verifying project structure..."
required_dirs=("models" "models/training" "models/training/cluster" "Nature_data")
required_files=("models/training/config.py" "models/training/trainer.py" "models/training/run_production_training.py" "models/solarknowledge_ret_plus.py" "models/utils.py")

all_verified=true
for dir in "${required_dirs[@]}"; do
    if [ -d "$dir" ]; then
        echo "‚úÖ Directory found: $dir"
    else
        echo "‚ùå Directory missing: $dir"
        all_verified=false
    fi
done

for file in "${required_files[@]}"; do
    if [ -f "$file" ]; then
        echo "‚úÖ File found: $file"
    else
        echo "‚ùå File missing: $file"
        all_verified=false
    fi
done

if [ "$all_verified" = false ]; then
    echo "‚ùå Project structure verification failed!"
    exit 1
fi

echo "‚úÖ Project structure verified successfully"

# Validate GPU availability
echo ""
echo "üñ•Ô∏è Validating GPU availability..."
nvidia-smi || echo "nvidia-smi not available"

python -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f'GPU: {gpu_name}')
    print(f'GPU memory: {gpu_memory:.1f}GB')
    print('‚úÖ GPU validation successful')
else:
    print('‚ùå GPU not available - production training cannot proceed')
    exit(1)
"

if [ $? -ne 0 ]; then
    echo "‚ùå GPU validation failed - terminating test"
    exit 1
fi

# Test basic imports
echo ""
echo "üì¶ Testing module imports..."
python -c "
import sys
print(f'Python path: {sys.path[:3]}...')

try:
    import numpy as np
    print(f'‚úÖ NumPy {np.__version__}')
except ImportError as e:
    print(f'‚ùå NumPy import failed: {e}')
    exit(1)

try:
    import pandas as pd
    print(f'‚úÖ Pandas {pd.__version__}')
except ImportError as e:
    print(f'‚ùå Pandas import failed: {e}')
    exit(1)

try:
    import sklearn
    print(f'‚úÖ Scikit-learn {sklearn.__version__}')
except ImportError as e:
    print(f'‚ùå Scikit-learn import failed: {e}')
    exit(1)

print('‚úÖ Basic scientific packages imported successfully')
"

if [ $? -ne 0 ]; then
    echo "‚ùå Basic package import test failed"
    exit 1
fi

# Test EVEREST model imports
echo ""
echo "üî¨ Testing EVEREST model imports..."
python -c "
try:
    from models.solarknowledge_ret_plus import RETPlusWrapper
    print('‚úÖ RETPlusWrapper imported successfully')
except ImportError as e:
    print(f'‚ùå RETPlusWrapper import failed: {e}')
    exit(1)

try:
    from models.utils import get_training_data, get_testing_data
    print('‚úÖ Data utilities imported successfully')
except ImportError as e:
    print(f'‚ùå Data utilities import failed: {e}')
    exit(1)

print('‚úÖ EVEREST model components imported successfully')
"

if [ $? -ne 0 ]; then
    echo "‚ùå EVEREST model import test failed"
    exit 1
fi

# Test production training module imports
echo ""
echo "üè≠ Testing production training imports..."
python -c "
try:
    from models.training.config import TRAINING_TARGETS, get_all_experiments, get_array_job_mapping
    print('‚úÖ Production training config imported successfully')
    
    # Test config functionality
    experiments = get_all_experiments()
    print(f'‚úÖ Found {len(experiments)} total experiments')
    
    mapping = get_array_job_mapping()
    print(f'‚úÖ Array job mapping created for {len(mapping)} jobs')
    
    if len(experiments) != 45:
        print(f'‚ö†Ô∏è Expected 45 experiments, found {len(experiments)}')
    
except ImportError as e:
    print(f'‚ùå Production training config import failed: {e}')
    exit(1)

try:
    from models.training.trainer import ProductionTrainer
    print('‚úÖ ProductionTrainer imported successfully')
except ImportError as e:
    print(f'‚ùå ProductionTrainer import failed: {e}')
    exit(1)

try:
    from models.training.run_production_training import run_array_job_experiment
    print('‚úÖ Production training runner imported successfully')
except ImportError as e:
    print(f'‚ùå Production training runner import failed: {e}')
    exit(1)

print('‚úÖ Production training modules imported successfully')
"

if [ $? -ne 0 ]; then
    echo "‚ùå Production training module import test failed"
    exit 1
fi

# Test data availability
echo ""
echo "üìä Testing data availability..."
python -c "
import os
from models.utils import get_training_data, get_testing_data

# Test a few representative datasets
test_configs = [('M5', '72'), ('C', '24'), ('M', '48')]

for flare_class, time_window in test_configs:
    try:
        X_train, y_train = get_training_data(time_window, flare_class)
        X_test, y_test = get_testing_data(time_window, flare_class)
        
        if X_train is not None and y_train is not None:
            print(f'‚úÖ Training data found for {flare_class}-{time_window}h: {len(X_train)} samples')
        else:
            print(f'‚ùå Training data missing for {flare_class}-{time_window}h')
            
        if X_test is not None and y_test is not None:
            print(f'‚úÖ Testing data found for {flare_class}-{time_window}h: {len(X_test)} samples')
        else:
            print(f'‚ùå Testing data missing for {flare_class}-{time_window}h')
            
    except Exception as e:
        print(f'‚ùå Data loading failed for {flare_class}-{time_window}h: {e}')

print('‚úÖ Data availability test completed')
"

if [ $? -ne 0 ]; then
    echo "‚ùå Data availability test failed"
    exit 1
fi

# Test array job functionality
echo ""
echo "üî¢ Testing array job functionality..."
python -c "
from models.training.config import get_array_job_mapping

mapping = get_array_job_mapping()

# Test first few array indices
test_indices = [1, 2, 23, 45]

for idx in test_indices:
    if idx in mapping:
        exp = mapping[idx]
        exp_name = exp['experiment_name']
        print(f'‚úÖ Array index {idx}: {exp_name}')
    else:
        print(f'‚ùå Array index {idx} not found in mapping')

# Verify mapping covers all expected indices
expected_indices = set(range(1, 46))  # 1-45
actual_indices = set(mapping.keys())

if expected_indices == actual_indices:
    print('‚úÖ Array job mapping covers all expected indices (1-45)')
else:
    missing = expected_indices - actual_indices
    extra = actual_indices - expected_indices
    if missing:
        print(f'‚ùå Missing indices: {sorted(missing)}')
    if extra:
        print(f'‚ùå Extra indices: {sorted(extra)}')

print('‚úÖ Array job functionality test completed')
"

if [ $? -ne 0 ]; then
    echo "‚ùå Array job functionality test failed"
    exit 1
fi

# Test single experiment execution (quick test)
echo ""
echo "üöÄ Testing single experiment execution (quick test)..."
echo "This will run a minimal training test to verify the training pipeline..."

python -c "
import sys
import torch
from models.training.trainer import ProductionTrainer

# Test with minimal configuration
print('Creating test trainer for M5-72h with seed 0...')
try:
    trainer = ProductionTrainer('M5', '72', 0)
    print('‚úÖ ProductionTrainer created successfully')
    
    # Test data loading
    X_train, y_train, X_test, y_test = trainer.load_data()
    print(f'‚úÖ Data loaded: {len(X_train)} train, {len(X_test)} test samples')
    
    # Test model creation
    model = trainer.create_model()
    print('‚úÖ Model created successfully')
    
    # Quick forward pass test
    device = next(model.model.parameters()).device
    X_sample = torch.tensor(X_test[:4], dtype=torch.float32).to(device)
    
    with torch.no_grad():
        outputs = model.model(X_sample)
        print('‚úÖ Model forward pass successful')
        print(f'   Output shape: {outputs[\"logits\"].shape}')
    
    print('‚úÖ Single experiment execution test passed')
    
except Exception as e:
    print(f'‚ùå Single experiment execution test failed: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)
"

if [ $? -ne 0 ]; then
    echo "‚ùå Single experiment execution test failed"
    exit 1
fi

# System resource check
echo ""
echo "üíª System resource check..."
echo "Memory info:"
free -h | head -2

echo ""
echo "Disk space:"
df -h . | head -2

echo ""
echo "GPU memory:"
nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv,noheader,nounits 2>/dev/null || echo "GPU memory info unavailable"

# Test 5: Test production training pipeline
echo "5. Testing production training pipeline..."
python -c "
import sys
sys.path.append('.')
from models.training.trainer import ProductionTrainer

# Test a small training run
print('Creating ProductionTrainer...')
trainer = ProductionTrainer('C', '24', 0)

print('Testing data loading...')
X_train, y_train, X_test, y_test = trainer.load_data()
print(f'Data shapes: X_train={X_train.shape}, y_train={y_train.shape}')

print('Testing model creation...')
model = trainer.create_model()
print(f'Model created: {type(model)}')

print('Testing directory setup...')
import os
print(f'Experiment dir exists: {os.path.exists(trainer.experiment_dir)}')
print(f'Model dir path: {trainer.model_dir}')
print(f'Results dir exists: {os.path.exists(\"models/training/results\")}')
print(f'Trained models dir exists: {os.path.exists(\"models/training/trained_models\")}')

print('‚úÖ Production training pipeline test completed')
"

if [ $? -ne 0 ]; then
    echo "‚ùå Production training pipeline test failed"
    exit 1
fi

# Final summary
echo ""
echo "üéâ PRODUCTION TRAINING TEST SUMMARY"
echo "=================================="
echo "‚úÖ Project structure verified"
echo "‚úÖ Environment setup successful"
echo "‚úÖ GPU validation passed"
echo "‚úÖ Package imports successful"
echo "‚úÖ EVEREST model imports successful"
echo "‚úÖ Production training imports successful"
echo "‚úÖ Data availability verified"
echo "‚úÖ Array job functionality tested"
echo "‚úÖ Single experiment execution tested"
echo "‚úÖ Production training pipeline tested"
echo ""
echo "üöÄ PRODUCTION TRAINING IS READY TO RUN!"
echo ""
echo "To submit the full production training array job:"
echo "   cd models/training/cluster"
echo "   ./submit_jobs.sh"
echo ""
echo "To submit with specific targets only:"
echo "   ./submit_jobs.sh --targets C-24 M-48 M5-72"
echo ""
echo "To run dry-run first:"
echo "   ./submit_jobs.sh --dry-run"
echo ""
echo "Test completed: $(date)"

exit 0 