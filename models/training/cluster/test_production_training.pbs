#!/bin/bash
#PBS -N test_production_training
#PBS -l walltime=2:00:00
#PBS -l select=1:ncpus=4:mem=24gb:ngpus=1
#PBS -j oe
#PBS -o test_production_training.log

# EVEREST Production Training - Test Script
# This script validates the production training setup before running the full array job

echo "🧪 EVEREST Production Training - Test Script"
echo "Job ID: $PBS_JOBID"
echo "Node: $(hostname)"
echo "Started: $(date)"
echo "============================================="

# Initialize conda
source ~/miniforge3/etc/profile.d/conda.sh

# Navigate to project root and verify structure
cd $PBS_O_WORKDIR
cd ../../..  # Go up from cluster -> training -> models -> project_root
PROJECT_ROOT=$(pwd)
echo "Project root: $PROJECT_ROOT"

# Verify we're in the right directory
echo "Working directory: $(pwd)"
echo "Contents: $(ls -la | head -5)"

# Activate conda environment
conda activate everest_env

# Set environment variables for GPU
export CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES
export PYTHONPATH="$PROJECT_ROOT:$PYTHONPATH"

echo "Using GPU: $CUDA_VISIBLE_DEVICES"
echo "Conda environment: $CONDA_DEFAULT_ENV"
echo "Python path: $PYTHONPATH"
echo "Python executable: $(which python)"
echo "Python version: $(python --version)"

# Comprehensive directory verification
echo ""
echo "📁 Verifying project structure..."
required_dirs=("models" "models/training" "models/training/cluster" "Nature_data")
required_files=("models/training/config.py" "models/training/trainer.py" "models/training/run_production_training.py" "models/solarknowledge_ret_plus.py" "models/utils.py")

all_verified=true
for dir in "${required_dirs[@]}"; do
    if [ -d "$dir" ]; then
        echo "✅ Directory found: $dir"
    else
        echo "❌ Directory missing: $dir"
        all_verified=false
    fi
done

for file in "${required_files[@]}"; do
    if [ -f "$file" ]; then
        echo "✅ File found: $file"
    else
        echo "❌ File missing: $file"
        all_verified=false
    fi
done

if [ "$all_verified" = false ]; then
    echo "❌ Project structure verification failed!"
    exit 1
fi

echo "✅ Project structure verified successfully"

# Validate GPU availability
echo ""
echo "🖥️ Validating GPU availability..."
nvidia-smi || echo "nvidia-smi not available"

python -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f'GPU: {gpu_name}')
    print(f'GPU memory: {gpu_memory:.1f}GB')
    print('✅ GPU validation successful')
else:
    print('❌ GPU not available - production training cannot proceed')
    exit(1)
"

if [ $? -ne 0 ]; then
    echo "❌ GPU validation failed - terminating test"
    exit 1
fi

# Test basic imports
echo ""
echo "📦 Testing module imports..."
python -c "
import sys
print(f'Python path: {sys.path[:3]}...')

try:
    import numpy as np
    print(f'✅ NumPy {np.__version__}')
except ImportError as e:
    print(f'❌ NumPy import failed: {e}')
    exit(1)

try:
    import pandas as pd
    print(f'✅ Pandas {pd.__version__}')
except ImportError as e:
    print(f'❌ Pandas import failed: {e}')
    exit(1)

try:
    import sklearn
    print(f'✅ Scikit-learn {sklearn.__version__}')
except ImportError as e:
    print(f'❌ Scikit-learn import failed: {e}')
    exit(1)

print('✅ Basic scientific packages imported successfully')
"

if [ $? -ne 0 ]; then
    echo "❌ Basic package import test failed"
    exit 1
fi

# Test EVEREST model imports
echo ""
echo "🔬 Testing EVEREST model imports..."
python -c "
try:
    from models.solarknowledge_ret_plus import RETPlusWrapper
    print('✅ RETPlusWrapper imported successfully')
except ImportError as e:
    print(f'❌ RETPlusWrapper import failed: {e}')
    exit(1)

try:
    from models.utils import get_training_data, get_testing_data
    print('✅ Data utilities imported successfully')
except ImportError as e:
    print(f'❌ Data utilities import failed: {e}')
    exit(1)

print('✅ EVEREST model components imported successfully')
"

if [ $? -ne 0 ]; then
    echo "❌ EVEREST model import test failed"
    exit 1
fi

# Test production training module imports
echo ""
echo "🏭 Testing production training imports..."
python -c "
try:
    from models.training.config import TRAINING_TARGETS, get_all_experiments, get_array_job_mapping
    print('✅ Production training config imported successfully')
    
    # Test config functionality
    experiments = get_all_experiments()
    print(f'✅ Found {len(experiments)} total experiments')
    
    mapping = get_array_job_mapping()
    print(f'✅ Array job mapping created for {len(mapping)} jobs')
    
    if len(experiments) != 45:
        print(f'⚠️ Expected 45 experiments, found {len(experiments)}')
    
except ImportError as e:
    print(f'❌ Production training config import failed: {e}')
    exit(1)

try:
    from models.training.trainer import ProductionTrainer
    print('✅ ProductionTrainer imported successfully')
except ImportError as e:
    print(f'❌ ProductionTrainer import failed: {e}')
    exit(1)

try:
    from models.training.run_production_training import run_array_job_experiment
    print('✅ Production training runner imported successfully')
except ImportError as e:
    print(f'❌ Production training runner import failed: {e}')
    exit(1)

print('✅ Production training modules imported successfully')
"

if [ $? -ne 0 ]; then
    echo "❌ Production training module import test failed"
    exit 1
fi

# Test data availability
echo ""
echo "📊 Testing data availability..."
python -c "
import os
from models.utils import get_training_data, get_testing_data

# Test a few representative datasets
test_configs = [('M5', '72'), ('C', '24'), ('M', '48')]

for flare_class, time_window in test_configs:
    try:
        X_train, y_train = get_training_data(time_window, flare_class)
        X_test, y_test = get_testing_data(time_window, flare_class)
        
        if X_train is not None and y_train is not None:
            print(f'✅ Training data found for {flare_class}-{time_window}h: {len(X_train)} samples')
        else:
            print(f'❌ Training data missing for {flare_class}-{time_window}h')
            
        if X_test is not None and y_test is not None:
            print(f'✅ Testing data found for {flare_class}-{time_window}h: {len(X_test)} samples')
        else:
            print(f'❌ Testing data missing for {flare_class}-{time_window}h')
            
    except Exception as e:
        print(f'❌ Data loading failed for {flare_class}-{time_window}h: {e}')

print('✅ Data availability test completed')
"

if [ $? -ne 0 ]; then
    echo "❌ Data availability test failed"
    exit 1
fi

# Test array job functionality
echo ""
echo "🔢 Testing array job functionality..."
python -c "
from models.training.config import get_array_job_mapping

mapping = get_array_job_mapping()

# Test first few array indices
test_indices = [1, 2, 23, 45]

for idx in test_indices:
    if idx in mapping:
        exp = mapping[idx]
        exp_name = exp['experiment_name']
        print(f'✅ Array index {idx}: {exp_name}')
    else:
        print(f'❌ Array index {idx} not found in mapping')

# Verify mapping covers all expected indices
expected_indices = set(range(1, 46))  # 1-45
actual_indices = set(mapping.keys())

if expected_indices == actual_indices:
    print('✅ Array job mapping covers all expected indices (1-45)')
else:
    missing = expected_indices - actual_indices
    extra = actual_indices - expected_indices
    if missing:
        print(f'❌ Missing indices: {sorted(missing)}')
    if extra:
        print(f'❌ Extra indices: {sorted(extra)}')

print('✅ Array job functionality test completed')
"

if [ $? -ne 0 ]; then
    echo "❌ Array job functionality test failed"
    exit 1
fi

# Test single experiment execution (quick test)
echo ""
echo "🚀 Testing single experiment execution (quick test)..."
echo "This will run a minimal training test to verify the training pipeline..."

python -c "
import sys
import torch
from models.training.trainer import ProductionTrainer

# Test with minimal configuration
print('Creating test trainer for M5-72h with seed 0...')
try:
    trainer = ProductionTrainer('M5', '72', 0)
    print('✅ ProductionTrainer created successfully')
    
    # Test data loading
    X_train, y_train, X_test, y_test = trainer.load_data()
    print(f'✅ Data loaded: {len(X_train)} train, {len(X_test)} test samples')
    
    # Test model creation
    model = trainer.create_model()
    print('✅ Model created successfully')
    
    # Quick forward pass test
    device = next(model.model.parameters()).device
    X_sample = torch.tensor(X_test[:4], dtype=torch.float32).to(device)
    
    with torch.no_grad():
        outputs = model.model(X_sample)
        print('✅ Model forward pass successful')
        print(f'   Output shape: {outputs[\"logits\"].shape}')
    
    print('✅ Single experiment execution test passed')
    
except Exception as e:
    print(f'❌ Single experiment execution test failed: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)
"

if [ $? -ne 0 ]; then
    echo "❌ Single experiment execution test failed"
    exit 1
fi

# System resource check
echo ""
echo "💻 System resource check..."
echo "Memory info:"
free -h | head -2

echo ""
echo "Disk space:"
df -h . | head -2

echo ""
echo "GPU memory:"
nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv,noheader,nounits 2>/dev/null || echo "GPU memory info unavailable"

# Final summary
echo ""
echo "🎉 PRODUCTION TRAINING TEST SUMMARY"
echo "=================================="
echo "✅ Project structure verified"
echo "✅ Environment setup successful"
echo "✅ GPU validation passed"
echo "✅ Package imports successful"
echo "✅ EVEREST model imports successful"
echo "✅ Production training imports successful"
echo "✅ Data availability verified"
echo "✅ Array job functionality tested"
echo "✅ Single experiment execution tested"
echo ""
echo "🚀 PRODUCTION TRAINING IS READY TO RUN!"
echo ""
echo "To submit the full production training array job:"
echo "   cd models/training/cluster"
echo "   ./submit_jobs.sh"
echo ""
echo "To submit with specific targets only:"
echo "   ./submit_jobs.sh --targets C-24 M-48 M5-72"
echo ""
echo "To run dry-run first:"
echo "   ./submit_jobs.sh --dry-run"
echo ""
echo "Test completed: $(date)"

exit 0 