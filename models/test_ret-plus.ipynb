{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a46ae6-8821-49f0-8db0-9ab2aaa30341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 10:26:33.280411: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-15 10:26:33.280477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-15 10:26:33.281530: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-15 10:26:33.288650: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-15 10:26:46.592313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-15 10:27:01.400581: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: TensorFlow GPU device not found.\n",
      "TensorFlow backend version: 2.15.0\n",
      "SUCCESS: PyTorch found GPU: Quadro RTX 6000\n",
      "PyTorch CUDA version: 12.6\n",
      "PyTorch version: 2.7.0+cu126\n",
      "Python version: 3.11.12\n",
      "\n",
      "\n",
      "🎯 Best threshold for models/EVEREST-v1.0-M5-72h/model_weights.pt: 0.38\n",
      "Confusion matrix:\n",
      " [[71559    66]\n",
      " [   26    78]]\n",
      "Accuracy:  0.9987\n",
      "Precision: 0.5417\n",
      "Recall:    0.7500\n",
      "F1:        0.6290\n",
      "TSS:       0.7491\n"
     ]
    }
   ],
   "source": [
    "# RET+ precision-tuned evaluation block\n",
    "\n",
    "from solarknowledge_ret_plus import RETPlusWrapper\n",
    "from utils import get_testing_data\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --- Config ---\n",
    "flare_classes = [\"M5\"]\n",
    "time_windows = [\"72\"]\n",
    "input_shape = (10, 9)\n",
    "thresholds = np.linspace(0.1, 0.9, 81)  # Fine-grained search\n",
    "min_recall = 0.75  # Optional: skip thresholds with too-low recall\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "for flare in flare_classes:\n",
    "    for time in time_windows:\n",
    "        model_path = f\"models/EVEREST-v1.0-{flare}-{time}h/model_weights.pt\"\n",
    "\n",
    "        # Load data\n",
    "        X_test, y_test = get_testing_data(time, flare)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        # Load model\n",
    "        model = RETPlusWrapper(input_shape)\n",
    "        model.load(model_path)\n",
    "\n",
    "        # Predict probabilities\n",
    "        probs = model.predict_proba(X_test).squeeze()\n",
    "\n",
    "        # Threshold tuning\n",
    "        best_score = -np.inf\n",
    "        best_thresh = None\n",
    "        best_metrics = {}\n",
    "\n",
    "        for t in thresholds:\n",
    "            y_pred = (probs >= t).astype(int)\n",
    "\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "            tss = rec + cm[0, 0] / (cm[0, 0] + cm[0, 1] + 1e-8) - 1\n",
    "\n",
    "            # Skip thresholds with very low recall\n",
    "            if rec < min_recall:\n",
    "                continue\n",
    "\n",
    "            # Precision-weighted scoring rule\n",
    "            score = 0.6 * prec + 0.2 * f1 + 0.2 * tss\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_thresh = t\n",
    "                best_metrics = {\n",
    "                    'confusion_matrix': cm,\n",
    "                    'accuracy': acc,\n",
    "                    'precision': prec,\n",
    "                    'recall': rec,\n",
    "                    'f1': f1,\n",
    "                    'tss': tss\n",
    "                }\n",
    "\n",
    "        # --- Print Results ---\n",
    "        print(f\"\\n🎯 Best threshold for {model_path}: {best_thresh:.2f}\")\n",
    "        print(\"Confusion matrix:\\n\", best_metrics['confusion_matrix'])\n",
    "        print(f\"Accuracy:  {best_metrics['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
    "        print(f\"Recall:    {best_metrics['recall']:.4f}\")\n",
    "        print(f\"F1:        {best_metrics['f1']:.4f}\")\n",
    "        print(f\"TSS:       {best_metrics['tss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336d4a3d-53d7-4b74-900e-2b2393f5fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 20:17:56.100450: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-14 20:17:56.100522: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-14 20:17:56.101580: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-14 20:17:56.108909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-14 20:18:10.096730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-14 20:18:24.840535: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: TensorFlow GPU device not found.\n",
      "TensorFlow backend version: 2.15.0\n",
      "SUCCESS: PyTorch found GPU: Quadro RTX 6000\n",
      "PyTorch CUDA version: 12.6\n",
      "PyTorch version: 2.7.0+cu126\n",
      "Python version: 3.11.12\n",
      "\n",
      "EVT Score Summary by Class:\n",
      "  C: min=-40.9388, mean=-8.9765, max=1.9916\n",
      "Not enough variation to compute Spearman/Kendall correlations.\n",
      "Done. Check output folders:\n",
      "  Attention plots: attention_plots\n",
      "  Uncertainty violin plots: uncertainty_plots\n",
      "  EVT plots: evt_plots\n",
      "Representative attention maps:\n",
      "  TP: attention_plots/C_72h_TP_35590.png  (prob=0.985)\n",
      "  TN: attention_plots/C_72h_TN_57907.png  (prob=0.018)\n",
      "  FP: attention_plots/C_72h_FP_13223.png  (prob=0.570)\n",
      "  FN: attention_plots/C_72h_FN_5215.png  (prob=0.420)\n",
      "Representative attention maps:\n",
      "  TP: attention_plots/C_72h_TP_35590.png  (prob=0.985)\n",
      "  TN: attention_plots/C_72h_TN_57907.png  (prob=0.018)\n",
      "  FP: attention_plots/C_72h_FP_13223.png  (prob=0.570)\n",
      "  FN: attention_plots/C_72h_FN_5215.png  (prob=0.420)\n",
      "Representative attention maps:\n",
      "  TP: attention_plots/C_72h_TP_35590.png  (prob=0.985)\n",
      "  TN: attention_plots/C_72h_TN_57907.png  (prob=0.018)\n",
      "  FP: attention_plots/C_72h_FP_13223.png  (prob=0.570)\n",
      "  FN: attention_plots/C_72h_FN_5215.png  (prob=0.420)\n"
     ]
    }
   ],
   "source": [
    "# plot_attention_and_uncertainty.py\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "from solarknowledge_ret_plus import RETPlusWrapper\n",
    "from utils import get_testing_data\n",
    "from model_tracking import get_latest_version\n",
    "\n",
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "flare       = \"C\"\n",
    "time_window = \"72\"\n",
    "input_shape = (10, 9)\n",
    "threshold   = 0.5\n",
    "n_per_cat   = 5    # number of samples per TP/TN/FP/FN\n",
    "batch_size  = 512\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\"  if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "\n",
    "out_attention = \"attention_plots\"\n",
    "out_uncert    = \"uncertainty_plots\"\n",
    "out_evt       = \"evt_plots\"\n",
    "os.makedirs(out_attention, exist_ok=True)\n",
    "os.makedirs(out_uncert, exist_ok=True)\n",
    "os.makedirs(out_evt, exist_ok=True)\n",
    "\n",
    "# ── Load test data & model ────────────────────────────────────────────────────\n",
    "X_test, y_test = get_testing_data(time_window, flare)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "version    = get_latest_version(flare, time_window)\n",
    "model_dir  = f\"models/EVEREST-v{version}-{flare}-{time_window}h\"\n",
    "weights_fp = os.path.join(model_dir, \"model_weights.pt\")\n",
    "\n",
    "model = RETPlusWrapper(input_shape)\n",
    "model.load(weights_fp)\n",
    "model.model.to(device).eval()\n",
    "\n",
    "# ── 1) Attention heatmaps ────────────────────────────────────────────────────\n",
    "probs = model.predict_proba(X_test).ravel()\n",
    "preds = (probs >= threshold).astype(int)\n",
    "\n",
    "idx_tp = np.where((preds==1) & (y_test==1))[0]\n",
    "idx_tn = np.where((preds==0) & (y_test==0))[0]\n",
    "idx_fp = np.where((preds==1) & (y_test==0))[0]\n",
    "idx_fn = np.where((preds==0) & (y_test==1))[0]\n",
    "categories = {\"TP\": idx_tp, \"TN\": idx_tn, \"FP\": idx_fp, \"FN\": idx_fn}\n",
    "\n",
    "att_storage = {}\n",
    "def att_hook(module, inp, out):\n",
    "    # out shape: [batch, T, 1]\n",
    "    att_storage['w'] = out.detach().cpu().numpy()\n",
    "model.model.att_pool.register_forward_hook(att_hook)\n",
    "\n",
    "for cat, idxs in categories.items():\n",
    "    if len(idxs) == 0:\n",
    "        continue\n",
    "    chosen = random.sample(list(idxs), min(n_per_cat, len(idxs)))\n",
    "    for i in chosen:\n",
    "        x_np = X_test[i:i+1]  # shape (1, T, F)\n",
    "        x_t  = torch.tensor(x_np, dtype=torch.float32).to(device)\n",
    "        _    = model.model(x_t)  # triggers hook\n",
    "        weights = att_storage['w'][0, :, 0]  # shape (T,)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 1.5))\n",
    "        im = ax.imshow(weights[np.newaxis, :], aspect='auto')\n",
    "        ax.set_title(f\"{cat} idx={i} true={y_test[i]} prob={probs[i]:.2f}\")\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks(np.arange(len(weights)))\n",
    "        ax.set_xticklabels(np.arange(1, len(weights) + 1))\n",
    "        fig.colorbar(im, ax=ax, label=\"Attention weight\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fn = os.path.join(out_attention,\n",
    "                          f\"{flare}_{time_window}h_{cat}_{i}.png\")\n",
    "        fig.savefig(fn, dpi=200)\n",
    "        plt.close(fig)\n",
    "\n",
    "# ── 2) Epistemic & Aleatoric variance violin plots ────────────────────────────\n",
    "# Collect evidential outputs for all test samples\n",
    "all_mu, all_v, all_a, all_b = [], [], [], []\n",
    "for start in range(0, len(X_test), batch_size):\n",
    "    xb = torch.tensor(X_test[start:start+batch_size],\n",
    "                      dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        evid = model.model(xb)['evid']  # shape [B,4]\n",
    "    mu,v,a,b = evid.split(1, dim=-1)\n",
    "    all_mu.append(mu.cpu().numpy())\n",
    "    all_v.append(v.cpu().numpy())\n",
    "    all_a.append(a.cpu().numpy())\n",
    "    all_b.append(b.cpu().numpy())\n",
    "\n",
    "mu_arr = np.vstack(all_mu).squeeze(-1)\n",
    "v_arr  = np.vstack(all_v).squeeze(-1)\n",
    "a_arr  = np.vstack(all_a).squeeze(-1)\n",
    "b_arr  = np.vstack(all_b).squeeze(-1)\n",
    "\n",
    "# Compute total, epistemic, and aleatoric variances\n",
    "var_total     = b_arr / ((a_arr - 1) * v_arr + 1e-12)\n",
    "var_epistemic = var_total / a_arr\n",
    "var_aleatoric = var_total * (1 - 1/a_arr)\n",
    "\n",
    "# Build DataFrame\n",
    "df_unc = pd.DataFrame({\n",
    "    'Epistemic': var_epistemic.flatten(),\n",
    "    'Aleatoric': var_aleatoric.flatten(),\n",
    "    'Outcome': np.where((preds==1)&(y_test==1),'TP',\n",
    "                np.where((preds==0)&(y_test==0),'TN',\n",
    "                np.where((preds==1)&(y_test==0),'FP','FN')))\n",
    "})\n",
    "\n",
    "outcomes = ['TP','TN','FP','FN']\n",
    "for col in ['Epistemic','Aleatoric']:\n",
    "    data = [df_unc.loc[df_unc['Outcome']==o, col].values for o in outcomes]\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    parts = ax.violinplot(\n",
    "        data,\n",
    "        positions=range(len(outcomes)),\n",
    "        showmeans=True,\n",
    "        showmedians=True,\n",
    "        showextrema=False\n",
    "    )\n",
    "    ax.set_xticks(range(len(outcomes)))\n",
    "    ax.set_xticklabels(outcomes)\n",
    "    ax.set_xlabel(\"Prediction Outcome\")\n",
    "    ax.set_ylabel(f\"{col} Variance\")\n",
    "    ax.set_title(f\"{col} Uncertainty by Outcome\")\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.7)\n",
    "    fig.tight_layout()\n",
    "    fn = os.path.join(out_uncert, f\"{col}_uncertainty_violin.png\")\n",
    "    fig.savefig(fn, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ── 3) EVT score distributions & correlations ────────────────────────────────\n",
    "flare_classes = [\"C\"]\n",
    "evt_scores = []\n",
    "class_labels = []\n",
    "\n",
    "for fc in flare_classes:\n",
    "    X_t, y_t = get_testing_data(time_window, fc)\n",
    "    X_t = np.array(X_t)\n",
    "    version = get_latest_version(fc, time_window)\n",
    "    wd = f\"models/EVEREST-v{version}-{fc}-{time_window}h\"\n",
    "    wp = os.path.join(wd, \"model_weights.pt\")\n",
    "\n",
    "    m = RETPlusWrapper(input_shape)\n",
    "    m.load(wp)\n",
    "    m.model.to(device).eval()\n",
    "\n",
    "    xi_list, sig_list = [], []\n",
    "    for start in range(0, len(X_t), batch_size):\n",
    "        xb = torch.tensor(X_t[start:start+batch_size],\n",
    "                          dtype=torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            gpd_out = m.model(xb)['gpd']  # shape [B,2]\n",
    "        xi, sig = gpd_out.split(1, dim=-1)\n",
    "        xi_list.append(xi.cpu().numpy().squeeze(-1))\n",
    "        sig_list.append(sig.cpu().numpy().squeeze(-1))\n",
    "\n",
    "    xi_arr  = np.concatenate(xi_list)\n",
    "    sig_arr = np.concatenate(sig_list)\n",
    "    score   = xi_arr * sig_arr\n",
    "\n",
    "    evt_scores.append(score)\n",
    "    class_labels.append(np.full_like(score, fill_value=flare_classes.index(fc)))\n",
    "\n",
    "# Boxplot of EVT score by flare class\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.boxplot(evt_scores, labels=flare_classes)\n",
    "ax.set_title(\"EVT Score (ξ·σ) by Flare Class\")\n",
    "ax.set_xlabel(\"Flare Class\")\n",
    "ax.set_ylabel(\"ξ·σ\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(out_evt, \"evt_score_boxplot.png\"), dpi=200)\n",
    "plt.close(fig)\n",
    "\n",
    "# Summary & correlations\n",
    "print(\"EVT Score Summary by Class:\")\n",
    "for fc, score in zip(flare_classes, evt_scores):\n",
    "    print(f\"  {fc}: min={score.min():.4f}, mean={score.mean():.4f}, max={score.max():.4f}\")\n",
    "\n",
    "all_scores  = np.concatenate(evt_scores)\n",
    "all_classes = np.concatenate(class_labels)\n",
    "\n",
    "if len(np.unique(all_classes)) > 1 and np.nanstd(all_scores) > 0:\n",
    "    rho, _ = spearmanr(all_classes, all_scores)\n",
    "    tau, _ = kendalltau(all_classes, all_scores)\n",
    "    print(f\"Spearman ρ = {rho:.3f}\")\n",
    "    print(f\"Kendall τ  = {tau:.3f}\")\n",
    "else:\n",
    "    print(\"Not enough variation to compute Spearman/Kendall correlations.\")\n",
    "\n",
    "print(\"Done. Check output folders:\")\n",
    "print(f\"  Attention plots: {out_attention}\")\n",
    "print(f\"  Uncertainty violin plots: {out_uncert}\")\n",
    "print(f\"  EVT plots: {out_evt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0afc4e-bc1c-45d5-886c-d396567afa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "import numpy as np\n",
    "\n",
    "# --- assume you’ve already run the model on X_test ---\n",
    "probs = model.predict_proba(X_test).ravel()\n",
    "preds = (probs >= threshold).astype(int)\n",
    "\n",
    "flare       = \"C\"\n",
    "time_window = \"72\"\n",
    "threshold   = 0.5\n",
    "\n",
    "# grab the probs & preds again (if needed)\n",
    "probs = model.predict_proba(X_test).ravel()\n",
    "preds = (probs >= threshold).astype(int)\n",
    "\n",
    "# list all your heatmap files\n",
    "files = glob.glob(f\"attention_plots/{flare}_{time_window}h_*.png\")\n",
    "\n",
    "# pattern to capture category and index\n",
    "pat = re.compile(rf\"{flare}_{time_window}h_(TP|TN|FP|FN)_(\\d+)\\.png\")\n",
    "\n",
    "buckets = {\"TP\": [], \"TN\": [], \"FP\": [], \"FN\": []}\n",
    "for fn in files:\n",
    "    m = pat.search(os.path.basename(fn))\n",
    "    if not m:\n",
    "        continue\n",
    "    cat, idx = m.group(1), int(m.group(2))\n",
    "    p = float(probs[idx])\n",
    "    buckets[cat].append((fn, p))\n",
    "\n",
    "# pick one per category nearest to that category's median prob\n",
    "picked = {}\n",
    "for cat, lst in buckets.items():\n",
    "    if not lst:\n",
    "        continue\n",
    "    ps = np.array([p for (_, p) in lst])\n",
    "    med = np.median(ps)\n",
    "    best = min(lst, key=lambda x: abs(x[1] - med))\n",
    "    picked[cat] = best\n",
    "\n",
    "print(\"Representative attention maps:\")\n",
    "for cat in [\"TP\",\"TN\",\"FP\",\"FN\"]:\n",
    "    fn, p = picked[cat]\n",
    "    print(f\"  {cat}: {fn}  (prob={p:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0915142-c8c3-483e-b3e6-f454cfba4b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EVEREST Environment",
   "language": "python",
   "name": "everest_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
