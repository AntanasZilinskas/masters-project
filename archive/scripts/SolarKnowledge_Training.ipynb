{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SolarKnowledge Model Training & Testing - PyTorch Implementation\n",
    "\n",
    "This notebook provides an interface to train and test SolarKnowledge models for solar flare prediction using the PyTorch implementation that exactly matches the TensorFlow version's behavior for direct comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install matplotlib seaborn tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu126\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure models directory is in the path\n",
    "models_dir = \"models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if models_dir not in sys.path:\n",
    "    sys.path.append(models_dir)\n",
    "\n",
    "# Import necessary modules\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Check if PyTorch is using GPU\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    print(\"Apple Silicon MPS available\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: enabling mixed precision training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 07:39:17.587672: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-09 07:39:21.063527: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-09 07:39:21.063568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-09 07:39:21.281960: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-09 07:39:21.438674: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-09 07:39:36.562829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-09 07:39:52.106074: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-05-09 07:39:52.295318: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: GPU device not found.\n",
      "Python version: 3.11.12\n",
      "Tensorflow bakcend version: 2.15.0\n",
      "\n",
      "CUDA available: enabling mixed precision training\n",
      "WARNING: GPU device not found.\n",
      "Python version: 3.11.12\n",
      "Tensorflow bakcend version: 2.15.0\n",
      "\n",
      "Successfully imported all modules\n",
      "\n",
      "Training Configuration:\n",
      "Flare Classes: C\n",
      "Time Windows: 24\n",
      "Version: Auto\n",
      "Description: A6000-optimised config: deeper, wider, faster\n",
      "Auto-increment: Yes\n",
      "\n",
      "Hyperparameters:\n",
      "Epochs: 200\n",
      "Early Stopping Patience: 15\n",
      "Learning Rate: 0.0003\n",
      "Optimizer: AdamW\n",
      "L1 Regularization: 1e-05\n",
      "L2 Regularization: 0.0001\n",
      "Scheduler: cosine_with_restarts (T_0=10, T_mult=2, min_lr=1e-06)\n",
      "Embedding Dimension: 256\n",
      "Transformer Blocks: 8\n",
      "Batch Size: 2048\n",
      "Using Focal Loss: Yes\n",
      "\n",
      "Starting Training...\n",
      "--------------------------------------------------\n",
      "\n",
      "Training model for C-class flares with 24h window\n",
      "Input shape: (10, 9)\n",
      "Using Categorical Focal Loss for rare event awareness\n",
      "Set regularization: L1=1e-05, L2=0.0001\n",
      "[2025-05-09 07:40:22] Training is initiated for time window: 24 and flare class: C \n",
      "[2025-05-09 07:40:22] Automatically using version v3.4 (next available) \n",
      "[2025-05-09 07:40:24] Class distribution: [13769. 29058.] \n",
      "[2025-05-09 07:40:24] Using class weights: {0: 1.0, 1: 0.4421536237869089} \n",
      "[2025-05-09 07:40:24] Starting training for C-class flares with 24h window \n",
      "\n",
      "Epoch 1/200\n",
      "Training: loss: 4.3057 - accuracy: 0.5949 - tss: 0.0824 - lr: 0.000300\n",
      "\n",
      "Epoch 2/200\n",
      "Training: loss: 3.8846 - accuracy: 0.6890 - tss: 0.1413 - lr: 0.000300\n",
      "\n",
      "Epoch 3/200\n",
      "Training: loss: 3.5872 - accuracy: 0.7139 - tss: 0.1728 - lr: 0.000300\n",
      "\n",
      "Epoch 4/200\n",
      "Training: loss: 3.2975 - accuracy: 0.7215 - tss: 0.1963 - lr: 0.000300\n",
      "\n",
      "Epoch 5/200\n",
      "Training: loss: 3.0248 - accuracy: 0.7193 - tss: 0.2085 - lr: 0.000300\n",
      "\n",
      "Epoch 6/200\n",
      "Training: loss: 2.7757 - accuracy: 0.7185 - tss: 0.2146 - lr: 0.000300\n",
      "\n",
      "Epoch 7/200\n",
      "Training: loss: 2.5515 - accuracy: 0.7243 - tss: 0.2218 - lr: 0.000300\n",
      "\n",
      "Epoch 8/200\n",
      "Training: loss: 2.3471 - accuracy: 0.7328 - tss: 0.2295 - lr: 0.000300\n",
      "\n",
      "Epoch 9/200\n",
      "Training: loss: 2.1623 - accuracy: 0.7321 - tss: 0.2349 - lr: 0.000300\n",
      "\n",
      "Epoch 10/200\n",
      "Training: loss: 1.9991 - accuracy: 0.7360 - tss: 0.2411 - lr: 0.000300\n",
      "\n",
      "Epoch 11/200\n",
      "Training: loss: 1.8543 - accuracy: 0.7401 - tss: 0.2469 - lr: 0.000300\n",
      "\n",
      "Epoch 12/200\n",
      "Training: loss: 1.7230 - accuracy: 0.7479 - tss: 0.2536 - lr: 0.000300\n",
      "\n",
      "Epoch 13/200\n",
      "Training: loss: 1.6085 - accuracy: 0.7556 - tss: 0.2615 - lr: 0.000300\n",
      "\n",
      "Epoch 14/200\n",
      "Training: loss: 1.5088 - accuracy: 0.7594 - tss: 0.2693 - lr: 0.000300\n",
      "\n",
      "Epoch 15/200\n",
      "Training: loss: 1.4185 - accuracy: 0.7728 - tss: 0.2786 - lr: 0.000300\n",
      "\n",
      "Epoch 16/200\n",
      "Training: loss: 1.3414 - accuracy: 0.7836 - tss: 0.2893 - lr: 0.000300\n",
      "\n",
      "Epoch 17/200\n",
      "Training: loss: 1.2719 - accuracy: 0.7967 - tss: 0.3011 - lr: 0.000300\n",
      "\n",
      "Epoch 18/200\n",
      "Training: loss: 1.2116 - accuracy: 0.8008 - tss: 0.3122 - lr: 0.000300\n",
      "\n",
      "Epoch 19/200\n",
      "Training: loss: 1.1544 - accuracy: 0.8164 - tss: 0.3244 - lr: 0.000300\n",
      "\n",
      "Epoch 20/200\n",
      "Training: loss: 1.1051 - accuracy: 0.8231 - tss: 0.3364 - lr: 0.000300\n",
      "\n",
      "Epoch 21/200\n",
      "Training: loss: 1.0615 - accuracy: 0.8257 - tss: 0.3476 - lr: 0.000300\n",
      "\n",
      "Epoch 22/200\n",
      "Training: loss: 1.0180 - accuracy: 0.8371 - tss: 0.3591 - lr: 0.000300\n",
      "\n",
      "Epoch 23/200\n",
      "Training: loss: 0.9802 - accuracy: 0.8451 - tss: 0.3705 - lr: 0.000300\n",
      "\n",
      "Epoch 24/200\n",
      "Training: loss: 0.9475 - accuracy: 0.8444 - tss: 0.3809 - lr: 0.000300\n",
      "\n",
      "Epoch 25/200\n",
      "Training: loss: 0.9136 - accuracy: 0.8561 - tss: 0.3917 - lr: 0.000300\n",
      "\n",
      "Epoch 26/200\n",
      "Training: loss: 0.8832 - accuracy: 0.8602 - tss: 0.4021 - lr: 0.000300\n",
      "\n",
      "Epoch 27/200\n",
      "Training: loss: 0.8591 - accuracy: 0.8552 - tss: 0.4112 - lr: 0.000300\n",
      "\n",
      "Epoch 28/200\n",
      "Training: loss: 0.8303 - accuracy: 0.8693 - tss: 0.4211 - lr: 0.000300\n",
      "\n",
      "Epoch 29/200\n",
      "Training: loss: 0.8072 - accuracy: 0.8685 - tss: 0.4302 - lr: 0.000300\n",
      "\n",
      "Epoch 30/200\n",
      "Training: loss: 0.7855 - accuracy: 0.8723 - tss: 0.4389 - lr: 0.000300\n",
      "\n",
      "Epoch 31/200\n",
      "Training: loss: 0.7651 - accuracy: 0.8742 - tss: 0.4472 - lr: 0.000300\n",
      "\n",
      "Epoch 32/200\n",
      "Training: loss: 0.7470 - accuracy: 0.8702 - tss: 0.4548 - lr: 0.000300\n",
      "\n",
      "Epoch 33/200\n",
      "Training: loss: 0.7270 - accuracy: 0.8779 - tss: 0.4624 - lr: 0.000300\n",
      "\n",
      "Epoch 34/200\n",
      "Training: loss: 0.7100 - accuracy: 0.8781 - tss: 0.4696 - lr: 0.000300\n",
      "\n",
      "Epoch 35/200\n",
      "Training: loss: 0.6935 - accuracy: 0.8821 - tss: 0.4767 - lr: 0.000300\n",
      "\n",
      "Epoch 36/200\n",
      "Training: loss: 0.6770 - accuracy: 0.8850 - tss: 0.4837 - lr: 0.000300\n",
      "\n",
      "Epoch 37/200\n",
      "Training: loss: 0.6621 - accuracy: 0.8881 - tss: 0.4904 - lr: 0.000300\n",
      "\n",
      "Epoch 38/200\n",
      "Training: loss: 0.6471 - accuracy: 0.8924 - tss: 0.4969 - lr: 0.000300\n",
      "\n",
      "Epoch 39/200\n",
      "Training: loss: 0.6349 - accuracy: 0.8913 - tss: 0.5032 - lr: 0.000300\n",
      "\n",
      "Epoch 40/200\n",
      "Training: loss: 0.6223 - accuracy: 0.8927 - tss: 0.5093 - lr: 0.000300\n",
      "\n",
      "Epoch 41/200\n",
      "Training: loss: 0.6091 - accuracy: 0.8941 - tss: 0.5151 - lr: 0.000300\n",
      "\n",
      "Epoch 42/200\n",
      "Training: loss: 0.5986 - accuracy: 0.8952 - tss: 0.5207 - lr: 0.000300\n",
      "\n",
      "Epoch 43/200\n",
      "Training: loss: 0.5869 - accuracy: 0.8989 - tss: 0.5262 - lr: 0.000300\n",
      "\n",
      "Epoch 44/200\n",
      "Training: loss: 0.5755 - accuracy: 0.9031 - tss: 0.5318 - lr: 0.000300\n",
      "\n",
      "Epoch 45/200\n",
      "Training: loss: 0.5650 - accuracy: 0.9042 - tss: 0.5371 - lr: 0.000300\n",
      "\n",
      "Epoch 46/200\n",
      "Training: loss: 0.5554 - accuracy: 0.9061 - tss: 0.5423 - lr: 0.000300\n",
      "\n",
      "Epoch 47/200\n",
      "Training: loss: 0.5454 - accuracy: 0.9067 - tss: 0.5474 - lr: 0.000300\n",
      "\n",
      "Epoch 48/200\n",
      "Training: loss: 0.5375 - accuracy: 0.9053 - tss: 0.5521 - lr: 0.000300\n",
      "\n",
      "Epoch 49/200\n",
      "Training: loss: 0.5278 - accuracy: 0.9100 - tss: 0.5569 - lr: 0.000300\n",
      "\n",
      "Epoch 50/200\n",
      "Training: loss: 0.5192 - accuracy: 0.9115 - tss: 0.5615 - lr: 0.000300\n",
      "\n",
      "Epoch 51/200\n",
      "Training: loss: 0.5113 - accuracy: 0.9133 - tss: 0.5661 - lr: 0.000300\n",
      "\n",
      "Epoch 52/200\n",
      "Training: loss: 0.5040 - accuracy: 0.9121 - tss: 0.5704 - lr: 0.000300\n",
      "\n",
      "Epoch 53/200\n",
      "Training: loss: 0.4967 - accuracy: 0.9146 - tss: 0.5747 - lr: 0.000300\n",
      "\n",
      "Epoch 54/200\n",
      "Training: loss: 0.4888 - accuracy: 0.9158 - tss: 0.5789 - lr: 0.000300\n",
      "\n",
      "Epoch 55/200\n",
      "Training: loss: 0.4818 - accuracy: 0.9183 - tss: 0.5831 - lr: 0.000300\n",
      "\n",
      "Epoch 56/200\n",
      "Training: loss: 0.4737 - accuracy: 0.9209 - tss: 0.5872 - lr: 0.000300\n",
      "\n",
      "Epoch 57/200\n",
      "Training: loss: 0.4682 - accuracy: 0.9197 - tss: 0.5911 - lr: 0.000300\n",
      "\n",
      "Epoch 58/200\n",
      "Training: loss: 0.4629 - accuracy: 0.9180 - tss: 0.5949 - lr: 0.000300\n",
      "\n",
      "Epoch 59/200\n",
      "Training: loss: 0.4553 - accuracy: 0.9224 - tss: 0.5986 - lr: 0.000300\n",
      "\n",
      "Epoch 60/200\n",
      "Training: loss: 0.4481 - accuracy: 0.9265 - tss: 0.6024 - lr: 0.000300\n",
      "\n",
      "Epoch 61/200\n",
      "Training: loss: 0.4426 - accuracy: 0.9265 - tss: 0.6061 - lr: 0.000300\n",
      "\n",
      "Epoch 62/200\n",
      "Training: loss: 0.4368 - accuracy: 0.9273 - tss: 0.6097 - lr: 0.000300\n",
      "\n",
      "Epoch 63/200\n",
      "Training: loss: 0.4317 - accuracy: 0.9263 - tss: 0.6132 - lr: 0.000300\n",
      "\n",
      "Epoch 64/200\n",
      "Training: loss: 0.4260 - accuracy: 0.9297 - tss: 0.6166 - lr: 0.000300\n",
      "\n",
      "Epoch 65/200\n",
      "Training: loss: 0.4214 - accuracy: 0.9268 - tss: 0.6199 - lr: 0.000300\n",
      "\n",
      "Epoch 66/200\n",
      "Training: loss: 0.4158 - accuracy: 0.9281 - tss: 0.6231 - lr: 0.000300\n",
      "\n",
      "Epoch 67/200\n",
      "Training: loss: 0.4118 - accuracy: 0.9273 - tss: 0.6262 - lr: 0.000300\n",
      "\n",
      "Epoch 68/200\n",
      "Training: loss: 0.4059 - accuracy: 0.9315 - tss: 0.6293 - lr: 0.000300\n",
      "\n",
      "Epoch 69/200\n",
      "Training: loss: 0.4015 - accuracy: 0.9304 - tss: 0.6323 - lr: 0.000300\n",
      "\n",
      "Epoch 70/200\n",
      "Training: loss: 0.3976 - accuracy: 0.9306 - tss: 0.6352 - lr: 0.000300\n",
      "\n",
      "Epoch 71/200\n",
      "Training: loss: 0.3923 - accuracy: 0.9335 - tss: 0.6382 - lr: 0.000300\n",
      "\n",
      "Epoch 72/200\n",
      "Training: loss: 0.3874 - accuracy: 0.9338 - tss: 0.6411 - lr: 0.000300\n",
      "\n",
      "Epoch 73/200\n",
      "Training: loss: 0.3829 - accuracy: 0.9357 - tss: 0.6439 - lr: 0.000300\n",
      "\n",
      "Epoch 74/200\n",
      "Training: loss: 0.3786 - accuracy: 0.9363 - tss: 0.6467 - lr: 0.000300\n",
      "\n",
      "Epoch 75/200\n",
      "Training: loss: 0.3739 - accuracy: 0.9383 - tss: 0.6495 - lr: 0.000300\n",
      "\n",
      "Epoch 76/200\n",
      "Training: loss: 0.3700 - accuracy: 0.9384 - tss: 0.6522 - lr: 0.000300\n",
      "\n",
      "Epoch 77/200\n",
      "Training: loss: 0.3665 - accuracy: 0.9383 - tss: 0.6549 - lr: 0.000300\n",
      "\n",
      "Epoch 78/200\n",
      "Training: loss: 0.3634 - accuracy: 0.9364 - tss: 0.6574 - lr: 0.000300\n",
      "\n",
      "Epoch 79/200\n",
      "Training: loss: 0.3588 - accuracy: 0.9378 - tss: 0.6599 - lr: 0.000300\n",
      "\n",
      "Epoch 80/200\n",
      "Training: loss: 0.3565 - accuracy: 0.9351 - tss: 0.6622 - lr: 0.000300\n",
      "\n",
      "Epoch 81/200\n",
      "Training: loss: 0.3523 - accuracy: 0.9376 - tss: 0.6646 - lr: 0.000300\n",
      "\n",
      "Epoch 82/200\n",
      "Training: loss: 0.3480 - accuracy: 0.9392 - tss: 0.6670 - lr: 0.000300\n",
      "\n",
      "Epoch 83/200\n",
      "Training: loss: 0.3443 - accuracy: 0.9412 - tss: 0.6694 - lr: 0.000300\n",
      "\n",
      "Epoch 84/200\n",
      "Training: loss: 0.3414 - accuracy: 0.9399 - tss: 0.6716 - lr: 0.000300\n",
      "\n",
      "Epoch 85/200\n",
      "Training: loss: 0.3372 - accuracy: 0.9416 - tss: 0.6739 - lr: 0.000300\n",
      "\n",
      "Epoch 86/200\n",
      "Training: loss: 0.3335 - accuracy: 0.9448 - tss: 0.6762 - lr: 0.000300\n",
      "\n",
      "Epoch 87/200\n",
      "Training: loss: 0.3307 - accuracy: 0.9434 - tss: 0.6784 - lr: 0.000300\n",
      "\n",
      "Epoch 88/200\n",
      "Training: loss: 0.3288 - accuracy: 0.9402 - tss: 0.6805 - lr: 0.000300\n",
      "\n",
      "Epoch 89/200\n",
      "Training: loss: 0.3240 - accuracy: 0.9446 - tss: 0.6826 - lr: 0.000300\n",
      "\n",
      "Epoch 90/200\n",
      "Training: loss: 0.3205 - accuracy: 0.9471 - tss: 0.6848 - lr: 0.000300\n",
      "\n",
      "Epoch 91/200\n",
      "Training: loss: 0.3181 - accuracy: 0.9444 - tss: 0.6868 - lr: 0.000300\n",
      "\n",
      "Epoch 92/200\n",
      "Training: loss: 0.3151 - accuracy: 0.9441 - tss: 0.6888 - lr: 0.000300\n",
      "\n",
      "Epoch 93/200\n",
      "Training: loss: 0.3116 - accuracy: 0.9476 - tss: 0.6909 - lr: 0.000300\n",
      "\n",
      "Epoch 94/200\n",
      "Training: loss: 0.3090 - accuracy: 0.9465 - tss: 0.6928 - lr: 0.000300\n",
      "\n",
      "Epoch 95/200\n",
      "Training: loss: 0.3057 - accuracy: 0.9476 - tss: 0.6948 - lr: 0.000300\n",
      "\n",
      "Epoch 96/200\n",
      "Training: loss: 0.3029 - accuracy: 0.9486 - tss: 0.6967 - lr: 0.000300\n",
      "\n",
      "Epoch 97/200\n",
      "Training: loss: 0.2993 - accuracy: 0.9509 - tss: 0.6987 - lr: 0.000300\n",
      "\n",
      "Epoch 98/200\n",
      "Training: loss: 0.2971 - accuracy: 0.9486 - tss: 0.7005 - lr: 0.000300\n",
      "\n",
      "Epoch 99/200\n",
      "Training: loss: 0.2948 - accuracy: 0.9491 - tss: 0.7024 - lr: 0.000300\n",
      "\n",
      "Epoch 100/200\n",
      "Training: loss: 0.2919 - accuracy: 0.9493 - tss: 0.7042 - lr: 0.000300\n",
      "\n",
      "Epoch 101/200\n",
      "Training: loss: 0.2894 - accuracy: 0.9494 - tss: 0.7059 - lr: 0.000300\n",
      "\n",
      "Epoch 102/200\n",
      "Training: loss: 0.2867 - accuracy: 0.9500 - tss: 0.7077 - lr: 0.000300\n",
      "\n",
      "Epoch 103/200\n",
      "Training: loss: 0.2840 - accuracy: 0.9500 - tss: 0.7094 - lr: 0.000300\n",
      "\n",
      "Epoch 104/200\n",
      "Training: loss: 0.2816 - accuracy: 0.9497 - tss: 0.7111 - lr: 0.000300\n",
      "\n",
      "Epoch 105/200\n",
      "Training: loss: 0.2796 - accuracy: 0.9497 - tss: 0.7127 - lr: 0.000300\n",
      "\n",
      "Epoch 106/200\n",
      "Training: loss: 0.2771 - accuracy: 0.9502 - tss: 0.7143 - lr: 0.000300\n",
      "\n",
      "Epoch 107/200\n",
      "Training: loss: 0.2744 - accuracy: 0.9515 - tss: 0.7160 - lr: 0.000300\n",
      "\n",
      "Epoch 108/200\n",
      "Training: loss: 0.2730 - accuracy: 0.9484 - tss: 0.7175 - lr: 0.000300\n",
      "\n",
      "Epoch 109/200\n",
      "Training: loss: 0.2714 - accuracy: 0.9481 - tss: 0.7190 - lr: 0.000300\n",
      "\n",
      "Epoch 110/200\n",
      "Training: loss: 0.2685 - accuracy: 0.9485 - tss: 0.7204 - lr: 0.000300\n",
      "\n",
      "Epoch 111/200\n",
      "Training: loss: 0.2662 - accuracy: 0.9493 - tss: 0.7219 - lr: 0.000300\n",
      "\n",
      "Epoch 112/200\n",
      "Training: loss: 0.2631 - accuracy: 0.9510 - tss: 0.7234 - lr: 0.000300\n",
      "\n",
      "Epoch 113/200\n",
      "Training: loss: 0.2608 - accuracy: 0.9530 - tss: 0.7249 - lr: 0.000300\n",
      "\n",
      "Epoch 114/200\n",
      "Training: loss: 0.2579 - accuracy: 0.9547 - tss: 0.7264 - lr: 0.000300\n",
      "\n",
      "Epoch 115/200\n",
      "Training: loss: 0.2556 - accuracy: 0.9542 - tss: 0.7278 - lr: 0.000300\n",
      "\n",
      "Epoch 116/200\n",
      "Training: loss: 0.2537 - accuracy: 0.9539 - tss: 0.7292 - lr: 0.000300\n",
      "\n",
      "Epoch 117/200\n",
      "Training: loss: 0.2515 - accuracy: 0.9538 - tss: 0.7306 - lr: 0.000300\n",
      "\n",
      "Epoch 118/200\n",
      "Training: loss: 0.2488 - accuracy: 0.9555 - tss: 0.7320 - lr: 0.000300\n",
      "\n",
      "Epoch 119/200\n",
      "Training: loss: 0.2469 - accuracy: 0.9558 - tss: 0.7334 - lr: 0.000300\n",
      "\n",
      "Epoch 120/200\n",
      "Training: loss: 0.2450 - accuracy: 0.9564 - tss: 0.7348 - lr: 0.000300\n",
      "\n",
      "Epoch 121/200\n",
      "Training: loss: 0.2445 - accuracy: 0.9514 - tss: 0.7361 - lr: 0.000300\n",
      "\n",
      "Epoch 122/200\n",
      "Training: loss: 0.2419 - accuracy: 0.9539 - tss: 0.7374 - lr: 0.000300\n",
      "\n",
      "Epoch 123/200\n",
      "Training: loss: 0.2397 - accuracy: 0.9547 - tss: 0.7387 - lr: 0.000300\n",
      "\n",
      "Epoch 124/200\n",
      "Training: loss: 0.2367 - accuracy: 0.9572 - tss: 0.7400 - lr: 0.000300\n",
      "\n",
      "Epoch 125/200\n",
      "Training: loss: 0.2359 - accuracy: 0.9540 - tss: 0.7412 - lr: 0.000300\n",
      "\n",
      "Epoch 126/200\n",
      "Training: loss: 0.2344 - accuracy: 0.9541 - tss: 0.7424 - lr: 0.000300\n",
      "\n",
      "Epoch 127/200\n",
      "Training: loss: 0.2316 - accuracy: 0.9562 - tss: 0.7436 - lr: 0.000300\n",
      "\n",
      "Epoch 128/200\n",
      "Training: loss: 0.2294 - accuracy: 0.9577 - tss: 0.7449 - lr: 0.000300\n",
      "\n",
      "Epoch 129/200\n",
      "Training: loss: 0.2280 - accuracy: 0.9573 - tss: 0.7461 - lr: 0.000300\n",
      "\n",
      "Epoch 130/200\n",
      "Training: loss: 0.2255 - accuracy: 0.9583 - tss: 0.7473 - lr: 0.000300\n",
      "\n",
      "Epoch 131/200\n",
      "Training: loss: 0.2240 - accuracy: 0.9584 - tss: 0.7485 - lr: 0.000300\n",
      "\n",
      "Epoch 132/200\n",
      "Training: loss: 0.2217 - accuracy: 0.9588 - tss: 0.7496 - lr: 0.000300\n",
      "\n",
      "Epoch 133/200\n",
      "Training: loss: 0.2201 - accuracy: 0.9577 - tss: 0.7508 - lr: 0.000300\n",
      "\n",
      "Epoch 134/200\n",
      "Training: loss: 0.2186 - accuracy: 0.9578 - tss: 0.7519 - lr: 0.000300\n",
      "\n",
      "Epoch 135/200\n",
      "Training: loss: 0.2171 - accuracy: 0.9580 - tss: 0.7530 - lr: 0.000300\n",
      "\n",
      "Epoch 136/200\n",
      "Training: loss: 0.2148 - accuracy: 0.9594 - tss: 0.7542 - lr: 0.000300\n",
      "\n",
      "Epoch 137/200\n",
      "Training: loss: 0.2135 - accuracy: 0.9592 - tss: 0.7553 - lr: 0.000300\n",
      "\n",
      "Epoch 138/200\n",
      "Training: loss: 0.2120 - accuracy: 0.9590 - tss: 0.7563 - lr: 0.000300\n",
      "\n",
      "Epoch 139/200\n",
      "Training: loss: 0.2102 - accuracy: 0.9586 - tss: 0.7574 - lr: 0.000300\n",
      "\n",
      "Epoch 140/200\n",
      "Training: loss: 0.2084 - accuracy: 0.9587 - tss: 0.7585 - lr: 0.000300\n",
      "\n",
      "Epoch 141/200\n",
      "Training: loss: 0.2068 - accuracy: 0.9596 - tss: 0.7595 - lr: 0.000300\n",
      "\n",
      "Epoch 142/200\n",
      "Training: loss: 0.2054 - accuracy: 0.9595 - tss: 0.7605 - lr: 0.000300\n",
      "\n",
      "Epoch 143/200\n",
      "Training: loss: 0.2033 - accuracy: 0.9611 - tss: 0.7616 - lr: 0.000300\n",
      "\n",
      "Epoch 144/200\n",
      "Training: loss: 0.2013 - accuracy: 0.9614 - tss: 0.7626 - lr: 0.000300\n",
      "\n",
      "Epoch 145/200\n",
      "Training: loss: 0.1995 - accuracy: 0.9620 - tss: 0.7637 - lr: 0.000300\n",
      "\n",
      "Epoch 146/200\n",
      "Training: loss: 0.1977 - accuracy: 0.9629 - tss: 0.7647 - lr: 0.000300\n",
      "\n",
      "Epoch 147/200\n",
      "Training: loss: 0.1968 - accuracy: 0.9625 - tss: 0.7657 - lr: 0.000300\n",
      "\n",
      "Epoch 148/200\n",
      "Training: loss: 0.1953 - accuracy: 0.9614 - tss: 0.7667 - lr: 0.000300\n",
      "\n",
      "Epoch 149/200\n",
      "Training: loss: 0.1936 - accuracy: 0.9624 - tss: 0.7676 - lr: 0.000300\n",
      "\n",
      "Epoch 150/200\n",
      "Training: loss: 0.1922 - accuracy: 0.9622 - tss: 0.7686 - lr: 0.000300\n",
      "\n",
      "Epoch 151/200\n",
      "Training: loss: 0.1911 - accuracy: 0.9617 - tss: 0.7696 - lr: 0.000300\n",
      "\n",
      "Epoch 152/200\n",
      "Training: loss: 0.1895 - accuracy: 0.9629 - tss: 0.7705 - lr: 0.000300\n",
      "\n",
      "Epoch 153/200\n",
      "Training: loss: 0.1877 - accuracy: 0.9635 - tss: 0.7714 - lr: 0.000300\n",
      "\n",
      "Epoch 154/200\n",
      "Training: loss: 0.1865 - accuracy: 0.9631 - tss: 0.7724 - lr: 0.000300\n",
      "\n",
      "Epoch 155/200\n",
      "Training: loss: 0.1859 - accuracy: 0.9615 - tss: 0.7733 - lr: 0.000300\n",
      "\n",
      "Epoch 156/200\n",
      "Training: loss: 0.1836 - accuracy: 0.9641 - tss: 0.7742 - lr: 0.000300\n",
      "\n",
      "Epoch 157/200\n",
      "Training: loss: 0.1823 - accuracy: 0.9638 - tss: 0.7751 - lr: 0.000300\n",
      "\n",
      "Epoch 158/200\n",
      "Training: loss: 0.1817 - accuracy: 0.9624 - tss: 0.7760 - lr: 0.000300\n",
      "\n",
      "Epoch 159/200\n",
      "Training: loss: 0.1802 - accuracy: 0.9638 - tss: 0.7769 - lr: 0.000300\n",
      "\n",
      "Epoch 160/200\n",
      "Training: loss: 0.1791 - accuracy: 0.9630 - tss: 0.7777 - lr: 0.000300\n",
      "\n",
      "Epoch 161/200\n",
      "Training: loss: 0.1773 - accuracy: 0.9640 - tss: 0.7786 - lr: 0.000300\n",
      "\n",
      "Epoch 162/200\n",
      "Training: loss: 0.1759 - accuracy: 0.9638 - tss: 0.7794 - lr: 0.000300\n",
      "\n",
      "Epoch 163/200\n",
      "Training: loss: 0.1745 - accuracy: 0.9642 - tss: 0.7803 - lr: 0.000300\n",
      "\n",
      "Epoch 164/200\n",
      "Training: loss: 0.1739 - accuracy: 0.9623 - tss: 0.7811 - lr: 0.000300\n",
      "\n",
      "Epoch 165/200\n",
      "Training: loss: 0.1721 - accuracy: 0.9646 - tss: 0.7819 - lr: 0.000300\n",
      "\n",
      "Epoch 166/200\n",
      "Training: loss: 0.1712 - accuracy: 0.9647 - tss: 0.7827 - lr: 0.000300\n",
      "\n",
      "Epoch 167/200\n",
      "Training: loss: 0.1695 - accuracy: 0.9660 - tss: 0.7835 - lr: 0.000300\n",
      "\n",
      "Epoch 168/200\n",
      "Training: loss: 0.1696 - accuracy: 0.9633 - tss: 0.7843 - lr: 0.000300\n",
      "EarlyStopping: 1/15\n",
      "\n",
      "Epoch 169/200\n",
      "Training: loss: 0.1678 - accuracy: 0.9651 - tss: 0.7851 - lr: 0.000300\n",
      "\n",
      "Epoch 170/200\n",
      "Training: loss: 0.1655 - accuracy: 0.9667 - tss: 0.7859 - lr: 0.000300\n",
      "\n",
      "Epoch 171/200\n",
      "Training: loss: 0.1642 - accuracy: 0.9674 - tss: 0.7867 - lr: 0.000300\n",
      "\n",
      "Epoch 172/200\n",
      "Training: loss: 0.1632 - accuracy: 0.9667 - tss: 0.7875 - lr: 0.000300\n",
      "\n",
      "Epoch 173/200\n",
      "Training: loss: 0.1622 - accuracy: 0.9674 - tss: 0.7883 - lr: 0.000300\n",
      "\n",
      "Epoch 174/200\n",
      "Training: loss: 0.1613 - accuracy: 0.9659 - tss: 0.7891 - lr: 0.000300\n",
      "\n",
      "Epoch 175/200\n",
      "Training: loss: 0.1599 - accuracy: 0.9669 - tss: 0.7898 - lr: 0.000300\n",
      "\n",
      "Epoch 176/200\n",
      "Training: loss: 0.1590 - accuracy: 0.9672 - tss: 0.7906 - lr: 0.000300\n",
      "\n",
      "Epoch 177/200\n",
      "Training: loss: 0.1584 - accuracy: 0.9657 - tss: 0.7913 - lr: 0.000300\n",
      "\n",
      "Epoch 178/200\n",
      "Training: loss: 0.1573 - accuracy: 0.9666 - tss: 0.7921 - lr: 0.000300\n",
      "\n",
      "Epoch 179/200\n",
      "Training: loss: 0.1561 - accuracy: 0.9661 - tss: 0.7928 - lr: 0.000300\n",
      "\n",
      "Epoch 180/200\n",
      "Training: loss: 0.1550 - accuracy: 0.9662 - tss: 0.7935 - lr: 0.000300\n",
      "\n",
      "Epoch 181/200\n",
      "Training: loss: 0.1528 - accuracy: 0.9687 - tss: 0.7942 - lr: 0.000300\n",
      "\n",
      "Epoch 182/200\n",
      "Training: loss: 0.1523 - accuracy: 0.9688 - tss: 0.7949 - lr: 0.000300\n",
      "\n",
      "Epoch 183/200\n",
      "Training: loss: 0.1511 - accuracy: 0.9687 - tss: 0.7957 - lr: 0.000300\n",
      "\n",
      "Epoch 184/200\n",
      "Training: loss: 0.1505 - accuracy: 0.9681 - tss: 0.7964 - lr: 0.000300\n",
      "\n",
      "Epoch 185/200\n",
      "Training: loss: 0.1500 - accuracy: 0.9671 - tss: 0.7971 - lr: 0.000300\n",
      "\n",
      "Epoch 186/200\n",
      "Training: loss: 0.1488 - accuracy: 0.9676 - tss: 0.7977 - lr: 0.000300\n",
      "\n",
      "Epoch 187/200\n",
      "Training: loss: 0.1479 - accuracy: 0.9676 - tss: 0.7984 - lr: 0.000300\n",
      "\n",
      "Epoch 188/200\n",
      "Training: loss: 0.1460 - accuracy: 0.9701 - tss: 0.7991 - lr: 0.000300\n",
      "\n",
      "Epoch 189/200\n",
      "Training: loss: 0.1456 - accuracy: 0.9682 - tss: 0.7998 - lr: 0.000300\n",
      "\n",
      "Epoch 190/200\n",
      "Training: loss: 0.1447 - accuracy: 0.9681 - tss: 0.8005 - lr: 0.000300\n",
      "\n",
      "Epoch 191/200\n",
      "Training: loss: 0.1429 - accuracy: 0.9703 - tss: 0.8011 - lr: 0.000300\n",
      "\n",
      "Epoch 192/200\n",
      "Training: loss: 0.1424 - accuracy: 0.9704 - tss: 0.8018 - lr: 0.000300\n",
      "\n",
      "Epoch 193/200\n",
      "Training: loss: 0.1413 - accuracy: 0.9701 - tss: 0.8025 - lr: 0.000300\n",
      "\n",
      "Epoch 194/200\n",
      "Training: loss: 0.1412 - accuracy: 0.9679 - tss: 0.8031 - lr: 0.000300\n",
      "\n",
      "Epoch 195/200\n",
      "Training: loss: 0.1398 - accuracy: 0.9715 - tss: 0.8038 - lr: 0.000300\n",
      "\n",
      "Epoch 196/200\n",
      "Training: loss: 0.1390 - accuracy: 0.9693 - tss: 0.8044 - lr: 0.000300\n",
      "\n",
      "Epoch 197/200\n",
      "Training: loss: 0.1384 - accuracy: 0.9689 - tss: 0.8050 - lr: 0.000300\n",
      "\n",
      "Epoch 198/200\n",
      "Training: loss: 0.1377 - accuracy: 0.9693 - tss: 0.8057 - lr: 0.000300\n",
      "\n",
      "Epoch 199/200\n",
      "Training: loss: 0.1367 - accuracy: 0.9706 - tss: 0.8063 - lr: 0.000300\n",
      "\n",
      "Epoch 200/200\n",
      "Training: loss: 0.1355 - accuracy: 0.9701 - tss: 0.8069 - lr: 0.000300\n",
      "Saving model weights to directory: models/SolarKnowledge-v3.4-C-24h\n",
      "Model saved to models/SolarKnowledge-v3.4-C-24h\n",
      "[2025-05-09 07:45:11] Model saved to models/SolarKnowledge-v3.4-C-24h \n",
      "\n",
      "Model saved to models/SolarKnowledge-v3.4-C-24h\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing Configuration:\n",
      "Flare Classes: C\n",
      "Time Windows: 24\n",
      "Monte Carlo Passes: 30\n",
      "Generate Uncertainty Plots: Yes\n",
      "Test Latest Models: Yes\n",
      "Test Specific Version: No\n",
      "\n",
      "Testing model for C-class flares with 24h window\n",
      "--------------------------------------------------\n",
      "Testing model at: models/SolarKnowledge-v3.4-C-24h\n",
      "[2025-05-09 07:45:11] Testing initiated for time window: 24 and flare class: C \n",
      "[2025-05-09 07:45:13] Test data positive label ratio: 0.6785 \n",
      "[2025-05-09 07:45:16] Train data positive label ratio: 0.6785 \n",
      "[2025-05-09 07:45:16] Checking data statistics for diagnostics... \n",
      "[2025-05-09 07:45:16] X_test sample: [0. 0. 0. 0. 0.] \n",
      "[2025-05-09 07:45:16] X_train sample: [0. 0. 0. 0. 0.] \n",
      "[2025-05-09 07:45:16] Training data mean: [0.69428184 0.62894614 0.99067656 0.87684039 0.55027902] \n",
      "[2025-05-09 07:45:16] Training data std: [1.33961408 1.47582328 1.46004184 1.39755292 0.799842  ] \n",
      "[2025-05-09 07:45:16] Data is already normalized, skipping normalization \n",
      "[2025-05-09 07:45:16] Train y data type: <class 'list'>, shape: (42827,) \n",
      "[2025-05-09 07:45:16] Test y data type: <class 'list'>, shape: (42827,) \n",
      "[2025-05-09 07:45:16] FIXED Training distribution: 13769 negative, 29058 positive \n",
      "[2025-05-09 07:45:16] FIXED Testing distribution: 13769 negative, 29058 positive \n",
      "[2025-05-09 07:45:16] REVISED Train positive ratio: 0.6785 \n",
      "[2025-05-09 07:45:16] REVISED Test positive ratio: 0.6785 \n",
      "[2025-05-09 07:45:16] Train minority is positive: False \n",
      "[2025-05-09 07:45:16] Test minority is positive: False \n",
      "[2025-05-09 07:45:16] Labels likely inverted: False \n",
      "[2025-05-09 07:45:16] Ratio mismatch: False \n",
      "[2025-05-09 07:45:16] Using model at: models/SolarKnowledge-v3.4-C-24h \n",
      "Loading weights from model dir: models/SolarKnowledge-v3.4-C-24h\n",
      "[2025-05-09 07:45:16] WARNING: Metadata embed_dim (128) doesn't match weights (256). Using value from weights. \n",
      "[2025-05-09 07:45:16] WARNING: Metadata transformer_blocks (6) doesn't match weights (8). Using value from weights. \n",
      "[2025-05-09 07:45:16] WARNING: Metadata ff_dim (256) doesn't match weights (1024). Using value from weights. \n",
      "[2025-05-09 07:45:16] Building model based on metadata: embed_dim=256, transformer_blocks=8, heads=4, ff_dim=1024 \n",
      "Using Categorical Focal Loss for rare event awareness\n",
      "Loading weights from model dir: models/SolarKnowledge-v3.4-C-24h\n",
      "[2025-05-09 07:45:16] Successfully loaded weights from models/SolarKnowledge-v3.4-C-24h \n",
      "[2025-05-09 07:45:16] Using Monte Carlo dropout with 30 passes for robust prediction \n",
      "Performing 30 MC dropout passes...\n",
      "MC pass 1/30\n",
      "MC pass 6/30\n",
      "MC pass 11/30\n",
      "MC pass 16/30\n",
      "MC pass 21/30\n",
      "MC pass 26/30\n",
      "[2025-05-09 07:45:43] Raw prediction statistics: \n",
      "[2025-05-09 07:45:43] Mean positive probability: 0.6348 \n",
      "[2025-05-09 07:45:43] Median positive probability: 0.6310 \n",
      "[2025-05-09 07:45:43] Min positive probability: 0.0977 \n",
      "[2025-05-09 07:45:43] Max positive probability: 0.9997 \n",
      "[2025-05-09 07:45:43] Std of positive probability: 0.1811 \n",
      "[2025-05-09 07:45:43] Saved probability distribution plot to models/SolarKnowledge-v3.4-C-24h/probability_distribution_20250509074543.png \n",
      "[2025-05-09 07:45:43] Applying probability calibration using Platt scaling... \n",
      "[2025-05-09 07:45:43] Saved calibrated probability distribution plot to models/SolarKnowledge-v3.4-C-24h/calibrated_probability_distribution_20250509074543.png \n",
      "[2025-05-09 07:45:43] Using calibrated probabilities for predictions \n",
      "[2025-05-09 07:45:43] Mean calibrated probability: 0.6800 \n",
      "[2025-05-09 07:45:43] Median calibrated probability: 0.8541 \n",
      "[2025-05-09 07:45:43] Best threshold for calibrated probabilities: 0.6930, TSS: 0.7500 \n",
      "[2025-05-09 07:45:43] Predictions using calibrated probabilities: Positive ratio = 0.6029 \n",
      "Performing 30 MC dropout passes...\n",
      "MC pass 1/30\n",
      "MC pass 6/30\n",
      "MC pass 11/30\n",
      "MC pass 16/30\n",
      "MC pass 21/30\n",
      "MC pass 26/30\n",
      "[2025-05-09 07:45:46] Finding optimal classification threshold using validation data... \n",
      "[2025-05-09 07:45:46] Validation data has 1564 negative samples and 3436 positive samples \n",
      "[2025-05-09 07:45:46] Positive ratio: 0.6872 \n",
      "[2025-05-09 07:45:50] Optimal threshold (maximizing TSS): 0.5839 \n",
      "[2025-05-09 07:45:50] Optimal TSS: 0.7282 \n",
      "[2025-05-09 07:45:50] At optimal threshold - Precision: 0.9505, Recall: 0.8222 \n",
      "[2025-05-09 07:45:50] Balanced threshold (TSS + weighted precision/recall): 0.6061 \n",
      "[2025-05-09 07:45:50] Balanced TSS: 0.7145 \n",
      "[2025-05-09 07:45:50] At balanced threshold - Precision: 0.9665, Recall: 0.7733 \n",
      "[2025-05-09 07:45:50] Using balanced threshold: 0.6061 \n",
      "[2025-05-09 07:45:50] Predictions using optimal threshold: Positive ratio = 0.5465 \n",
      "[2025-05-09 07:45:50] Predictions using default threshold (0.5): Positive ratio = 0.7486 \n",
      "[2025-05-09 07:45:52] Saved uncertainty visualization plots to models/SolarKnowledge-v3.4-C-24h \n",
      "==============================================\n",
      "Accuracy for flare class C with time window 24: 0.8361\n",
      "TSS (True Skill Statistic): 0.7323\n",
      "Sensitivity (True Positive Rate): 0.7820\n",
      "Specificity (True Negative Rate): 0.9504\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.79     13769\n",
      "           1       0.97      0.78      0.87     29058\n",
      "\n",
      "    accuracy                           0.84     42827\n",
      "   macro avg       0.82      0.87      0.83     42827\n",
      "weighted avg       0.88      0.84      0.84     42827\n",
      "\n",
      "\n",
      "Comparison with default threshold (argmax):\n",
      "Accuracy: 0.8620\n",
      "TSS: 0.6264\n",
      "Sensitivity: 0.9500\n",
      "Specificity: 0.6764\n",
      "==============================================\n",
      "\n",
      "\n",
      "[2025-05-09 07:45:52] Updated metadata file at models/SolarKnowledge-v3.4-C-24h/metadata.json with test results \n",
      "\n",
      "Test Results Summary:\n",
      "Accuracy: 0.8361\n",
      "TSS: 0.7323\n",
      "Precision: 0.9708\n",
      "Recall: 0.782\n",
      "Balanced Accuracy: 0.8662\n",
      "\n",
      "Uncertainty Metrics:\n",
      "Mean Uncertainty: 0.2375\n",
      "Mean Confidence: 0.6820\n",
      "Mean Entropy: 0.5776\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13086, 683]\n",
      " [6336, 22722]]\n",
      "Sensitivity (TPR): 0.7820\n",
      "Specificity (TNR): 0.9504\n",
      "False Positive Rate: 0.0496\n",
      "False Negative Rate: 0.2180\n",
      "\n",
      "Test Data Distribution:\n",
      "Total samples: 42827\n",
      "Positive samples: 29058 (67.85%)\n",
      "Negative samples: 13769 (32.15%)\n",
      "--------------------------------------------------\n",
      "\n",
      "All test results saved to pytorch_test_results_20250509074552.json\n",
      "TensorFlow results file 'tensorflow_results.json' not found. Skipping comparison.\n",
      "Model comparison skipped (set compare_models = True to enable)\n",
      "\n",
      "Starting Training...\n",
      "--------------------------------------------------\n",
      "\n",
      "Training model for C-class flares with 24h window\n",
      "Input shape: (10, 9)\n",
      "Using Categorical Focal Loss for rare event awareness\n",
      "Set regularization: L1=1e-05, L2=0.0001\n",
      "[2025-05-09 08:35:25] Training is initiated for time window: 24 and flare class: C \n",
      "[2025-05-09 08:35:25] Automatically using version v3.5 (next available) \n",
      "[2025-05-09 08:35:28] Class distribution: [13769. 29058.] \n",
      "[2025-05-09 08:35:28] Using class weights: {0: 1.0, 1: 0.4421536237869089} \n",
      "[2025-05-09 08:35:28] Starting training for C-class flares with 24h window \n",
      "\n",
      "Epoch 1/200\n",
      "Training: loss: 4.3410 - accuracy: 0.6515 - tss: 0.1441 - lr: 0.000300\n",
      "\n",
      "Epoch 2/200\n",
      "Training: loss: 3.8146 - accuracy: 0.7097 - tss: 0.1848 - lr: 0.000300\n",
      "\n",
      "Epoch 3/200\n",
      "Training: loss: 3.5017 - accuracy: 0.7208 - tss: 0.2110 - lr: 0.000300\n",
      "\n",
      "Epoch 4/200\n",
      "Training: loss: 3.2081 - accuracy: 0.7345 - tss: 0.2316 - lr: 0.000300\n",
      "\n",
      "Epoch 5/200\n",
      "Training: loss: 2.9419 - accuracy: 0.7370 - tss: 0.2448 - lr: 0.000300\n",
      "\n",
      "Epoch 6/200\n",
      "Training: loss: 2.7018 - accuracy: 0.7378 - tss: 0.2536 - lr: 0.000300\n",
      "\n",
      "Epoch 7/200\n",
      "Training: loss: 2.4890 - accuracy: 0.7397 - tss: 0.2617 - lr: 0.000300\n",
      "\n",
      "Epoch 8/200\n",
      "Training: loss: 2.2974 - accuracy: 0.7441 - tss: 0.2702 - lr: 0.000300\n",
      "\n",
      "Epoch 9/200\n",
      "Training: loss: 2.1253 - accuracy: 0.7567 - tss: 0.2802 - lr: 0.000300\n",
      "\n",
      "Epoch 10/200\n",
      "Training: loss: 1.9730 - accuracy: 0.7619 - tss: 0.2905 - lr: 0.000300\n",
      "\n",
      "Epoch 11/200\n",
      "Training: loss: 1.8389 - accuracy: 0.7687 - tss: 0.3003 - lr: 0.000300\n",
      "\n",
      "Epoch 12/200\n",
      "Training: loss: 1.7208 - accuracy: 0.7769 - tss: 0.3110 - lr: 0.000300\n",
      "\n",
      "Epoch 13/200\n",
      "Training: loss: 1.6144 - accuracy: 0.7878 - tss: 0.3222 - lr: 0.000300\n",
      "\n",
      "Epoch 14/200\n",
      "Training: loss: 1.5199 - accuracy: 0.8010 - tss: 0.3342 - lr: 0.000300\n",
      "\n",
      "Epoch 15/200\n",
      "Training: loss: 1.4398 - accuracy: 0.8041 - tss: 0.3461 - lr: 0.000300\n",
      "\n",
      "Epoch 16/200\n",
      "Training: loss: 1.3667 - accuracy: 0.8183 - tss: 0.3586 - lr: 0.000300\n",
      "\n",
      "Epoch 17/200\n",
      "Training: loss: 1.3025 - accuracy: 0.8259 - tss: 0.3711 - lr: 0.000300\n",
      "\n",
      "Epoch 18/200\n",
      "Training: loss: 1.2462 - accuracy: 0.8293 - tss: 0.3827 - lr: 0.000300\n",
      "\n",
      "Epoch 19/200\n",
      "Training: loss: 1.1944 - accuracy: 0.8375 - tss: 0.3943 - lr: 0.000300\n",
      "\n",
      "Epoch 20/200\n",
      "Training: loss: 1.1442 - accuracy: 0.8527 - tss: 0.4064 - lr: 0.000300\n",
      "\n",
      "Epoch 21/200\n",
      "Training: loss: 1.1018 - accuracy: 0.8547 - tss: 0.4179 - lr: 0.000300\n",
      "\n",
      "Epoch 22/200\n",
      "Training: loss: 1.0612 - accuracy: 0.8650 - tss: 0.4292 - lr: 0.000300\n",
      "\n",
      "Epoch 23/200\n",
      "Training: loss: 1.0235 - accuracy: 0.8718 - tss: 0.4406 - lr: 0.000300\n",
      "\n",
      "Epoch 24/200\n",
      "Training: loss: 0.9901 - accuracy: 0.8759 - tss: 0.4514 - lr: 0.000300\n",
      "\n",
      "Epoch 25/200\n",
      "Training: loss: 0.9589 - accuracy: 0.8782 - tss: 0.4616 - lr: 0.000300\n",
      "\n",
      "Epoch 26/200\n",
      "Training: loss: 0.9292 - accuracy: 0.8830 - tss: 0.4714 - lr: 0.000300\n",
      "\n",
      "Epoch 27/200\n",
      "Training: loss: 0.9017 - accuracy: 0.8880 - tss: 0.4810 - lr: 0.000300\n",
      "\n",
      "Epoch 28/200\n",
      "Training: loss: 0.8773 - accuracy: 0.8878 - tss: 0.4900 - lr: 0.000300\n",
      "\n",
      "Epoch 29/200\n",
      "Training: loss: 0.8531 - accuracy: 0.8905 - tss: 0.4985 - lr: 0.000300\n",
      "\n",
      "Epoch 30/200\n",
      "Training: loss: 0.8297 - accuracy: 0.8975 - tss: 0.5071 - lr: 0.000300\n",
      "\n",
      "Epoch 31/200\n",
      "Training: loss: 0.8085 - accuracy: 0.8981 - tss: 0.5151 - lr: 0.000300\n",
      "\n",
      "Epoch 32/200\n",
      "Training: loss: 0.7898 - accuracy: 0.8977 - tss: 0.5226 - lr: 0.000300\n",
      "\n",
      "Epoch 33/200\n",
      "Training: loss: 0.7697 - accuracy: 0.9023 - tss: 0.5300 - lr: 0.000300\n",
      "\n",
      "Epoch 34/200\n",
      "Training: loss: 0.7519 - accuracy: 0.9055 - tss: 0.5373 - lr: 0.000300\n",
      "\n",
      "Epoch 35/200\n",
      "Training: loss: 0.7344 - accuracy: 0.9063 - tss: 0.5441 - lr: 0.000300\n",
      "\n",
      "Epoch 36/200\n",
      "Training: loss: 0.7165 - accuracy: 0.9142 - tss: 0.5511 - lr: 0.000300\n",
      "\n",
      "Epoch 37/200\n",
      "Training: loss: 0.7023 - accuracy: 0.9111 - tss: 0.5575 - lr: 0.000300\n",
      "\n",
      "Epoch 38/200\n",
      "Training: loss: 0.6883 - accuracy: 0.9110 - tss: 0.5636 - lr: 0.000300\n",
      "\n",
      "Epoch 39/200\n",
      "Training: loss: 0.6737 - accuracy: 0.9141 - tss: 0.5696 - lr: 0.000300\n",
      "\n",
      "Epoch 40/200\n",
      "Training: loss: 0.6596 - accuracy: 0.9169 - tss: 0.5754 - lr: 0.000300\n",
      "\n",
      "Epoch 41/200\n",
      "Training: loss: 0.6463 - accuracy: 0.9175 - tss: 0.5810 - lr: 0.000300\n",
      "\n",
      "Epoch 42/200\n",
      "Training: loss: 0.6331 - accuracy: 0.9211 - tss: 0.5865 - lr: 0.000300\n",
      "\n",
      "Epoch 43/200\n",
      "Training: loss: 0.6212 - accuracy: 0.9212 - tss: 0.5919 - lr: 0.000300\n",
      "\n",
      "Epoch 44/200\n",
      "Training: loss: 0.6097 - accuracy: 0.9220 - tss: 0.5970 - lr: 0.000300\n",
      "\n",
      "Epoch 45/200\n",
      "Training: loss: 0.5997 - accuracy: 0.9205 - tss: 0.6017 - lr: 0.000300\n",
      "\n",
      "Epoch 46/200\n",
      "Training: loss: 0.5885 - accuracy: 0.9243 - tss: 0.6065 - lr: 0.000300\n",
      "\n",
      "Epoch 47/200\n",
      "Training: loss: 0.5779 - accuracy: 0.9249 - tss: 0.6111 - lr: 0.000300\n",
      "\n",
      "Epoch 48/200\n",
      "Training: loss: 0.5673 - accuracy: 0.9281 - tss: 0.6157 - lr: 0.000300\n",
      "\n",
      "Epoch 49/200\n",
      "Training: loss: 0.5583 - accuracy: 0.9270 - tss: 0.6200 - lr: 0.000300\n",
      "\n",
      "Epoch 50/200\n",
      "Training: loss: 0.5502 - accuracy: 0.9251 - tss: 0.6241 - lr: 0.000300\n",
      "\n",
      "Epoch 51/200\n",
      "Training: loss: 0.5402 - accuracy: 0.9298 - tss: 0.6283 - lr: 0.000300\n",
      "\n",
      "Epoch 52/200\n",
      "Training: loss: 0.5313 - accuracy: 0.9301 - tss: 0.6323 - lr: 0.000300\n",
      "\n",
      "Epoch 53/200\n",
      "Training: loss: 0.5224 - accuracy: 0.9319 - tss: 0.6362 - lr: 0.000300\n",
      "\n",
      "Epoch 54/200\n",
      "Training: loss: 0.5150 - accuracy: 0.9323 - tss: 0.6400 - lr: 0.000300\n",
      "\n",
      "Epoch 55/200\n",
      "Training: loss: 0.5076 - accuracy: 0.9310 - tss: 0.6436 - lr: 0.000300\n",
      "\n",
      "Epoch 56/200\n",
      "Training: loss: 0.4989 - accuracy: 0.9350 - tss: 0.6473 - lr: 0.000300\n",
      "\n",
      "Epoch 57/200\n",
      "Training: loss: 0.4919 - accuracy: 0.9350 - tss: 0.6508 - lr: 0.000300\n",
      "\n",
      "Epoch 58/200\n",
      "Training: loss: 0.4843 - accuracy: 0.9369 - tss: 0.6543 - lr: 0.000300\n",
      "\n",
      "Epoch 59/200\n",
      "Training: loss: 0.4774 - accuracy: 0.9375 - tss: 0.6577 - lr: 0.000300\n",
      "\n",
      "Epoch 60/200\n",
      "Training: loss: 0.4708 - accuracy: 0.9384 - tss: 0.6610 - lr: 0.000300\n",
      "\n",
      "Epoch 61/200\n",
      "Training: loss: 0.4648 - accuracy: 0.9373 - tss: 0.6642 - lr: 0.000300\n",
      "\n",
      "Epoch 62/200\n",
      "Training: loss: 0.4586 - accuracy: 0.9389 - tss: 0.6673 - lr: 0.000300\n",
      "\n",
      "Epoch 63/200\n",
      "Training: loss: 0.4519 - accuracy: 0.9396 - tss: 0.6703 - lr: 0.000300\n",
      "\n",
      "Epoch 64/200\n",
      "Training: loss: 0.4459 - accuracy: 0.9413 - tss: 0.6734 - lr: 0.000300\n",
      "\n",
      "Epoch 65/200\n",
      "Training: loss: 0.4409 - accuracy: 0.9386 - tss: 0.6762 - lr: 0.000300\n",
      "\n",
      "Epoch 66/200\n",
      "Training: loss: 0.4343 - accuracy: 0.9438 - tss: 0.6791 - lr: 0.000300\n",
      "\n",
      "Epoch 67/200\n",
      "Training: loss: 0.4302 - accuracy: 0.9385 - tss: 0.6818 - lr: 0.000300\n",
      "\n",
      "Epoch 68/200\n",
      "Training: loss: 0.4235 - accuracy: 0.9428 - tss: 0.6845 - lr: 0.000300\n",
      "\n",
      "Epoch 69/200\n",
      "Training: loss: 0.4192 - accuracy: 0.9411 - tss: 0.6871 - lr: 0.000300\n",
      "\n",
      "Epoch 70/200\n",
      "Training: loss: 0.4134 - accuracy: 0.9440 - tss: 0.6897 - lr: 0.000300\n",
      "\n",
      "Epoch 71/200\n",
      "Training: loss: 0.4079 - accuracy: 0.9455 - tss: 0.6923 - lr: 0.000300\n",
      "\n",
      "Epoch 72/200\n",
      "Training: loss: 0.4046 - accuracy: 0.9413 - tss: 0.6947 - lr: 0.000300\n",
      "\n",
      "Epoch 73/200\n",
      "Training: loss: 0.3997 - accuracy: 0.9425 - tss: 0.6970 - lr: 0.000300\n",
      "\n",
      "Epoch 74/200\n",
      "Training: loss: 0.3959 - accuracy: 0.9417 - tss: 0.6993 - lr: 0.000300\n",
      "\n",
      "Epoch 75/200\n",
      "Training: loss: 0.3913 - accuracy: 0.9437 - tss: 0.7015 - lr: 0.000300\n",
      "\n",
      "Epoch 76/200\n",
      "Training: loss: 0.3852 - accuracy: 0.9475 - tss: 0.7039 - lr: 0.000300\n",
      "\n",
      "Epoch 77/200\n",
      "Training: loss: 0.3806 - accuracy: 0.9487 - tss: 0.7062 - lr: 0.000300\n",
      "\n",
      "Epoch 78/200\n",
      "Training: loss: 0.3765 - accuracy: 0.9474 - tss: 0.7084 - lr: 0.000300\n",
      "\n",
      "Epoch 79/200\n",
      "Training: loss: 0.3727 - accuracy: 0.9478 - tss: 0.7105 - lr: 0.000300\n",
      "\n",
      "Epoch 80/200\n",
      "Training: loss: 0.3683 - accuracy: 0.9484 - tss: 0.7126 - lr: 0.000300\n",
      "\n",
      "Epoch 81/200\n",
      "Training: loss: 0.3639 - accuracy: 0.9496 - tss: 0.7147 - lr: 0.000300\n",
      "\n",
      "Epoch 82/200\n",
      "Training: loss: 0.3600 - accuracy: 0.9509 - tss: 0.7168 - lr: 0.000300\n",
      "\n",
      "Epoch 83/200\n",
      "Training: loss: 0.3564 - accuracy: 0.9512 - tss: 0.7189 - lr: 0.000300\n",
      "\n",
      "Epoch 84/200\n",
      "Training: loss: 0.3524 - accuracy: 0.9514 - tss: 0.7209 - lr: 0.000300\n",
      "\n",
      "Epoch 85/200\n",
      "Training: loss: 0.3487 - accuracy: 0.9512 - tss: 0.7228 - lr: 0.000300\n",
      "\n",
      "Epoch 86/200\n",
      "Training: loss: 0.3465 - accuracy: 0.9486 - tss: 0.7247 - lr: 0.000300\n",
      "\n",
      "Epoch 87/200\n",
      "Training: loss: 0.3415 - accuracy: 0.9533 - tss: 0.7266 - lr: 0.000300\n",
      "\n",
      "Epoch 88/200\n",
      "Training: loss: 0.3383 - accuracy: 0.9519 - tss: 0.7284 - lr: 0.000300\n",
      "\n",
      "Epoch 89/200\n",
      "Training: loss: 0.3347 - accuracy: 0.9530 - tss: 0.7303 - lr: 0.000300\n",
      "\n",
      "Epoch 90/200\n",
      "Training: loss: 0.3324 - accuracy: 0.9507 - tss: 0.7320 - lr: 0.000300\n",
      "\n",
      "Epoch 91/200\n",
      "Training: loss: 0.3291 - accuracy: 0.9523 - tss: 0.7337 - lr: 0.000300\n",
      "\n",
      "Epoch 92/200\n",
      "Training: loss: 0.3258 - accuracy: 0.9514 - tss: 0.7354 - lr: 0.000300\n",
      "\n",
      "Epoch 93/200\n",
      "Training: loss: 0.3217 - accuracy: 0.9542 - tss: 0.7371 - lr: 0.000300\n",
      "\n",
      "Epoch 94/200\n",
      "Training: loss: 0.3191 - accuracy: 0.9535 - tss: 0.7387 - lr: 0.000300\n",
      "\n",
      "Epoch 95/200\n",
      "Training: loss: 0.3157 - accuracy: 0.9552 - tss: 0.7404 - lr: 0.000300\n",
      "\n",
      "Epoch 96/200\n",
      "Training: loss: 0.3130 - accuracy: 0.9540 - tss: 0.7420 - lr: 0.000300\n",
      "\n",
      "Epoch 97/200\n",
      "Training: loss: 0.3100 - accuracy: 0.9548 - tss: 0.7436 - lr: 0.000300\n",
      "\n",
      "Epoch 98/200\n",
      "Training: loss: 0.3063 - accuracy: 0.9576 - tss: 0.7452 - lr: 0.000300\n",
      "\n",
      "Epoch 99/200\n",
      "Training: loss: 0.3041 - accuracy: 0.9571 - tss: 0.7468 - lr: 0.000300\n",
      "\n",
      "Epoch 100/200\n",
      "Training: loss: 0.3005 - accuracy: 0.9584 - tss: 0.7483 - lr: 0.000300\n",
      "\n",
      "Epoch 101/200\n",
      "Training: loss: 0.2991 - accuracy: 0.9544 - tss: 0.7498 - lr: 0.000300\n",
      "\n",
      "Epoch 102/200\n",
      "Training: loss: 0.2951 - accuracy: 0.9578 - tss: 0.7513 - lr: 0.000300\n",
      "\n",
      "Epoch 103/200\n",
      "Training: loss: 0.2920 - accuracy: 0.9594 - tss: 0.7528 - lr: 0.000300\n",
      "\n",
      "Epoch 104/200\n",
      "Training: loss: 0.2895 - accuracy: 0.9596 - tss: 0.7543 - lr: 0.000300\n",
      "\n",
      "Epoch 105/200\n",
      "Training: loss: 0.2869 - accuracy: 0.9596 - tss: 0.7557 - lr: 0.000300\n",
      "\n",
      "Epoch 106/200\n",
      "Training: loss: 0.2841 - accuracy: 0.9600 - tss: 0.7571 - lr: 0.000300\n",
      "\n",
      "Epoch 107/200\n",
      "Training: loss: 0.2826 - accuracy: 0.9586 - tss: 0.7585 - lr: 0.000300\n",
      "\n",
      "Epoch 108/200\n",
      "Training: loss: 0.2799 - accuracy: 0.9591 - tss: 0.7599 - lr: 0.000300\n",
      "\n",
      "Epoch 109/200\n",
      "Training: loss: 0.2763 - accuracy: 0.9607 - tss: 0.7612 - lr: 0.000300\n",
      "\n",
      "Epoch 110/200\n",
      "Training: loss: 0.2735 - accuracy: 0.9619 - tss: 0.7626 - lr: 0.000300\n",
      "\n",
      "Epoch 111/200\n",
      "Training: loss: 0.2729 - accuracy: 0.9582 - tss: 0.7639 - lr: 0.000300\n",
      "\n",
      "Epoch 112/200\n",
      "Training: loss: 0.2698 - accuracy: 0.9586 - tss: 0.7651 - lr: 0.000300\n",
      "\n",
      "Epoch 113/200\n",
      "Training: loss: 0.2673 - accuracy: 0.9606 - tss: 0.7664 - lr: 0.000300\n",
      "\n",
      "Epoch 114/200\n",
      "Training: loss: 0.2646 - accuracy: 0.9613 - tss: 0.7677 - lr: 0.000300\n",
      "\n",
      "Epoch 115/200\n",
      "Training: loss: 0.2619 - accuracy: 0.9622 - tss: 0.7689 - lr: 0.000300\n",
      "\n",
      "Epoch 116/200\n",
      "Training: loss: 0.2597 - accuracy: 0.9622 - tss: 0.7702 - lr: 0.000300\n",
      "\n",
      "Epoch 117/200\n",
      "Training: loss: 0.2573 - accuracy: 0.9628 - tss: 0.7714 - lr: 0.000300\n",
      "\n",
      "Epoch 118/200\n",
      "Training: loss: 0.2558 - accuracy: 0.9605 - tss: 0.7726 - lr: 0.000300\n",
      "\n",
      "Epoch 119/200\n",
      "Training: loss: 0.2531 - accuracy: 0.9629 - tss: 0.7738 - lr: 0.000300\n",
      "\n",
      "Epoch 120/200\n",
      "Training: loss: 0.2507 - accuracy: 0.9636 - tss: 0.7750 - lr: 0.000300\n",
      "\n",
      "Epoch 121/200\n",
      "Training: loss: 0.2483 - accuracy: 0.9642 - tss: 0.7761 - lr: 0.000300\n",
      "\n",
      "Epoch 122/200\n",
      "Training: loss: 0.2465 - accuracy: 0.9644 - tss: 0.7773 - lr: 0.000300\n",
      "\n",
      "Epoch 123/200\n",
      "Training: loss: 0.2447 - accuracy: 0.9631 - tss: 0.7784 - lr: 0.000300\n",
      "\n",
      "Epoch 124/200\n",
      "Training: loss: 0.2426 - accuracy: 0.9636 - tss: 0.7795 - lr: 0.000300\n",
      "\n",
      "Epoch 125/200\n",
      "Training: loss: 0.2411 - accuracy: 0.9622 - tss: 0.7806 - lr: 0.000300\n",
      "\n",
      "Epoch 126/200\n",
      "Training: loss: 0.2388 - accuracy: 0.9625 - tss: 0.7817 - lr: 0.000300\n",
      "\n",
      "Epoch 127/200\n",
      "Training: loss: 0.2366 - accuracy: 0.9642 - tss: 0.7827 - lr: 0.000300\n",
      "\n",
      "Epoch 128/200\n",
      "Training: loss: 0.2344 - accuracy: 0.9644 - tss: 0.7838 - lr: 0.000300\n",
      "\n",
      "Epoch 129/200\n",
      "Training: loss: 0.2320 - accuracy: 0.9660 - tss: 0.7848 - lr: 0.000300\n",
      "\n",
      "Epoch 130/200\n",
      "Training: loss: 0.2306 - accuracy: 0.9649 - tss: 0.7859 - lr: 0.000300\n",
      "\n",
      "Epoch 131/200\n",
      "Training: loss: 0.2287 - accuracy: 0.9651 - tss: 0.7869 - lr: 0.000300\n",
      "\n",
      "Epoch 132/200\n",
      "Training: loss: 0.2260 - accuracy: 0.9664 - tss: 0.7879 - lr: 0.000300\n",
      "\n",
      "Epoch 133/200\n",
      "Training: loss: 0.2247 - accuracy: 0.9656 - tss: 0.7889 - lr: 0.000300\n",
      "\n",
      "Epoch 134/200\n",
      "Training: loss: 0.2234 - accuracy: 0.9656 - tss: 0.7899 - lr: 0.000300\n",
      "\n",
      "Epoch 135/200\n",
      "Training: loss: 0.2207 - accuracy: 0.9664 - tss: 0.7909 - lr: 0.000300\n",
      "\n",
      "Epoch 136/200\n",
      "Training: loss: 0.2194 - accuracy: 0.9668 - tss: 0.7919 - lr: 0.000300\n",
      "\n",
      "Epoch 137/200\n",
      "Training: loss: 0.2174 - accuracy: 0.9665 - tss: 0.7928 - lr: 0.000300\n",
      "\n",
      "Epoch 138/200\n",
      "Training: loss: 0.2159 - accuracy: 0.9663 - tss: 0.7938 - lr: 0.000300\n",
      "\n",
      "Epoch 139/200\n",
      "Training: loss: 0.2136 - accuracy: 0.9673 - tss: 0.7947 - lr: 0.000300\n",
      "\n",
      "Epoch 140/200\n",
      "Training: loss: 0.2124 - accuracy: 0.9670 - tss: 0.7956 - lr: 0.000300\n",
      "\n",
      "Epoch 141/200\n",
      "Training: loss: 0.2098 - accuracy: 0.9693 - tss: 0.7966 - lr: 0.000300\n",
      "\n",
      "Epoch 142/200\n",
      "Training: loss: 0.2081 - accuracy: 0.9685 - tss: 0.7975 - lr: 0.000300\n",
      "\n",
      "Epoch 143/200\n",
      "Training: loss: 0.2080 - accuracy: 0.9650 - tss: 0.7983 - lr: 0.000300\n",
      "\n",
      "Epoch 144/200\n",
      "Training: loss: 0.2060 - accuracy: 0.9668 - tss: 0.7992 - lr: 0.000300\n",
      "\n",
      "Epoch 145/200\n",
      "Training: loss: 0.2048 - accuracy: 0.9668 - tss: 0.8001 - lr: 0.000300\n",
      "\n",
      "Epoch 146/200\n",
      "Training: loss: 0.2026 - accuracy: 0.9681 - tss: 0.8009 - lr: 0.000300\n",
      "\n",
      "Epoch 147/200\n",
      "Training: loss: 0.2003 - accuracy: 0.9697 - tss: 0.8018 - lr: 0.000300\n",
      "\n",
      "Epoch 148/200\n",
      "Training: loss: 0.1983 - accuracy: 0.9709 - tss: 0.8027 - lr: 0.000300\n",
      "\n",
      "Epoch 149/200\n",
      "Training: loss: 0.1976 - accuracy: 0.9683 - tss: 0.8035 - lr: 0.000300\n",
      "\n",
      "Epoch 150/200\n",
      "Training: loss: 0.1962 - accuracy: 0.9694 - tss: 0.8044 - lr: 0.000300\n",
      "\n",
      "Epoch 151/200\n",
      "Training: loss: 0.1943 - accuracy: 0.9701 - tss: 0.8052 - lr: 0.000300\n",
      "\n",
      "Epoch 152/200\n",
      "Training: loss: 0.1932 - accuracy: 0.9691 - tss: 0.8060 - lr: 0.000300\n",
      "\n",
      "Epoch 153/200\n",
      "Training: loss: 0.1914 - accuracy: 0.9708 - tss: 0.8068 - lr: 0.000300\n",
      "\n",
      "Epoch 154/200\n",
      "Training: loss: 0.1896 - accuracy: 0.9713 - tss: 0.8077 - lr: 0.000300\n",
      "\n",
      "Epoch 155/200\n",
      "Training: loss: 0.1881 - accuracy: 0.9703 - tss: 0.8085 - lr: 0.000300\n",
      "\n",
      "Epoch 156/200\n",
      "Training: loss: 0.1867 - accuracy: 0.9713 - tss: 0.8093 - lr: 0.000300\n",
      "\n",
      "Epoch 157/200\n",
      "Training: loss: 0.1850 - accuracy: 0.9709 - tss: 0.8100 - lr: 0.000300\n",
      "\n",
      "Epoch 158/200\n",
      "Training: loss: 0.1837 - accuracy: 0.9717 - tss: 0.8108 - lr: 0.000300\n",
      "\n",
      "Epoch 159/200\n",
      "Training: loss: 0.1829 - accuracy: 0.9693 - tss: 0.8116 - lr: 0.000300\n",
      "\n",
      "Epoch 160/200\n",
      "Training: loss: 0.1810 - accuracy: 0.9711 - tss: 0.8123 - lr: 0.000300\n",
      "\n",
      "Epoch 161/200\n",
      "Training: loss: 0.1792 - accuracy: 0.9720 - tss: 0.8131 - lr: 0.000300\n",
      "\n",
      "Epoch 162/200\n",
      "Training: loss: 0.1785 - accuracy: 0.9713 - tss: 0.8138 - lr: 0.000300\n",
      "\n",
      "Epoch 163/200\n",
      "Training: loss: 0.1769 - accuracy: 0.9724 - tss: 0.8146 - lr: 0.000300\n",
      "\n",
      "Epoch 164/200\n",
      "Training: loss: 0.1753 - accuracy: 0.9730 - tss: 0.8153 - lr: 0.000300\n",
      "\n",
      "Epoch 165/200\n",
      "Training: loss: 0.1739 - accuracy: 0.9734 - tss: 0.8161 - lr: 0.000300\n",
      "\n",
      "Epoch 166/200\n",
      "Training: loss: 0.1741 - accuracy: 0.9699 - tss: 0.8168 - lr: 0.000300\n",
      "EarlyStopping: 1/15\n",
      "\n",
      "Epoch 167/200\n",
      "Training: loss: 0.1723 - accuracy: 0.9712 - tss: 0.8175 - lr: 0.000300\n",
      "\n",
      "Epoch 168/200\n",
      "Training: loss: 0.1712 - accuracy: 0.9717 - tss: 0.8182 - lr: 0.000300\n",
      "\n",
      "Epoch 169/200\n"
     ]
    }
   ],
   "source": [
    "# Import required model functions\n",
    "try:\n",
    "    # Training modules\n",
    "    from models.SolarKnowledge_run_all_trainings_pytorch import train as run_training, set_seed\n",
    "    from models.SolarKnowledge_model_pytorch import SolarKnowledge\n",
    "    from models.utils import supported_flare_class, get_training_data\n",
    "    \n",
    "    # Testing modules\n",
    "    from models.SolarKnowledge_run_all_tests_pytorch import test_model, find_latest_model_version\n",
    "    from models.utils import get_testing_data\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    # Ensure consistent seed setting\n",
    "    set_seed(RANDOM_SEED)\n",
    "    \n",
    "    print(\"Successfully imported all modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"\\nPlease ensure the following files exist in the 'models' directory:\")\n",
    "    print(\"- SolarKnowledge_model_pytorch.py\")\n",
    "    print(\"- SolarKnowledge_run_all_trainings_pytorch.py\")\n",
    "    print(\"- SolarKnowledge_run_all_tests_pytorch.py\")\n",
    "    print(\"- utils.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training Parameters\n",
    "\n",
    "Edit the parameters below to configure your training settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters (modify these as needed)\n",
    "\n",
    "# Basic parameters\n",
    "flare_classes = ['C']  # Options: 'C', 'M', 'M5' - you can select multiple\n",
    "time_windows = ['24']  # Options: '24', '48', '72' - you can select multiple\n",
    "version = None  # Set to None for auto version or specify (e.g., '2')\n",
    "description = \"A6000-optimised config: deeper, wider, faster\"  # Optional description of this training run\n",
    "auto_increment = True  # Whether to auto-increment version numbers\n",
    "\n",
    "# Model hyperparameters - A6000-optimised values\n",
    "epochs = 200  # Give enough room for long convergence\n",
    "patience = 15  # Allow extended early stopping\n",
    "learning_rate = 3e-4  # Larger LR for faster convergence with larger batch\n",
    "batch_size = 2048  # Exploit A6000's memory\n",
    "embed_dim = 256  # Wider token embeddings\n",
    "transformer_blocks = 8  # Deeper model\n",
    "use_focal_loss = True  # Good for imbalanced datasets\n",
    "compare_models = False  # Whether to compare models after training\n",
    "\n",
    "# Optimizer and regularization\n",
    "optimizer_type = 'AdamW'  # Switch to AdamW for decoupled weight decay\n",
    "l1_regularization = 1e-5  # Match TensorFlow style\n",
    "l2_regularization = 1e-4  # Match TensorFlow style\n",
    "\n",
    "# Learning rate scheduler  use cosine annealing with restarts\n",
    "scheduler_params = {\n",
    "    \"T_0\": 10,        # First restart after 10 epochs\n",
    "    \"T_mult\": 2,      # Double the period after each restart\n",
    "    \"eta_min\": 1e-6   # Minimum LR\n",
    "}\n",
    "scheduler_type = \"cosine_with_restarts\"\n",
    "\n",
    "# Display current settings\n",
    "print(\"\\nTraining Configuration:\")\n",
    "print(f\"Flare Classes: {', '.join(flare_classes)}\")\n",
    "print(f\"Time Windows: {', '.join(time_windows)}\")\n",
    "print(f\"Version: {'Auto' if version is None else version}\")\n",
    "print(f\"Description: {'None' if description is None else description}\")\n",
    "print(f\"Auto-increment: {'Yes' if auto_increment else 'No'}\")\n",
    "\n",
    "print(\"\\nHyperparameters:\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Early Stopping Patience: {patience}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Optimizer: {optimizer_type}\")\n",
    "print(f\"L1 Regularization: {l1_regularization}\")\n",
    "print(f\"L2 Regularization: {l2_regularization}\")\n",
    "print(f\"Scheduler: {scheduler_type} (T_0={scheduler_params['T_0']}, T_mult={scheduler_params['T_mult']}, min_lr={scheduler_params['eta_min']})\")\n",
    "print(f\"Embedding Dimension: {embed_dim}\")\n",
    "print(f\"Transformer Blocks: {transformer_blocks}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Using Focal Loss: {'Yes' if use_focal_loss else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training\n",
    "\n",
    "Execute the training with the configured parameters. You can monitor progress with epoch-by-epoch metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 21/21 [00:02<00:00,  9.95it/s, accuracy=0.651, loss=4.34, tss=0.144] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.19it/s, accuracy=0.71, loss=3.81, tss=0.185] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.98it/s, accuracy=0.721, loss=3.5, tss=0.211] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.22it/s, accuracy=0.734, loss=3.21, tss=0.232]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.98it/s, accuracy=0.737, loss=2.94, tss=0.245]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.18it/s, accuracy=0.738, loss=2.7, tss=0.254] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.97it/s, accuracy=0.74, loss=2.49, tss=0.262] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.97it/s, accuracy=0.744, loss=2.3, tss=0.27]  \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.19it/s, accuracy=0.757, loss=2.13, tss=0.28] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.97it/s, accuracy=0.762, loss=1.97, tss=0.291]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.23it/s, accuracy=0.769, loss=1.84, tss=0.3]  \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.95it/s, accuracy=0.777, loss=1.72, tss=0.311]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.19it/s, accuracy=0.788, loss=1.61, tss=0.322]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.96it/s, accuracy=0.801, loss=1.52, tss=0.334]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.21it/s, accuracy=0.804, loss=1.44, tss=0.346]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.98it/s, accuracy=0.818, loss=1.37, tss=0.359]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.16it/s, accuracy=0.826, loss=1.3, tss=0.371] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.96it/s, accuracy=0.829, loss=1.25, tss=0.383]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.79it/s, accuracy=0.837, loss=1.19, tss=0.394]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.60it/s, accuracy=0.853, loss=1.14, tss=0.406]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 12.76it/s, accuracy=0.855, loss=1.1, tss=0.418] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.76it/s, accuracy=0.865, loss=1.06, tss=0.429]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.872, loss=1.02, tss=0.441]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.94it/s, accuracy=0.876, loss=0.99, tss=0.451] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.878, loss=0.959, tss=0.462]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.883, loss=0.929, tss=0.471]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.77it/s, accuracy=0.888, loss=0.902, tss=0.481]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.93it/s, accuracy=0.888, loss=0.877, tss=0.49] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.89, loss=0.853, tss=0.498] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.96it/s, accuracy=0.897, loss=0.83, tss=0.507] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.898, loss=0.808, tss=0.515]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.898, loss=0.79, tss=0.523] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.76it/s, accuracy=0.902, loss=0.77, tss=0.53]  \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.97it/s, accuracy=0.906, loss=0.752, tss=0.537]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.76it/s, accuracy=0.906, loss=0.734, tss=0.544]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.914, loss=0.717, tss=0.551]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.911, loss=0.702, tss=0.558]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.03it/s, accuracy=0.911, loss=0.688, tss=0.564]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.914, loss=0.674, tss=0.57] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.917, loss=0.66, tss=0.575] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.97it/s, accuracy=0.917, loss=0.646, tss=0.581]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.921, loss=0.633, tss=0.587]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.97it/s, accuracy=0.921, loss=0.621, tss=0.592]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.922, loss=0.61, tss=0.597] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.99it/s, accuracy=0.921, loss=0.6, tss=0.602]  \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.924, loss=0.589, tss=0.606]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.99it/s, accuracy=0.925, loss=0.578, tss=0.611]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.928, loss=0.567, tss=0.616]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.00it/s, accuracy=0.927, loss=0.558, tss=0.62] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.925, loss=0.55, tss=0.624] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.93, loss=0.54, tss=0.628]  \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.93, loss=0.531, tss=0.632] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.97it/s, accuracy=0.932, loss=0.522, tss=0.636]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.932, loss=0.515, tss=0.64] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.931, loss=0.508, tss=0.644]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.77it/s, accuracy=0.935, loss=0.499, tss=0.647]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.935, loss=0.492, tss=0.651]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.937, loss=0.484, tss=0.654]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.00it/s, accuracy=0.937, loss=0.477, tss=0.658]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.77it/s, accuracy=0.938, loss=0.471, tss=0.661]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.81it/s, accuracy=0.937, loss=0.465, tss=0.664]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.939, loss=0.459, tss=0.667]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.94, loss=0.452, tss=0.67]  \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.941, loss=0.446, tss=0.673]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.939, loss=0.441, tss=0.676]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.944, loss=0.434, tss=0.679]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.938, loss=0.43, tss=0.682] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.97it/s, accuracy=0.943, loss=0.423, tss=0.685]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.75it/s, accuracy=0.941, loss=0.419, tss=0.687]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.01it/s, accuracy=0.944, loss=0.413, tss=0.69] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.84it/s, accuracy=0.945, loss=0.408, tss=0.692]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.99it/s, accuracy=0.941, loss=0.405, tss=0.695]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.942, loss=0.4, tss=0.697]  \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.942, loss=0.396, tss=0.699]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.944, loss=0.391, tss=0.702]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.00it/s, accuracy=0.948, loss=0.385, tss=0.704]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.949, loss=0.381, tss=0.706]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.947, loss=0.376, tss=0.708]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.96it/s, accuracy=0.948, loss=0.373, tss=0.711]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.948, loss=0.368, tss=0.713]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.01it/s, accuracy=0.95, loss=0.364, tss=0.715] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.951, loss=0.36, tss=0.717]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.96it/s, accuracy=0.951, loss=0.356, tss=0.719]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.951, loss=0.352, tss=0.721]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.01it/s, accuracy=0.951, loss=0.349, tss=0.723]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.82it/s, accuracy=0.949, loss=0.346, tss=0.725]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.00it/s, accuracy=0.953, loss=0.341, tss=0.727]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.952, loss=0.338, tss=0.728]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.95it/s, accuracy=0.953, loss=0.335, tss=0.73] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.76it/s, accuracy=0.951, loss=0.332, tss=0.732]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.93it/s, accuracy=0.952, loss=0.329, tss=0.734]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.76it/s, accuracy=0.951, loss=0.326, tss=0.735]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.01it/s, accuracy=0.954, loss=0.322, tss=0.737]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.954, loss=0.319, tss=0.739]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.955, loss=0.316, tss=0.74]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.97it/s, accuracy=0.954, loss=0.313, tss=0.742]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.955, loss=0.31, tss=0.744] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.00it/s, accuracy=0.958, loss=0.306, tss=0.745]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.81it/s, accuracy=0.957, loss=0.304, tss=0.747]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.958, loss=0.301, tss=0.748]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.954, loss=0.299, tss=0.75] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.99it/s, accuracy=0.958, loss=0.295, tss=0.751]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.959, loss=0.292, tss=0.753]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.96it/s, accuracy=0.96, loss=0.29, tss=0.754] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.96, loss=0.287, tss=0.756] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.96, loss=0.284, tss=0.757] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.81it/s, accuracy=0.959, loss=0.283, tss=0.759]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.00it/s, accuracy=0.959, loss=0.28, tss=0.76]  \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.78it/s, accuracy=0.961, loss=0.276, tss=0.761]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 14.01it/s, accuracy=0.962, loss=0.274, tss=0.763]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.958, loss=0.273, tss=0.764]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.95it/s, accuracy=0.959, loss=0.27, tss=0.765]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.75it/s, accuracy=0.961, loss=0.267, tss=0.766]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.98it/s, accuracy=0.961, loss=0.265, tss=0.768]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.80it/s, accuracy=0.962, loss=0.262, tss=0.769]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.79it/s, accuracy=0.962, loss=0.26, tss=0.77] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.94it/s, accuracy=0.963, loss=0.257, tss=0.771]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.81it/s, accuracy=0.961, loss=0.256, tss=0.773]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.97it/s, accuracy=0.963, loss=0.253, tss=0.774]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.75it/s, accuracy=0.964, loss=0.251, tss=0.775]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.83it/s, accuracy=0.964, loss=0.248, tss=0.776]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.57it/s, accuracy=0.964, loss=0.246, tss=0.777]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.78it/s, accuracy=0.963, loss=0.245, tss=0.778]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.67it/s, accuracy=0.964, loss=0.243, tss=0.78] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.77it/s, accuracy=0.962, loss=0.241, tss=0.781]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.68it/s, accuracy=0.962, loss=0.239, tss=0.782]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.90it/s, accuracy=0.964, loss=0.237, tss=0.783]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.70it/s, accuracy=0.964, loss=0.234, tss=0.784]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.79it/s, accuracy=0.966, loss=0.232, tss=0.785]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.72it/s, accuracy=0.965, loss=0.231, tss=0.786]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.79it/s, accuracy=0.965, loss=0.229, tss=0.787]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.69it/s, accuracy=0.966, loss=0.226, tss=0.788]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.69it/s, accuracy=0.966, loss=0.225, tss=0.789]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 13.82it/s, accuracy=0.966, loss=0.223, tss=0.79] \n",
      "Training: 100%|| 21/21 [00:01<00:00, 15.61it/s, accuracy=0.966, loss=0.221, tss=0.791]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 12.81it/s, accuracy=0.967, loss=0.219, tss=0.792]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 10.61it/s, accuracy=0.967, loss=0.217, tss=0.793]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 10.57it/s, accuracy=0.966, loss=0.216, tss=0.794]\n",
      "Training: 100%|| 21/21 [00:01<00:00, 11.83it/s, accuracy=0.967, loss=0.214, tss=0.795]\n",
      "Training: 100%|| 21/21 [00:02<00:00, 10.06it/s, accuracy=0.967, loss=0.212, tss=0.796]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.96it/s, accuracy=0.969, loss=0.21, tss=0.797] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.19it/s, accuracy=0.969, loss=0.208, tss=0.797]\n",
      "Training: 100%|| 21/21 [00:02<00:00, 10.12it/s, accuracy=0.965, loss=0.208, tss=0.798]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.19it/s, accuracy=0.967, loss=0.206, tss=0.799]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.97it/s, accuracy=0.967, loss=0.205, tss=0.8] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.21it/s, accuracy=0.968, loss=0.203, tss=0.801]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.98it/s, accuracy=0.97, loss=0.2, tss=0.802]  \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.20it/s, accuracy=0.971, loss=0.198, tss=0.803]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.95it/s, accuracy=0.968, loss=0.198, tss=0.804]\n",
      "Training: 100%|| 21/21 [00:02<00:00, 10.00it/s, accuracy=0.969, loss=0.196, tss=0.804]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.19it/s, accuracy=0.97, loss=0.194, tss=0.805] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.95it/s, accuracy=0.969, loss=0.193, tss=0.806]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.16it/s, accuracy=0.971, loss=0.191, tss=0.807]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.95it/s, accuracy=0.971, loss=0.19, tss=0.808]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.18it/s, accuracy=0.97, loss=0.188, tss=0.808] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.96it/s, accuracy=0.971, loss=0.187, tss=0.809]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.20it/s, accuracy=0.971, loss=0.185, tss=0.81]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.97it/s, accuracy=0.972, loss=0.184, tss=0.811]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.17it/s, accuracy=0.969, loss=0.183, tss=0.812]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.96it/s, accuracy=0.971, loss=0.181, tss=0.812]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.20it/s, accuracy=0.972, loss=0.179, tss=0.813]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.95it/s, accuracy=0.971, loss=0.179, tss=0.814]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.19it/s, accuracy=0.972, loss=0.177, tss=0.815]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.97it/s, accuracy=0.973, loss=0.175, tss=0.815]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.17it/s, accuracy=0.973, loss=0.174, tss=0.816]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.96it/s, accuracy=0.97, loss=0.174, tss=0.817] \n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.17it/s, accuracy=0.971, loss=0.172, tss=0.817]\n",
      "Training: 100%|| 21/21 [00:02<00:00,  9.97it/s, accuracy=0.972, loss=0.171, tss=0.818]\n",
      "Training:  86%| | 18/21 [00:02<00:00,  8.89it/s, accuracy=0.971, loss=0.17, tss=0.819] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     58\u001b[39m hyperparams = {\n\u001b[32m     59\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m: learning_rate,\n\u001b[32m     60\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1e-4\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrandom_seed\u001b[39m\u001b[33m\"\u001b[39m: RANDOM_SEED\n\u001b[32m     89\u001b[39m }\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Run the training function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m model_dir, trained_version = \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflare_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_increment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_increment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_hyperparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformer_blocks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformer_blocks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_focal_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_focal_loss\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m trained_models.append({\n\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtime_window\u001b[39m\u001b[33m\"\u001b[39m: time_window,\n\u001b[32m    110\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mflare_class\u001b[39m\u001b[33m\"\u001b[39m: flare_class,\n\u001b[32m    111\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_dir\u001b[39m\u001b[33m\"\u001b[39m: model_dir,\n\u001b[32m    112\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: trained_version\n\u001b[32m    113\u001b[39m })\n\u001b[32m    114\u001b[39m versions.append(trained_version)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/masters-project/models/SolarKnowledge_run_all_trainings_pytorch.py:160\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(time_window, flare_class, version, description, auto_increment, custom_model, custom_hyperparams, epochs, batch_size, learning_rate, embed_dim, transformer_blocks, use_batch_norm, use_focal_loss)\u001b[39m\n\u001b[32m    154\u001b[39m log(\n\u001b[32m    155\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting training for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflare_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-class flares with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_window\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mh window\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    156\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    157\u001b[39m )\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# Train the model using the specified scheduler\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Get performance metrics from training history\u001b[39;00m\n\u001b[32m    170\u001b[39m metrics = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/masters-project/models/SolarKnowledge_model_pytorch.py:719\u001b[39m, in \u001b[36mSolarKnowledge.fit\u001b[39m\u001b[34m(self, X_train, y_train, X_valid, y_valid, epochs, verbose, batch_size, class_weight, callbacks)\u001b[39m\n\u001b[32m    716\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m train_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;66;03m# Get current learning rate\u001b[39;00m\n\u001b[32m    722\u001b[39m current_lr = \u001b[38;5;28mself\u001b[39m.optimizer.param_groups[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/masters-project/models/SolarKnowledge_model_pytorch.py:532\u001b[39m, in \u001b[36mSolarKnowledge._train_epoch\u001b[39m\u001b[34m(self, data_loader, class_weight)\u001b[39m\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m weight_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.loss_fn, \u001b[33m'\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    530\u001b[39m             \u001b[38;5;28mself\u001b[39m.loss_fn.weight = weight_tensor\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m         loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    534\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.model(X_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/everest_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/everest_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/masters-project/models/SolarKnowledge_model_pytorch.py:224\u001b[39m, in \u001b[36mCategoricalFocalLoss.forward\u001b[39m\u001b[34m(self, y_pred, y_true)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Clip predictions for numerical stability (matching TensorFlow's epsilon of 1e-7)\u001b[39;00m\n\u001b[32m    223\u001b[39m epsilon = \u001b[32m1e-7\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m y_pred = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# Standard categorical cross-entropy loss\u001b[39;00m\n\u001b[32m    227\u001b[39m ce_loss = -torch.sum(y_true * torch.log(y_pred), dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Store trained models information\n",
    "trained_models = []\n",
    "versions = []\n",
    "\n",
    "# Validate selections\n",
    "if not flare_classes:\n",
    "    print(\"Error: Please select at least one flare class\")\n",
    "else:\n",
    "    if not time_windows:\n",
    "        print(\"Error: Please select at least one time window\")\n",
    "    else:\n",
    "        print(\"\\nStarting Training...\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        # Run training for each combination\n",
    "        for time_window in time_windows:\n",
    "            for flare_class in flare_classes:\n",
    "                if flare_class not in supported_flare_class:\n",
    "                    print(f\"Unsupported flare class: {flare_class}\")\n",
    "                    continue\n",
    "                    \n",
    "                print(f\"\\nTraining model for {flare_class}-class flares with {time_window}h window\")\n",
    "                \n",
    "                try:\n",
    "                    # First, get the input shape from the training data\n",
    "                    X_train, _ = get_training_data(time_window, flare_class)\n",
    "                    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "                    print(f\"Input shape: {input_shape}\")\n",
    "                    \n",
    "                    # Create a customized model instance with our parameters\n",
    "                    model = SolarKnowledge(early_stopping_patience=patience)\n",
    "                    \n",
    "                    # Build the model\n",
    "                    model.build_base_model(\n",
    "                        input_shape=input_shape,\n",
    "                        embed_dim=embed_dim,\n",
    "                        num_heads=8,\n",
    "                        ff_dim=1024,\n",
    "                        num_transformer_blocks=transformer_blocks,\n",
    "                        dropout_rate=0.3\n",
    "                    )\n",
    "                    \n",
    "                    # Compile the model\n",
    "                    model.compile(\n",
    "                        use_focal_loss=use_focal_loss,\n",
    "                        learning_rate=learning_rate,\n",
    "                        weight_decay=1e-4\n",
    "                    )\n",
    "                    \n",
    "                    # Model.model is the actual PyTorch model\n",
    "                    if hasattr(model.model, 'l1_regularizer') and hasattr(model.model, 'l2_regularizer'):\n",
    "                        # Set regularization strengths to match TensorFlow\n",
    "                        model.model.l1_regularizer = l1_regularization\n",
    "                        model.model.l2_regularizer = l2_regularization\n",
    "                        print(f\"Set regularization: L1={l1_regularization}, L2={l2_regularization}\")\n",
    "                    \n",
    "                    # Set up custom hyperparameters dictionary for model_tracking\n",
    "                    hyperparams = {\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"weight_decay\": 1e-4,\n",
    "                        \"batch_size\": batch_size,\n",
    "                        \"early_stopping_patience\": patience,\n",
    "                        \"early_stopping_metric\": \"loss\",\n",
    "                        \"epochs\": epochs,\n",
    "                        \"num_transformer_blocks\": transformer_blocks,\n",
    "                        \"embed_dim\": embed_dim,\n",
    "                        \"num_heads\": 8,\n",
    "                        \"ff_dim\": 1024,\n",
    "                        \"dropout_rate\": 0.3,\n",
    "                        \"focal_loss\": use_focal_loss,\n",
    "                        \"focal_loss_alpha\": 0.25,\n",
    "                        \"focal_loss_gamma\": 2.0,\n",
    "                        \"framework\": \"pytorch\",\n",
    "                        \"gradient_clipping\": True,\n",
    "                        \"max_grad_norm\": 1.0,\n",
    "                        \"input_shape\": input_shape,\n",
    "                        \"lr_scheduler\": {\n",
    "                            \"type\": \"cosine_with_restarts\",\n",
    "                            \"T_0\": scheduler_params[\"T_0\"],\n",
    "                            \"T_mult\": scheduler_params[\"T_mult\"],\n",
    "                            \"eta_min\": scheduler_params[\"eta_min\"]\n",
    "                        },\n",
    "                        \"regularization\": {\n",
    "                            \"l1\": l1_regularization,\n",
    "                            \"l2\": l2_regularization\n",
    "                        },\n",
    "                        \"optimizer\": optimizer_type,\n",
    "                        \"random_seed\": RANDOM_SEED\n",
    "                    }\n",
    "                    \n",
    "                    # Run the training function\n",
    "                    model_dir, trained_version = run_training(\n",
    "                        time_window,\n",
    "                        flare_class,\n",
    "                        version=version,\n",
    "                        description=description,\n",
    "                        auto_increment=auto_increment,\n",
    "                        custom_model=model,\n",
    "                        custom_hyperparams=hyperparams,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        learning_rate=learning_rate,\n",
    "                        embed_dim=embed_dim,\n",
    "                        transformer_blocks=transformer_blocks,\n",
    "                        use_focal_loss=use_focal_loss\n",
    "                    )\n",
    "                    \n",
    "                    trained_models.append({\n",
    "                        \"time_window\": time_window,\n",
    "                        \"flare_class\": flare_class,\n",
    "                        \"model_dir\": model_dir,\n",
    "                        \"version\": trained_version\n",
    "                    })\n",
    "                    versions.append(trained_version)\n",
    "                    \n",
    "                    print(f\"\\nModel saved to {model_dir}\")\n",
    "                    print(\"-\"*50)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error training model: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Testing Parameters\n",
    "\n",
    "Edit the parameters below to configure your testing settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing configuration\n",
    "test_flare_classes = flare_classes  # Default to same as training\n",
    "test_time_windows = time_windows    # Default to same as training\n",
    "mc_passes = 30                      # Number of Monte Carlo dropout passes for uncertainty estimation\n",
    "plot_uncertainties = True           # Whether to generate uncertainty visualization plots\n",
    "test_latest = True                  # Test the latest model versions by default\n",
    "test_specific_version = None        # Set to a specific version string to test it instead\n",
    "\n",
    "# Display testing settings\n",
    "print(\"\\nTesting Configuration:\")\n",
    "print(f\"Flare Classes: {', '.join(test_flare_classes)}\")\n",
    "print(f\"Time Windows: {', '.join(test_time_windows)}\")\n",
    "print(f\"Monte Carlo Passes: {mc_passes}\")\n",
    "print(f\"Generate Uncertainty Plots: {'Yes' if plot_uncertainties else 'No'}\")\n",
    "print(f\"Test Latest Models: {'Yes' if test_latest else 'No'}\")\n",
    "print(f\"Test Specific Version: {test_specific_version if test_specific_version else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Testing\n",
    "\n",
    "Execute testing on the trained models with the configured parameters. This will provide detailed performance metrics and uncertainty visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store all test results\n",
    "all_test_results = {}\n",
    "\n",
    "# Run tests for each model\n",
    "for time_window in test_time_windows:\n",
    "    if time_window not in all_test_results:\n",
    "        all_test_results[time_window] = {}\n",
    "        \n",
    "    for flare_class in test_flare_classes:\n",
    "        if flare_class not in supported_flare_class:\n",
    "            print(f\"Unsupported flare class: {flare_class}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nTesting model for {flare_class}-class flares with {time_window}h window\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        try:\n",
    "            # Find the model directory to test\n",
    "            model_dir = None\n",
    "            \n",
    "            if test_specific_version:\n",
    "                # Look for a specific version\n",
    "                model_patterns = [\n",
    "                    # New structure: models/models/SolarKnowledge-v*\n",
    "                    os.path.join(\"models\", \"models\", f\"SolarKnowledge-v{test_specific_version}-{flare_class}-{time_window}h\"),\n",
    "                    # Old structure: models/SolarKnowledge-v*\n",
    "                    os.path.join(\"models\", f\"SolarKnowledge-v{test_specific_version}-{flare_class}-{time_window}h\"),\n",
    "                ]\n",
    "                \n",
    "                for pattern in model_patterns:\n",
    "                    if os.path.exists(pattern):\n",
    "                        model_dir = pattern\n",
    "                        break\n",
    "                        \n",
    "                if not model_dir:\n",
    "                    print(f\"Could not find model with version {test_specific_version}\")\n",
    "                    continue\n",
    "                    \n",
    "            else:\n",
    "                # Find the latest model version\n",
    "                model_dir = find_latest_model_version(flare_class, time_window)\n",
    "                \n",
    "                if not model_dir:\n",
    "                    print(f\"Could not find a model for {flare_class}-class flares with {time_window}h window\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Testing model at: {model_dir}\")\n",
    "            \n",
    "            # Run the test\n",
    "            test_results = test_model(\n",
    "                time_window,\n",
    "                flare_class,\n",
    "                use_latest=True,\n",
    "                mc_passes=mc_passes,\n",
    "                plot_uncertainties=plot_uncertainties\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            if test_results is not None:\n",
    "                all_test_results[time_window][flare_class] = test_results\n",
    "                \n",
    "                # Print a summary of the results\n",
    "                print(\"\\nTest Results Summary:\")\n",
    "                print(f\"Accuracy: {test_results['accuracy']}\")\n",
    "                print(f\"TSS: {test_results['TSS']}\")\n",
    "                print(f\"Precision: {test_results['precision']}\")\n",
    "                print(f\"Recall: {test_results['recall']}\")\n",
    "                print(f\"Balanced Accuracy: {test_results['balanced_accuracy']}\")\n",
    "                \n",
    "                # Show uncertainty information if available\n",
    "                if 'mean_uncertainty' in test_results:\n",
    "                    print(f\"\\nUncertainty Metrics:\")\n",
    "                    print(f\"Mean Uncertainty: {test_results['mean_uncertainty']:.4f}\")\n",
    "                    print(f\"Mean Confidence: {test_results['mean_confidence']:.4f}\")\n",
    "                    print(f\"Mean Entropy: {test_results['mean_entropy']:.4f}\")\n",
    "                \n",
    "                # Print confusion matrix if available\n",
    "                if 'confusion_matrix' in test_results:\n",
    "                    print(\"\\nConfusion Matrix:\")\n",
    "                    cm = test_results['confusion_matrix']\n",
    "                    print(f\"[[{cm[0][0]}, {cm[0][1]}]\")\n",
    "                    print(f\" [{cm[1][0]}, {cm[1][1]}]]\")\n",
    "                    \n",
    "                    # Calculate and print additional metrics\n",
    "                    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "                    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                    print(f\"Sensitivity (TPR): {sensitivity:.4f}\")\n",
    "                    print(f\"Specificity (TNR): {specificity:.4f}\")\n",
    "                    print(f\"False Positive Rate: {1-specificity:.4f}\")\n",
    "                    print(f\"False Negative Rate: {1-sensitivity:.4f}\")\n",
    "                \n",
    "                # Show sample distribution\n",
    "                if all(k in test_results for k in [\"test_samples\", \"positive_samples\", \"negative_samples\"]):\n",
    "                    print(f\"\\nTest Data Distribution:\")\n",
    "                    pos = test_results[\"positive_samples\"]\n",
    "                    neg = test_results[\"negative_samples\"]\n",
    "                    total = test_results[\"test_samples\"]\n",
    "                    print(f\"Total samples: {total}\")\n",
    "                    print(f\"Positive samples: {pos} ({pos/total:.2%})\")\n",
    "                    print(f\"Negative samples: {neg} ({neg/total:.2%})\")\n",
    "            else:\n",
    "                print(\"No test results returned.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error testing model: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "        print(\"-\"*50)\n",
    "        \n",
    "# Save all test results to a JSON file\n",
    "results_filename = f\"pytorch_test_results_{datetime.now().strftime('%Y%m%d%H%M%S')}.json\"\n",
    "with open(results_filename, \"w\") as f:\n",
    "    json.dump(all_test_results, f, indent=4)\n",
    "    \n",
    "print(f\"\\nAll test results saved to {results_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Test Results\n",
    "\n",
    "Create visualizations to better understand model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZhFJREFUeJzt3XlYFXX///HXAQXcABcQTQQ1910UxQ01E8s0tdLUUtRM00wjK21RybvoLus29+zOpdJbs8wsTSuXcsHc8859QehbIm4sbiCc+f3hz3N3AvSghzmCz8d1nSvmM++Zec8Jp3o18xmLYRiGAAAAAAAAABO5uboBAAAAAAAA3H0IpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAKMQsFoueffZZV7chSWrXrp3atWvn6jZu2cSJE2WxWFzdhss4+/yDg4MVGRnptP252vz582WxWHTixIk7ep8AANxJCKUAAHACi8Xi0GfDhg2SpNOnT2vUqFGqVauWihUrJn9/f4WGhurll1/WhQsX7Pb9zTffKDw8XP7+/ipevLiqVq2qXr16afXq1S440+w2bNiQ6/k+/vjjrm7vpq5cuaJ//etfat68uXx8fOTl5aUaNWro2Wef1eHDh13dXoFxo9+Dv3/uNO+8844sFot2795tN24YhkqXLi2LxaK4uDi7dVeuXJGnp6f69u1rZqsAABQqRVzdAAAAhcGnn35qt/zJJ5/ohx9+yDZeu3ZtnTt3Tk2bNlVqaqoGDRqkWrVq6ezZs9q7d69mzZqlZ555RiVLlpQkTZ48WS+++KLCw8M1btw4FS9eXEePHtWPP/6oxYsXq3Pnzqad480899xzatasmd1YcHCwa5px0JkzZ9S5c2ft3LlTDz30kPr27auSJUvq0KFDWrx4sebMmaOMjAxXt1kg1K5dO9vv+7hx41SyZEm9+uqr2eoPHTokN7c74/+Ptm7dWpK0adMmNW7c2Da+b98+JScnq0iRItq8ebOqVKliW7d9+3ZlZGTYtn3yySf1+OOPy9PT09zmAQAowAilAABwgieeeMJueevWrfrhhx+yjUvSu+++q4SEBG3evFktW7a0W5eamioPDw9JUmZmpiZNmqT7779f33//fbb9JCUlOfEMbl+bNm306KOPmnKszMxMWa1W23d1qyIjI7V792598cUXeuSRR+zWTZo0KccwBTkrX758tt/3t99+W+XKlcvxz8GdFN40bdpUXl5e2rRpk0aOHGkb37x5s8qWLaumTZtq06ZNduexadMmSf8LtNzd3eXu7m5u4wAAFHB3xv+eAgDgLnLs2DG5u7urRYsW2dZ5e3vLy8tL0rW7eFJTU9WqVasc9+Pv7+/wMRcuXKiaNWvKy8tLISEh+vnnn23r1q9fL4vFoq+++irbdosWLZLFYlFsbKzDx3JURkaGxo8fr5CQEPn4+KhEiRJq06aN1q9fb1d34sQJWSwWTZ48WVOmTFG1atXk6emp/fv3S5IOHjyoRx99VGXKlJGXl5eaNm2qFStW3PT4v/zyi1auXKnBgwdnC6Ska6HJ5MmTb7iPefPmqUOHDvL395enp6fq1KmjWbNmZavbsWOHIiIiVK5cORUrVkxVqlTRoEGD7GoWL16skJAQlSpVSt7e3qpfv74++OCDm57H5MmT1bJlS5UtW1bFihVTSEiIvvjii2x11+cXW758uerVqydPT0/VrVs3x8dAN23apGbNmsnLy0vVqlXThx9+eNM+8urvc0pdnz9p06ZNeu655+Tn5ydfX18NHTpUGRkZSk5OVv/+/VW6dGmVLl1aL730kgzDsNun1WrVlClTVLduXXl5eal8+fIaOnSozp8/f8NePDw81KxZM23evNlufPPmzQoLC1OrVq1yXOfr66t69erZ9f/X+Z+Cg4P10EMPadOmTQoNDZWXl5eqVq2qTz75JFsP+/btU4cOHVSsWDFVqlRJ//jHP2S1WnPsd+bMmapbt648PT1VsWJFjRgxQsnJybb1U6dOlbu7u93Ye++9J4vFoqioKNtYVlaWSpUqpZdffvmG3w8AAPmFO6UAADBZUFCQsrKy9Omnn2rAgAG51vn7+6tYsWL65ptvNHLkSJUpU+aWjvfTTz9pyZIleu655+Tp6amZM2eqc+fO2rZtm+rVq6d27dopMDBQCxcuVI8ePey2XbhwoapVq6awsLCbHictLU1nzpyxGytTpkyuj2ilpqbq3//+t/r06aMhQ4YoLS1NH3/8sSIiIrRt2zY1atTIrn7evHm6cuWKnn76aXl6eqpMmTLat2+fWrVqpXvuuUdjx45ViRIl9Pnnn6t79+768ssvs53PX10Prp588smbnltuZs2apbp166pbt24qUqSIvvnmGw0fPlxWq1UjRoyQdO2Otk6dOsnPz09jx46Vr6+vTpw4oWXLltn288MPP6hPnz6677779M9//lOSdODAAW3evFmjRo26YQ8ffPCBunXrpn79+ikjI0OLFy/WY489pm+//VZdunSxq920aZOWLVum4cOHq1SpUpo6daoeeeQRJSQkqGzZspKk//73v7Z+J06cqMzMTE2YMEHly5e/5e8pL0aOHKmAgABFR0dr69atmjNnjnx9fbVlyxZVrlxZb731llatWqV3331X9erVU//+/W3bDh06VPPnz9fAgQP13HPPKS4uTtOnT9fu3bu1efNmFS1aNNfjtm7dWhs3btSJEydsj51u3rxZTz31lEJDQzVhwgQlJyfL19dXhmFoy5YtCgsLu+kjiEePHtWjjz6qwYMHa8CAAZo7d64iIyMVEhKiunXrSpISExPVvn17ZWZm2n6P58yZo2LFimXb38SJExUdHa2OHTvqmWee0aFDhzRr1ixt377ddo5t2rSR1WrVpk2b9NBDD0mSNm7cKDc3N23cuNG2r927d+vChQtq27atw39/AABwKgMAADjdiBEjjNz+MZuYmGj4+fkZkoxatWoZw4YNMxYtWmQkJydnqx0/frwhyShRooTxwAMPGG+++aaxc+dOh/uQZEgyduzYYRuLj483vLy8jB49etjGxo0bZ3h6etr1kJSUZBQpUsSYMGHCDY+xfv1623H+/omLi7PVhYeHG+Hh4bblzMxMIz093W5f58+fN8qXL28MGjTINhYXF2dIMry9vY2kpCS7+vvuu8+oX7++ceXKFduY1Wo1WrZsaVSvXv2Gfffo0cOQZJw/f/6GdddNmDAh29/TS5cuZauLiIgwqlatalv+6quvDEnG9u3bc933qFGjDG9vbyMzM9OhXm7UQ0ZGhlGvXj2jQ4cOduOSDA8PD+Po0aO2sV9//dWQZEybNs021r17d8PLy8uIj4+3je3fv99wd3fP9Xc6N3Xr1rX7e/5XQUFBxoABA2zL8+bNMyQZERERhtVqtY2HhYUZFovFGDZsmG0sMzPTqFSpkt2+N27caEgyFi5caHec1atX5zj+dytXrjQkGZ9++qlhGIZx8uRJQ5Lx008/GWlpaYa7u7uxcuVKwzAM47fffjMkGW+++Wa2/v/6Ox8UFGRIMn7++WfbWFJSkuHp6Wm88MILtrHRo0cbkoxffvnFrs7Hx8dun0lJSYaHh4fRqVMnIysry1Y7ffp0Q5Ixd+5cwzAMIysry/D29jZeeuklwzCu/ZkoW7as8dhjjxnu7u5GWlqaYRiG8f777xtubm4O/xkAAMDZeHwPAACTlS9fXr/++quGDRum8+fPa/bs2erbt6/8/f01adIku0eSoqOjtWjRIjVu3Fhr1qzRq6++qpCQEDVp0kQHDhxw6HhhYWEKCQmxLVeuXFkPP/yw1qxZo6ysLElS//79lZ6ebvfY15IlS5SZmZnjfEA5GT9+vH744Qe7T0BAQK717u7utjmhrFarzp07p8zMTDVt2lS7du3KVv/II4/Iz8/Ptnzu3DmtW7dOvXr1st2ldebMGZ09e1YRERE6cuSI/vjjj1yPn5qaKkkqVaqUQ+eXk7/eyZKSkqIzZ84oPDxcx48fV0pKiiTJ19dXkvTtt9/q6tWrOe7H19dXFy9e1A8//HBbPZw/f14pKSlq06ZNjt9hx44dVa1aNdtygwYN5O3trePHj0u69jjXmjVr1L17d1WuXNlWV7t2bUVEROS5t1sxePBguzf0NW/eXIZhaPDgwbYxd3d3NW3a1Na3JC1dulQ+Pj66//77bb8LZ86cUUhIiEqWLJntsdC/a9mypdzc3GxzRV2/66hZs2YqWbKkGjRoYHuE7/pfr88ndSN16tRRmzZtbMt+fn6qWbOmXe+rVq1SixYtFBoaalfXr18/u339+OOPysjI0OjRo+3u0BoyZIi8vb21cuVKSZKbm5tatmxpe0z3wIEDOnv2rMaOHSvDMGyP427cuFH16tWz/Y4CAGA2QikAAFygQoUKmjVrlk6ePKlDhw5p6tSp8vPz0/jx4/Xxxx/b1fbp00cbN27U+fPn9f3336tv377avXu3unbtqitXrtz0WNWrV882VqNGDV26dEmnT5+WJNWqVUvNmjXTwoULbTULFy5UixYtdO+99zp0TvXr11fHjh3tPtfnx8rNggUL1KBBA3l5eals2bLy8/PTypUrbYHOX/31zWfStceiDMPQ66+/Lj8/P7vPhAkTJN14Mnhvb29J1x47vFWbN29Wx44dVaJECfn6+srPz0+vvPKKJNnOITw8XI888oiio6NVrlw5Pfzww5o3b57S09Nt+xk+fLhq1KihBx54QJUqVdKgQYNynOspJ99++61atGghLy8vlSlTRn5+fpo1a1aO3+Ffg6brSpcubZtz6fTp07p8+XKOvzM1a9Z0qJ/b9fcefXx8JEmBgYHZxv86V9SRI0eUkpIif3//bL8PFy5cuOmLAXx9fVW3bl274Klx48a20K9ly5Z26zw8POxCJEfPR7L/ziUpPj7eoe88Pj4+x3EPDw9VrVrVtl669uKBnTt36vLly9q4caMqVKigJk2aqGHDhrZH+DZt2mQXmAEAYDbmlAIAwIUsFotq1KihGjVqqEuXLqpevboWLlyop556Klutt7e37r//ft1///0qWrSoFixYoF9++UXh4eFO6aV///4aNWqU/u///k/p6enaunWrpk+f7pR95+Szzz5TZGSkunfvrhdffFH+/v5yd3dXTEyMjh07lq3+7/PrXJ8EesyYMbnexXOjQK1WrVqSrs2hdCv/YX7s2DHdd999qlWrlt5//30FBgbKw8NDq1at0r/+9S9bfxaLRV988YW2bt2qb775RmvWrNGgQYP03nvvaevWrSpZsqT8/f21Z88erVmzRt99952+++47zZs3T/3799eCBQty7WHjxo3q1q2b2rZtq5kzZ6pChQoqWrSo5s2bp0WLFmWrz+3tcMbfJgx3pdx6zGn8r31brVb5+/vbBat/9de77HLTunVrzZ49W8nJydnejtmyZUvNnTtXV69e1aZNmxQSEnLT0DW3vv/ee35o3bq1rl69qtjYWG3cuNH2O96mTRtt3LhRBw8e1OnTpwmlAAAuRSgFAMAdomrVqipdurROnjx509qmTZtqwYIFDtUeOXIk29jhw4dVvHhxu/9Qf/zxxxUVFaX//Oc/unz5sooWLarevXvn7STy4IsvvlDVqlW1bNkyu8e1rt/ldDNVq1aVJBUtWlQdO3bM8/G7du2qmJgYffbZZ7f0H+bffPON0tPTtWLFCru7YXJ7TKxFixZq0aKF3nzzTS1atEj9+vXT4sWLbQGkh4eHunbtqq5du8pqtWr48OH68MMP9frrr+carn355Zfy8vLSmjVr5OnpaRufN29ens9HuhbcFCtWLMffmUOHDt3SPs1SrVo1/fjjj2rVqlWOE4Q7onXr1po1a5Z+/PFH7d69Wy+++KJtXcuWLXX58mWtXLlSx48fz/GNjbcqKCjIoe88KCjINn7991+69ibLuLg4uz8HoaGh8vDw0MaNG7Vx40bbubRt21YfffSR1q5da1sGAMBVeHwPAACT/fLLL7p48WK28W3btuns2bO2R3MuXbpkm/vl77777jtJjj1SFRsbaze/0O+//66vv/5anTp1sruLo1y5cnrggQf02WefaeHChercubPKlSuXp3PLi+vH/usdI7/88kuu5/x3/v7+ateunT788MMcw7nrjybmJiwsTJ07d9a///1vLV++PNv6jIwMjRkzJk/9p6SkZAuEzp8/n+2umOtvFrz+CN/Zs2ft1ru5ualBgwZ2Nbn1YLFYbHODSdKJEydyPB9HuLu7KyIiQsuXL1dCQoJt/MCBA1qzZs0t7dMsvXr1UlZWliZNmpRtXWZmppKTk2+6j+tzRL3//vu6evWq3Z1SwcHBqlChgt555x27Wmd48MEHtXXrVm3bts02dvr06Wx3fXXs2FEeHh6aOnWq3e/Uxx9/rJSUFLu3LXp5ealZs2b6z3/+o4SEBLs7pS5fvqypU6eqWrVqqlChgtPOAwCAvOJOKQAATPbpp59q4cKF6tGjh0JCQuTh4aEDBw5o7ty58vLyss1JdOnSJbVs2VItWrRQ586dFRgYqOTkZC1fvlwbN25U9+7d1bhx45ser169eoqIiNBzzz0nT09PzZw5U9K1SdT/rn///nr00UclKcf/uHemhx56SMuWLVOPHj3UpUsXxcXFafbs2apTp44uXLjg0D5mzJih1q1bq379+hoyZIiqVq2qU6dOKTY2Vv/3f/+nX3/99Ybbf/LJJ+rUqZN69uyprl276r777lOJEiV05MgRLV68WCdPntTkyZNz3LZTp062u5uGDh2qCxcu6KOPPpK/v79dSLZgwQLNnDlTPXr0ULVq1ZSWlqaPPvpI3t7eevDBByVJTz31lM6dO6cOHTqoUqVKio+P17Rp09SoUSPVrl071/67dOmi999/X507d1bfvn2VlJSkGTNm6N5779XevXsd+g7/Ljo6WqtXr1abNm00fPhwZWZmatq0aapbt+4t79MM4eHhGjp0qGJiYrRnzx516tRJRYsW1ZEjR7R06VJ98MEHtt/t3FSuXFmBgYGKjY1VcHCwKlasaLe+ZcuW+vLLL2WxWNSqVSun9f7SSy/p008/VefOnTVq1CiVKFFCc+bMUVBQkN137ufnp3Hjxik6OlqdO3dWt27ddOjQIc2cOVPNmjXL9lKCNm3a6O2335aPj4/q168v6VqYW7NmTR06dEiRkZFOOwcAAG4FoRQAACYbOnSoihcvrrVr1+rrr79Wamqq/Pz81KlTJ40bN84WNPn6+uqjjz7SypUrNW/ePCUmJsrd3V01a9bUu+++q+eee86h44WHhyssLEzR0dFKSEhQnTp1NH/+fNudOH/VtWtXlS5dWlarVd26dXPqef9dZGSkEhMT9eGHH2rNmjWqU6eOPvvsMy1dulQbNmxwaB916tTRjh07FB0drfnz5+vs2bPy9/dX48aNNX78+Jtu7+fnpy1btmjmzJlasmSJXn31VWVkZCgoKEjdunXTqFGjct22Zs2a+uKLL/Taa69pzJgxCggI0DPPPCM/Pz8NGjTIVhceHq5t27Zp8eLFOnXqlHx8fBQaGqqFCxfaJm9/4oknNGfOHM2cOVPJyckKCAhQ7969NXHiRLu3rP1dhw4d9PHHH+vtt9/W6NGjVaVKFf3zn//UiRMnbjlAatCggdasWaOoqCiNHz9elSpVUnR0tE6ePHlHh1KSNHv2bIWEhOjDDz/UK6+8oiJFiig4OFhPPPGEwyFS69at9Z///MfuLqnrWrVqpS+//FK1atVS2bJlndZ3hQoVtH79eo0cOVJvv/22ypYtq2HDhqlixYp2bx2UpIkTJ8rPz0/Tp0/X888/rzJlyujpp5/WW2+9paJFi9rVXg+lrr9Z8K/jhw4dYj4pAIDLWYw7aWZLAADgUpmZmapYsaK6du2a7S2AAAAAgDMxpxQAALBZvny5Tp8+rf79+7u6FQAAABRy3CkFAAD0yy+/aO/evZo0aZLKlStnNzE6AAAAkB+4UwoAAGjWrFl65pln5O/vr08++cTV7QAAAOAu4NJQ6ueff1bXrl1VsWJFWSwWh15fvGHDBjVp0kSenp669957NX/+/HzvEwCAwm7+/PnKzMzUjh07VK9ePVe3AwAAgLuAS0OpixcvqmHDhpoxY4ZD9XFxcerSpYvat2+vPXv2aPTo0Xrqqae0Zs2afO4UAAAAAAAAznTHzCllsVj01VdfqXv37rnWvPzyy1q5cqV+++0329jjjz+u5ORkrV692oQuAQAAAAAA4AxFXN1AXsTGxqpjx452YxERERo9enSu26Snpys9Pd22bLVade7cOZUtW1YWiyW/WgUAAAAAALgrGYahtLQ0VaxYUW5uuT+kV6BCqcTERJUvX95urHz58kpNTdXly5dVrFixbNvExMQoOjrarBYBAAAAAAAg6ffff1elSpVyXV+gQqlbMW7cOEVFRdmWU1JSVLlyZcXHx8vb29uFnQEAAAAAABQ+qampCgoKUqlSpW5YV6BCqYCAAJ06dcpu7NSpU/L29s7xLilJ8vT0lKenZ7ZxX19fQikAAAAAAAAnu/7I3s2mTXLp2/fyKiwsTGvXrrUb++GHHxQWFuaijgAAAAAAAHArXBpKXbhwQXv27NGePXskSXFxcdqzZ48SEhIkXXv0rn///rb6YcOG6fjx43rppZd08OBBzZw5U59//rmef/55V7QPAAAAAACAW+TSUGrHjh1q3LixGjduLEmKiopS48aNNX78eEnSyZMnbQGVJFWpUkUrV67UDz/8oIYNG+q9997Tv//9b0VERLikfwAAAAAAANwai2EYhqubMFNqaqp8fHyUkpLCnFIAAAAAANwlrFarMjIyXN1GoVC0aFG5u7vnut7R7KVATXQOAAAAAACQVxkZGYqLi5PVanV1K4WGr6+vAgICbjqZ+Y0QSgEAAAAAgELLMAydPHlS7u7uCgwMtL0ZDrfGMAxdunRJSUlJkqQKFSrc8r4IpQAAAAAAQKGVmZmpS5cuqWLFiipevLir2ykUihUrJklKSkqSv7//DR/luxHiQQAAAAAAUGhlZWVJkjw8PFzcSeFyPeC7evXqLe+DUAoAAAAAABR6tzP3EbJzxvdJKAUAAAAAAADTEUoBAAAAAADkoF27dho9erSr28jViRMnZLFYtGfPHle3cksIpQAAAAAAwF0pMjJSFosl2+fo0aOubk2SdPToUQ0cOFCVKlWSp6enqlSpoj59+mjHjh2ubs0pCKUAAAAAAMBdq3Pnzjp58qTdp0qVKk7Zt2EYyszMvKVtd+zYoZCQEB0+fFgffvih9u/fr6+++kq1atXSCy+84JT+XI1QCgAAAAAA3LU8PT0VEBBg93F3d8+x9tNPP1XTpk1VqlQpBQQEqG/fvkpKSrKt37BhgywWi7777juFhITI09NTmzZtktVqVUxMjKpUqaJixYqpYcOG+uKLL3LtyTAMRUZGqnr16tq4caO6dOmiatWqqVGjRpowYYK+/vrrHLfLysrS4MGDbcepWbOmPvjgA7uaDRs2KDQ0VCVKlJCvr69atWql+Ph4SdKvv/6q9u3bq1SpUvL29lZISEi+3pVVJN/2DAAAAAAAUIhcvXpVkyZNUs2aNZWUlKSoqChFRkZq1apVdnVjx47V5MmTVbVqVZUuXVoxMTH67LPPNHv2bFWvXl0///yznnjiCfn5+Sk8PDzbcfbs2aN9+/Zp0aJFcnPLfj+Rr69vjv1ZrVZVqlRJS5cuVdmyZbVlyxY9/fTTqlChgnr16qXMzEx1795dQ4YM0X/+8x9lZGRo27Zttjfp9evXT40bN9asWbPk7u6uPXv2qGjRorf/xeWCUAoAAAAAANy1vv32W5UsWdK2/MADD2jp0qU51g4aNMj2c9WqVTV16lQ1a9ZMFy5csNvHG2+8ofvvv1+SlJ6errfeeks//vijwsLCbNtu2rRJH374YY6h1JEjRyRJtWrVytO5FC1aVNHR0bblKlWqKDY2Vp9//rl69eql1NRUpaSk6KGHHlK1atUkSbVr17bVJyQk6MUXX7Qdt3r16nk6fl4RSgEAAAAAgLtW+/btNWvWLNtyiRIlcq3duXOnJk6cqF9//VXnz5+X1WqVdC3MqVOnjq2uadOmtp+PHj2qS5cu2UKq6zIyMtS4ceMcj2MYxi2diyTNmDFDc+fOVUJCgi5fvqyMjAw1atRIklSmTBlFRkYqIiJC999/vzp27KhevXqpQoUKkqSoqCg99dRT+vTTT9WxY0c99thjtvAqPzCnFAAAAAAAuGuVKFFC9957r+1zPaD5u4sXLyoiIkLe3t5auHChtm/frq+++krStYDp7/u87sKFC5KklStXas+ePbbP/v37c51XqkaNGpKkgwcP5ulcFi9erDFjxmjw4MH6/vvvtWfPHg0cONCuv3nz5ik2NlYtW7bUkiVLVKNGDW3dulWSNHHiRO3bt09dunTRunXrVKdOHds55gfulAIAAAAAALiJgwcP6uzZs3r77bcVGBgoSQ5NAl6nTh15enoqISEhx0f1ctKoUSPVqVNH7733nnr37p1tXqnk5OQc55XavHmzWrZsqeHDh9vGjh07lq2ucePGaty4scaNG6ewsDAtWrRILVq0kHQtEKtRo4aef/559enTR/PmzVOPHj0c6juvuFMKAAAAAADgJipXriwPDw9NmzZNx48f14oVKzRp0qSbbleqVCmNGTNGzz//vBYsWKBjx45p165dmjZtmhYsWJDjNhaLRfPmzdPhw4fVpk0brVq1SsePH9fevXv15ptv6uGHH85xu+rVq2vHjh1as2aNDh8+rNdff13bt2+3rY+Li9O4ceMUGxur+Ph4ff/99zpy5Ihq166ty5cv69lnn9WGDRsUHx+vzZs3a/v27XZzTjkbd0oBAAAAAADchJ+fn+bPn69XXnlFU6dOVZMmTTR58mR169btpttOmjRJfn5+iomJ0fHjx+Xr66smTZrolVdeyXWb0NBQ7dixQ2+++aaGDBmiM2fOqEKFCmrZsqWmTJmS4zZDhw7V7t271bt3b1ksFvXp00fDhw/Xd999J0kqXry4Dh48qAULFujs2bOqUKGCRowYoaFDhyozM1Nnz55V//79derUKZUrV049e/a0mzjd2SzG7cyeVQClpqbKx8dHKSkp8vb2dnU7AAAAAAAgH125ckVxcXGqUqWKvLy8XN1OoXGj79XR7IXH9wAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAADgbywWcz+3KjExUSNHjlTVqlXl6empwMBAde3aVWvXrnXel5FPiri6AQAAAAAAAOTdiRMn1KpVK/n6+urdd99V/fr1dfXqVa1Zs0YjRozQwYMHXd3iDRFKAQAAAAAAFEDDhw+XxWLRtm3bVKJECdt43bp1NWjQIBd25hge3wMAAAAAAChgzp07p9WrV2vEiBF2gdR1vr6+5jeVR4RSAAAAAAAABczRo0dlGIZq1arl6lZuGaEUAAAAAABAAWMYhqtbuG2EUgAAAAAAAAVM9erVZbFY7vjJzG+EUAoAAAAAAKCAKVOmjCIiIjRjxgxdvHgx2/rk5GTzm8ojQikAAAAAAIACaMaMGcrKylJoaKi+/PJLHTlyRAcOHNDUqVMVFhbm6vZuqoirGwAAAAAAAEDeVa1aVbt27dKbb76pF154QSdPnpSfn59CQkI0a9YsV7d3U4RSAAAAAAAAf1NQ5hGvUKGCpk+frunTp7u6lTzj8T0AAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApivi6gYAAAAAAADuNJZoi6nHMyYYeaqPjIzUggULNHToUM2ePdtu3YgRIzRz5kwNGDBA8+fPd2KXzsWdUgAAAAAAAAVQYGCgFi9erMuXL9vGrly5okWLFqly5cou7MwxhFIAAAAAAAAFUJMmTRQYGKhly5bZxpYtW6bKlSurcePGLuzMMYRSAAAAAAAABdSgQYM0b9482/LcuXM1cOBAF3bkOEIpAAAAAACAAuqJJ57Qpk2bFB8fr/j4eG3evFlPPPGEq9tyCBOdAwAAAAAAFFB+fn7q0qWL5s+fL8Mw1KVLF5UrV87VbTmEUAoAAAAAAKAAGzRokJ599llJ0owZM1zcjeMIpQAAAAAAAAqwzp07KyMjQxaLRREREa5ux2GEUgAAAAAAAAWYu7u7Dhw4YPu5oCCUAgAAAAAAKOC8vb1d3UKeEUoBAAAAAAD8jTHBcHULNzR//vwbrl++fLkpfdwON1c3AAAAAAAAgLsPoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAADwdxaLuZ88ioyMlMVi0bBhw7KtGzFihCwWiyIjIyVJEydOlMVisfvUqlXrdr+h20YoBQAAAAAAUAAFBgZq8eLFunz5sm3sypUrWrRokSpXrmxXW7duXZ08edL22bRpk9ntZkMoBQAAAAAAUAA1adJEgYGBWrZsmW1s2bJlqly5sho3bmxXW6RIEQUEBNg+5cqVM7vdbAilAAAAAAAACqhBgwZp3rx5tuW5c+dq4MCB2eqOHDmiihUrqmrVqurXr58SEhLMbDNHhFIAAAAAAAAF1BNPPKFNmzYpPj5e8fHx2rx5s5544gm7mubNm2v+/PlavXq1Zs2apbi4OLVp00ZpaWku6vqaIi49OgAAAAAAAG6Zn5+funTpovnz58swDHXp0iXbo3kPPPCA7ecGDRqoefPmCgoK0ueff67Bgweb3bINoRQAAAAAAEABNmjQID377LOSpBkzZty03tfXVzVq1NDRo0fzu7Ub4vE9AAAAAACAAqxz587KyMjQ1atXFRERcdP6Cxcu6NixY6pQoYIJ3eWOO6UAAAAAAAAKMHd3dx04cMD289+NGTNGXbt2VVBQkP78809NmDBB7u7u6tOnj9mt2iGUAgAAAAAAKOC8vb1zXfd///d/6tOnj86ePSs/Pz+1bt1aW7dulZ+fn4kdZkcoBQAAAAAA8HeG4eoObmj+/Pk3XL98+XLbz4sXL87fZm4Rc0oBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAIBCz7jDJy4vaJzxfRJKAQAAAACAQsvd3V2SlJGR4eJOCpdLly5JkooWLXrL+yjirGYAAAAAAADuNEWKFFHx4sV1+vRpFS1aVG5u3J9zOwzD0KVLl5SUlCRfX19b6HcrCKUAAAAAAEChZbFYVKFCBcXFxSk+Pt7V7RQavr6+CggIuK19EEoBAAAAAIBCzcPDQ9WrV+cRPicpWrTobd0hdZ3LQ6kZM2bo3XffVWJioho2bKhp06YpNDQ01/opU6Zo1qxZSkhIULly5fToo48qJiZGXl5eJnYNAAAAAAAKEjc3N7KDO4xLH6RcsmSJoqKiNGHCBO3atUsNGzZURESEkpKScqxftGiRxo4dqwkTJujAgQP6+OOPtWTJEr3yyismdw4AAAAAAIDb4dJQ6v3339eQIUM0cOBA1alTR7Nnz1bx4sU1d+7cHOu3bNmiVq1aqW/fvgoODlanTp3Up08fbdu2zeTOAQAAAAAAcDtc9vheRkaGdu7cqXHjxtnG3Nzc1LFjR8XGxua4TcuWLfXZZ59p27ZtCg0N1fHjx7Vq1So9+eSTuR4nPT1d6enptuXU1FRJktVqldVqddLZAAAAAAAAQJLDeYvLQqkzZ84oKytL5cuXtxsvX768Dh48mOM2ffv21ZkzZ9S6dWsZhqHMzEwNGzbsho/vxcTEKDo6Otv46dOndeXKlds7CQAAAAAAANhJS0tzqM7lE53nxYYNG/TWW29p5syZat68uY4ePapRo0Zp0qRJev3113PcZty4cYqKirItp6amKjAwUH5+fvL29jardQAAAAAAgLuCoxPKuyyUKleunNzd3XXq1Cm78VOnTikgICDHbV5//XU9+eSTeuqppyRJ9evX18WLF/X000/r1VdflZtb9imyPD095enpmW3czc0tx3oAAAAAAADcOkfzFpelMh4eHgoJCdHatWttY1arVWvXrlVYWFiO21y6dCnbibm7u0uSDMPIv2YBAAAAAADgVC59fC8qKkoDBgxQ06ZNFRoaqilTpujixYsaOHCgJKl///665557FBMTI0nq2rWr3n//fTVu3Nj2+N7rr7+url272sIpAAAAAAAA3PlcGkr17t1bp0+f1vjx45WYmKhGjRpp9erVtsnPExIS7O6Meu2112SxWPTaa6/pjz/+kJ+fn7p27ao333zTVacAAAAAAACAW2Ax7rLn3lJTU+Xj46OUlBQmOgcAAAAAAHAyR7MXZvoGAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYLoirm4AtychQTpzxtVdAAAAAACA21WunFS5squ7MA+hVAGWkCDVrCldueLqTgAAAAAAwO3y8pIOHbp7gike3yvAzpwhkAIAAAAAoLC4cuXuehqKUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYLoit7LR1atXlZiYqEuXLsnPz09lypRxdl8AAAAAAAAoxBy+UyotLU2zZs1SeHi4vL29FRwcrNq1a8vPz09BQUEaMmSItm/fnp+9AgAAAAAAoJBwKJR6//33FRwcrHnz5qljx45avny59uzZo8OHDys2NlYTJkxQZmamOnXqpM6dO+vIkSP53TcAAAAAAAAKMIce39u+fbt+/vln1a1bN8f1oaGhGjRokGbPnq158+Zp48aNql69ulMbBQAAAAAAQOHhUCj1n//8x6GdeXp6atiwYbfVEAAAAAAAAAq/2377Xnx8vPbv3y+r1eqMfgAAAAAAAHAXcDiUmjt3rt5//327saefflpVq1ZV/fr1Va9ePf3+++9ObxAAAAAAAACFj8Oh1Jw5c1S6dGnb8urVqzVv3jx98skn2r59u3x9fRUdHZ0vTQIAAAAAAKBwcWhOKUk6cuSImjZtalv++uuv9fDDD6tfv36SpLfeeksDBw50focAAAAAAAAodBy+U+ry5cvy9va2LW/ZskVt27a1LVetWlWJiYnO7Q4AAAAAAACFksOhVFBQkHbu3ClJOnPmjPbt26dWrVrZ1icmJsrHx8f5HQIAAAAAAKDQcfjxvQEDBmjEiBHat2+f1q1bp1q1aikkJMS2fsuWLapXr16+NAkAAAAAAIDCxeFQ6qWXXtKlS5e0bNkyBQQEaOnSpXbrN2/erD59+ji9QQAAAAAAABQ+FsMwDFc3YabU1FT5+PgoJSXFbo6sgmjXLukvN6sBAAAAAIACbudOqUkTV3dxexzNXhy+UyonV65c0ZIlS3Tx4kV16tRJ99577+3sDgAAAAAAAHcJh0OpqKgoXb16VdOmTZMkZWRkKCwsTPv27VPx4sX10ksv6YcfflBYWFi+NQsAAAAAAIDCweG3733//fe6//77bcsLFy5UfHy8jhw5ovPnz+uxxx7TP/7xj3xpEgAAAAAAAIWLw6FUQkKC6tSpY1v+/vvv9eijjyooKEgWi0WjRo3S7t2786VJAAAAAAAAFC4Oh1Jubm7665zoW7duVYsWLWzLvr6+On/+vHO7AwAAAAAAQKHkcChVu3ZtffPNN5Kkffv2KSEhQe3bt7etj4+PV/ny5Z3fIQAAAAAAAAodhyc6f+mll/T4449r5cqV2rdvnx588EFVqVLFtn7VqlUKDQ3NlyYBAAAAAABQuDh8p1SPHj20atUqNWjQQM8//7yWLFlit7548eIaPny40xsEAAAAAABA4ePwnVJvvPGGxowZo/vuuy/H9RMmTHBaUwAAAAAAACjcHL5TKjo6WhcuXMjPXgAAAAAAAHCXcDiU+uub9wAAAAAAAIDb4XAoJUkWiyW/+gAAAAAAAMBdJE+hVI0aNVSmTJkbfvJqxowZCg4OlpeXl5o3b65t27bdsD45OVkjRoxQhQoV5OnpqRo1amjVqlV5Pi4AAAAAAABcx+GJzqVr80r5+Pg47eBLlixRVFSUZs+erebNm2vKlCmKiIjQoUOH5O/vn60+IyND999/v/z9/fXFF1/onnvuUXx8vHx9fZ3WEwAAAAAAAPJfnkKpxx9/PMew6Fa9//77GjJkiAYOHChJmj17tlauXKm5c+dq7Nix2ernzp2rc+fOacuWLSpatKgkKTg42Gn9AAAAAAAAwBwOh1LOnk8qIyNDO3fu1Lhx42xjbm5u6tixo2JjY3PcZsWKFQoLC9OIESP09ddfy8/PT3379tXLL78sd3f3HLdJT09Xenq6bTk1NVWSZLVaZbVanXhG5jMMyS1PD2ACAAAAAIA7mWFIBTyucDhvcTiUcvbb986cOaOsrCyVL1/ebrx8+fI6ePBgjtscP35c69atU79+/bRq1SodPXpUw4cP19WrVzVhwoQct4mJiVF0dHS28dOnT+vKlSu3fyIudOWKFBLi6i4AAAAAAICzXLkiJSW5uovbk5aW5lCdw6HUnXBXkdVqlb+/v+bMmSN3d3eFhITojz/+0LvvvptrKDVu3DhFRUXZllNTUxUYGCg/Pz95e3ub1Xq++OMPaedOV3cBAAAAAACcxctLcuLMSS7h5eXlUJ1DodSwYcP02muvqVKlSjetXbJkiTIzM9WvX78b1pUrV07u7u46deqU3fipU6cUEBCQ4zYVKlRQ0aJF7R7Vq127thITE5WRkSEPD49s23h6esrT0zPbuJubm9wK+LNvFkvBv6UPAAAAAAD8j8VS8KfqcTRvcajKz89PdevW1YMPPqhZs2Zp+/bt+uOPP3T27FkdPXpUK1as0EsvvaTKlSvrX//6l+rXr3/TfXp4eCgkJERr1661jVmtVq1du1ZhYWE5btOqVSsdPXrU7q6tw4cPq0KFCjkGUgAAAAAAALgzORRKTZo0SYcPH1arVq00c+ZMtWjRQpUrV5a/v79q1qyp/v376/jx45ozZ462bt2qBg0aOHTwqKgoffTRR1qwYIEOHDigZ555RhcvXrS9ja9///52E6E/88wzOnfunEaNGqXDhw9r5cqVeuuttzRixIhbOHUAAAAAAAC4isNzSpUvX16vvvqqXn31VZ0/f14JCQm6fPmyypUrp2rVqt3S2/l69+6t06dPa/z48UpMTFSjRo20evVq2+TnCQkJdrd8BQYGas2aNXr++efVoEED3XPPPRo1apRefvnlPB8bAAAAAAAArmMxnP1avTtcamqqfHx8lJKSUuAnOt+1i7fvAQAAAABQmOzcKTVp4uoubo+j2UsBnzoLAAAAAAAABRGhFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdHkOpeLi4nTkyJFs40eOHNGJEyec0RMAAAAAAAAKuTyHUpGRkdqyZUu28V9++UWRkZHO6AkAAAAAAACFXJ5Dqd27d6tVq1bZxlu0aKE9e/Y4oycAAAAAAAAUcnkOpSwWi9LS0rKNp6SkKCsryylNAQAAAAAAoHDLcyjVtm1bxcTE2AVQWVlZiomJUevWrZ3aHAAAAAAAAAqnInnd4J///Kfatm2rmjVrqk2bNpKkjRs3KjU1VevWrXN6gwAAAAAAACh88nynVJ06dbR371716tVLSUlJSktLU//+/XXw4EHVq1cvP3oEAAAAAABAIZPnO6UkqWLFinrrrbec3QsAAAAAAADuEg6FUnv37lW9evXk5uamvXv33rC2QYMGTmkMAAAAAAAAhZdDoVSjRo2UmJgof39/NWrUSBaLRYZhZKuzWCy8gQ8AAAAAAAA35VAoFRcXJz8/P9vPAAAAAAAAwO1wKJQKCgqy/RwfH6+WLVuqSBH7TTMzM7Vlyxa7WgAAAAAAACAneX77Xvv27XXu3Lls4ykpKWrfvr1TmgIAAAAAAEDhludQyjAMWSyWbONnz55ViRIlnNIUAAAAAAAACjeHHt+TpJ49e0q6Npl5ZGSkPD09beuysrK0d+9etWzZ0vkdAgAAAAAAoNBxOJTy8fGRdO1OqVKlSqlYsWK2dR4eHmrRooWGDBni/A4BAAAAAABQ6DgcSs2bN0+SFBwcrDFjxvCoHgAAAAAAAG5ZnueUeumll+zmlIqPj9eUKVP0/fffO7UxAAAAAAAAFF55DqUefvhhffLJJ5Kk5ORkhYaG6r333tPDDz+sWbNmOb1BAAAAAAAAFD55DqV27dqlNm3aSJK++OILBQQEKD4+Xp988ommTp3q9AYBAAAAAABQ+OQ5lLp06ZJKlSolSfr+++/Vs2dPubm5qUWLFoqPj3d6gwAAAAAAACh88hxK3XvvvVq+fLl+//13rVmzRp06dZIkJSUlydvb2+kNAgAAAAAAoPDJcyg1fvx4jRkzRsHBwWrevLnCwsIkXbtrqnHjxk5vEAAAAAAAAIVPkbxu8Oijj6p169Y6efKkGjZsaBu/77771KNHD6c2BwAAAAAAgMIpz6GUJAUEBCggIMBuLDQ01CkNAQAAAAAAoPBzKJTq2bOn5s+fL29vb/Xs2fOGtcuWLXNKYwAAAAAAACi8HAqlfHx8ZLFYJEne3t62nwEAAAAAAIBb4VAoNW/ePNvP8+fPz69eAAAAAAAAcJfI89v3OnTooOTk5Gzjqamp6tChgzN6AgAAAAAAQCGX51Bqw4YNysjIyDZ+5coVbdy40SlNAQAAAAAAoHBz+O17e/futf28f/9+JSYm2pazsrK0evVq3XPPPc7tDgAAAAAAAIWSw6FUo0aNZLFYZLFYcnxMr1ixYpo2bZpTmwMAAAAAAEDh5HAoFRcXJ8MwVLVqVW3btk1+fn62dR4eHvL395e7u3u+NAkAAAAAAIDCxeFQKigoSJJktVrzrRkAAAAAAADcHRwOpf5u//79SkhIyDbpebdu3W67KQAAAAAAABRueQ6ljh8/rh49eui///2vLBaLDMOQJFksFknXJj0HAAAAAAAAbsQtrxuMGjVKVapUUVJSkooXL659+/bp559/VtOmTbVhw4Z8aBEAAAAAAACFTZ7vlIqNjdW6detUrlw5ubm5yc3NTa1bt1ZMTIyee+457d69Oz/6BAAAAAAAQCGS51AqKytLpUqVkiSVK1dOf/75p2rWrKmgoCAdOnTI6Q3ml8zMTGVmZmYbt1gsdm8RzKkmv2slqUiR//2tya02K0tyd5eysv5X6+6eJYvFyHW/mZl3Qq27pGuPe7q5ZcnNLT9qrXJzy31S/rzUZmW5yzDyo9ZNhuGW51qLxSp399xrrVY3Wa23UmvI3T33x29vtVYyVKSIs2otslrdnV5rGBZlZf3vz2eRIrn/+TSr1t09U///qegcav/+5z4vtVwjrtVyjch7LdeI67hGuLqWa8S1Wq4Rea/lGnGtlmvE7ddyjch7LdeI6/LyZ/lOziNyqs3KyrJN8XSz7WzbO1T1F/Xq1dOvv/6qKlWqqHnz5nrnnXfk4eGhOXPmqGrVqnndnct89dVXKl68eLbxChUqqF27drblZcuW5TpPlp+fnzp27GhbXrFihdLT03OsLVOmjCIiImzLK1eu1KVLl3Ks9fb2VpcuXWzLa9asUWpqara6lBSpS5fiWrHiYdtYx44/qkyZcznuNz3dU8uW9bQtt2u3Xv7+p3Oszcpy1+ef97Itt269URUrnsyxVpL+858+tp/DwmIVGPh7rrVLlz5m+wdLaOh2VakSl2vtsmU9lJ7uJUlq0mSXqlc/mmvtihXddPFiCUlSw4a/qlatg7nWrlr1oFJSfCRJdevuU716v+Vau2ZNJ507V1aSVLPmITVqtCfX2rVrOygpqbwkqVq1o2radGeutT/91FZ//nmPJCko6IRatPgl19rNm1spIaGyJCkw8P/UqtXmXGu3bm2uuLhrfxYrVDip8PCfc63dsSNER47UkCT5+SXpvvvW5Vq7Z08jHThQW5JUuvQ5RUR8n2vtb7/V03//W1+S5OOTqgcfXJVr7cGDtbR7d2NJUokSl9St24pca48cuVc7djSTJHl6pqtnz69yrY2Lq6KtW1tIkooUydJjjy3Ntfb33wO1aVNr2/KNav/8s4J++qmdbblnz2W5/kMzKclPa9f+7xrRrdsKeXrmfI04d66M1qz53zWiS5eVKlEi52tEaqq3Vq783zWic+c18vbOfo2QpIsXuUZcxzXiGq4R13CNuIZrxP9wjbiGa8Q1XCOu4RrxP1wjruEacY1Z14g7OY+QpOLFi+vhh/93jfjxxx917ty1a0Ru+/+7PIdSr732mi5evChJeuONN/TQQw+pTZs2Klu2rBYvXpzX3QEAAAAAAOAuZDGu31t1G86dO6fSpUvb3sB3J0tNTZWPj4/Onj0rb2/vbOsL0uN7u3dLYWHcUptzLbfU5r2WW2qv47Z7V9dyjbhWyzUi77VcI67Vco24/VquEXmv5RpxHdcIV9dyjbhWyzUi77V3zjVi506pSZM7O4/Iqfavj++lpqaqbNmySklJyTF7sfWW11Bq0KBB+uCDD2zzSl138eJFjRw5UnPnzs3L7kx3PZS62RdTEOzaJYWEuLoLAAAAAADgLNdDqYLM0ezFLdc1uViwYIEuX76cbfzy5cv65JNP8ro7AAAAAAAA3IUcnlMqNTVVhmHIMAylpaXJy8vLti4rK0urVq2Sv79/vjQJAAAAAACAwsXhUMrX11cWi0UWi0U1atTItt5isSg6OtqpzQEAAAAAAKBwcjiUWr9+vQzDUIcOHfTll1+qTJkytnUeHh4KCgpSxYoV86VJAAAAAAAAFC4Oh1Lh4eGSpLi4OFWuXLlAvGkPAAAAAAAAdyaHJzo/c+aM4uPjFRQUZAuk9u3bp4EDB6pXr15atGhRvjUJAAAAAACAwsXhUGrkyJGaOnWqbTkpKUlt2rTR9u3blZ6ersjISH366af50iQAAAAAAAAKF4dDqa1bt6pbt2625U8++URlypTRnj179PXXX+utt97SjBkz8qVJAAAAAAAAFC4Oh1KJiYkKDg62La9bt049e/ZUkSLXpqXq1q2bjhw54vQGAQAAAAAAUPg4HEp5e3srOTnZtrxt2zY1b97ctmyxWJSenu7U5gAAAAAAAFA4ORxKtWjRQlOnTpXVatUXX3yhtLQ0dejQwbb+8OHDCgwMzJcmAQAAAAAAULgUcbRw0qRJuu+++/TZZ58pMzNTr7zyikqXLm1bv3jxYoWHh+dLkwAAAAAAAChcHA6lGjRooAMHDmjz5s0KCAiwe3RPkh5//HHVqVPH6Q0CAAAAAACg8HE4lJKkcuXK6eGHH85xXZcuXZzSEAAAAAAAAAo/h+eUAgAAAAAAAJyFUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDqHJjpPTU11eIfe3t633AwAAAAAAADuDg6FUr6+vrJYLDesMQxDFotFWVlZTmkMAAAAAAAAhZdDodT69evzuw8AAAAAAADcRRwKpcLDw/O7DwAAAAAAANxFHAql9u7d6/AOGzRocMvNAAAAAAAA4O7gUCjVqFEjWSwWGYZxwzrmlAIAAAAAAIAjHAql4uLi8rsPAAAAAAAA3EUcCqWCgoLyuw8AAAAAAADcRRwKpVasWKEHHnhARYsW1YoVK25Y261bN6c0BgAAAAAAgMLLoVCqe/fuSkxMlL+/v7p3755rHXNKAQAAAAAAwBEOhVJWqzXHnwEAAAAAAIBb4ZbXDf7v//4v13Vbt269rWYAAAAAAABwd8hzKNWpUyedO3cu2/jmzZvVuXNnpzQFAAAAAACAwi3PoVSLFi3UqVMnpaWl2cZ+/vlnPfjgg5owYYJTmwMAAAAAAEDhlOdQ6t///rcqV66srl27Kj09XevXr1eXLl30xhtv6Pnnn8+PHgEAAAAAAFDI5DmUcnNz0+LFi1W0aFF16NBB3bp1U0xMjEaNGpUf/QEAAAAAAKAQcujte3v37s02NnHiRPXp00dPPPGE2rZta6tp0KCBczsEAAAAAABAoeNQKNWoUSNZLBYZhmEbu7784Ycfas6cOTIMQxaLRVlZWfnWLAAAAAAAAAoHh0KpuLi4/O4DAAAAAAAAdxGHQqmgoKD87gMAAAAAAAB3EYcnOj98+LC2bdtmN7Z27Vq1b99eoaGheuutt5zeHAAAAAAAAAonh0Opl19+Wd9++61tOS4uTl27dpWHh4fCwsIUExOjKVOm5EePAAAAAAAAKGQcenxPknbs2KGXXnrJtrxw4ULVqFFDa9askXTtrXvTpk3T6NGjnd4kAAAAAAAACheH75Q6c+aMKlWqZFtev369unbtaltu166dTpw44dTmAAAAAAAAUDg5HEqVKVNGJ0+elCRZrVbt2LFDLVq0sK3PyMiQYRi31MSMGTMUHBwsLy8vNW/ePNvcVblZvHixLBaLunfvfkvHBQAAAAAAgGs4HEq1a9dOkyZN0u+//64pU6bIarWqXbt2tvX79+9XcHBwnhtYsmSJoqKiNGHCBO3atUsNGzZURESEkpKSbrjdiRMnNGbMGLVp0ybPxwQAAAAAAIBrORxKvfnmmzp48KCCgoL08ssv65133lGJEiVs6z/99FN16NAhzw28//77GjJkiAYOHKg6depo9uzZKl68uObOnZvrNllZWerXr5+io6NVtWrVPB8TAAAAAAAAruXwROfBwcE6cOCA9u3bJz8/P1WsWNFufXR0tN2cU47IyMjQzp07NW7cONuYm5ubOnbsqNjY2Fy3e+ONN+Tv76/Bgwdr48aNeTomAAAAAAAAXM/hUEqSihQpooYNG+a4LrfxGzlz5oyysrJUvnx5u/Hy5cvr4MGDOW6zadMmffzxx9qzZ49Dx0hPT1d6erptOTU1VdK1ebGsVmuee76TGIbk5vC9bgAAAAAA4E5nGFIBjysczlvyFEq5Wlpamp588kl99NFHKleunEPbxMTEKDo6Otv46dOndeXKFWe3aKorV6SQEFd3AQAAAAAAnOXKFekm02zf8dLS0hyqc2koVa5cObm7u+vUqVN246dOnVJAQEC2+mPHjunEiRPq2rWrbex6+lakSBEdOnRI1apVs9tm3LhxioqKsi2npqYqMDBQfn5+8vb2dubpmO6PP6SdO13dBQAAAAAAcBYvL8nf39Vd3B4vLy+H6lwaSnl4eCgkJERr165V9+7dJV0LmdauXatnn302W32tWrX03//+127stddeU1pamj744AMFBgZm28bT01Oenp7Zxt3c3ORWwJ99s1gK/i19AAAAAADgfyyWgj9Vj6N5i8sf34uKitKAAQPUtGlThYaGasqUKbp48aIGDhwoSerfv7/uuecexcTEyMvLS/Xq1bPb3tfXV5KyjQMAAAAAAODOdUuh1MaNG/Xhhx/q2LFj+uKLL3TPPffo008/VZUqVdS6des87at37946ffq0xo8fr8TERDVq1EirV6+2TX6ekJBQ4O9oAgAAAAAAgL08h1JffvmlnnzySfXr10+7d++2vdkuJSVFb731llatWpXnJp599tkcH9eTpA0bNtxw2/nz5+f5eAAAAAAAAHCtPN+C9I9//EOzZ8/WRx99pKJFi9rGW7VqpV27djm1OQAAAAAAABROeQ6lDh06pLZt22Yb9/HxUXJysjN6AgAAAAAAQCGX51AqICBAR48ezTa+adMmVa1a1SlNAQAAAAAAoHDLcyg1ZMgQjRo1Sr/88ossFov+/PNPLVy4UGPGjNEzzzyTHz0CAAAAAACgkMnzROdjx46V1WrVfffdp0uXLqlt27by9PTUmDFjNHLkyPzoEQAAAAAAAIVMnkMpi8WiV199VS+++KKOHj2qCxcuqE6dOipZsmR+9AcAAAAAAIBCKM+h1HUeHh6qU6eOM3sBAAAAAADAXSLPoVT79u1lsVhyXb9u3brbaggAAAAAAACFX55DqUaNGtktX716VXv27NFvv/2mAQMGOKsvAAAAAAAAFGJ5DqX+9a9/5Tg+ceJEXbhw4bYbAgAAAAAAQOHn5qwdPfHEE5o7d66zdgcAAAAAAIBCzGmhVGxsrLy8vJy1OwAAAAAAABRieX58r2fPnnbLhmHo5MmT2rFjh15//XWnNQYAAAAAAIDCK8+hlI+Pj92ym5ubatasqTfeeEOdOnVyWmMAAAAAAAAovPIUSmVlZWngwIGqX7++SpcunV89AQAAAAAAoJDL05xS7u7u6tSpk5KTk/OpHQAAAAAAANwN8jzReb169XT8+PH86AUAAAAAAAB3iTyHUv/4xz80ZswYffvttzp58qRSU1PtPgAAAAAAAMDNODyn1BtvvKEXXnhBDz74oCSpW7duslgstvWGYchisSgrK8v5XQIAAAAAAKBQcTiUio6O1rBhw7R+/fr87AcAAAAAAAB3AYdDKcMwJEnh4eH51gwAAAAAAADuDnmaU+qvj+sBAAAAAAAAt8rhO6UkqUaNGjcNps6dO3dbDQEAAAAAAKDwy1MoFR0dLR8fn/zqBQAAAAAAAHeJPIVSjz/+uPz9/fOrFwAAAAAAANwlHJ5TivmkAAAAAAAA4CwOh1LX374HAAAAAAAA3C6HH9+zWq352QcAAAAAAADuIg7fKQUAAAAAAAA4C6EUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATHdHhFIzZsxQcHCwvLy81Lx5c23bti3X2o8++kht2rRR6dKlVbp0aXXs2PGG9QAAAAAAALjzuDyUWrJkiaKiojRhwgTt2rVLDRs2VEREhJKSknKs37Bhg/r06aP169crNjZWgYGB6tSpk/744w+TOwcAAAAAAMCtshiGYbiygebNm6tZs2aaPn26JMlqtSowMFAjR47U2LFjb7p9VlaWSpcurenTp6t///43rU9NTZWPj49SUlLk7e192/270q5dUkiIq7sAAAAAAADOsnOn1KSJq7u4PY5mLy69UyojI0M7d+5Ux44dbWNubm7q2LGjYmNjHdrHpUuXdPXqVZUpUya/2gQAAAAAAICTFXHlwc+cOaOsrCyVL1/ebrx8+fI6ePCgQ/t4+eWXVbFiRbtg66/S09OVnp5uW05NTZV07Y4sq9V6i53fGQxDcnP5A5gAAAAAAMBZDEMq4HGFw3mLS0Op2/X2229r8eLF2rBhg7y8vHKsiYmJUXR0dLbx06dP68qVK/ndYr66coXH9wAAAAAAKEyuXJFymWa7wEhLS3OozqWhVLly5eTu7q5Tp07ZjZ86dUoBAQE33Hby5Ml6++239eOPP6pBgwa51o0bN05RUVG25dTUVAUGBsrPz6/Azyn1xx/XnjUFAAAAAACFg5eX5O/v6i5uT243Dv2dS0MpDw8PhYSEaO3aterevbuka7d4rV27Vs8++2yu273zzjt68803tWbNGjVt2vSGx/D09JSnp2e2cTc3N7kV8GffLJaCf0sfAAAAAAD4H4ul4E/V42je4vLH96KiojRgwAA1bdpUoaGhmjJlii5evKiBAwdKkvr376977rlHMTExkqR//vOfGj9+vBYtWqTg4GAlJiZKkkqWLKmSJUu67DwAAAAAAADgOJeHUr1799bp06c1fvx4JSYmqlGjRlq9erVt8vOEhAS7hG3WrFnKyMjQo48+arefCRMmaOLEiWa2DgAAAAAAgFtkMQzDcHUTZkpNTZWPj49SUlIK/JxSu3Yx0TkAAAAAAIXJzp1Skyau7uL2OJq9FPCnFAEAAAAAAFAQEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdHdEKDVjxgwFBwfLy8tLzZs317Zt225Yv3TpUtWqVUteXl6qX7++Vq1aZVKnAAAAAAAAcAaXh1JLlixRVFSUJkyYoF27dqlhw4aKiIhQUlJSjvVbtmxRnz59NHjwYO3evVvdu3dX9+7d9dtvv5ncOQAAAAAAAG6VxTAMw5UNNG/eXM2aNdP06dMlSVarVYGBgRo5cqTGjh2brb537966ePGivv32W9tYixYt1KhRI82ePfumx0tNTZWPj49SUlLk7e3tvBNxgV27pJAQV3cBAAAAAACcZedOqUkTV3dxexzNXlx6p1RGRoZ27typjh072sbc3NzUsWNHxcbG5rhNbGysXb0kRURE5FoPAAAAAACAO08RVx78zJkzysrKUvny5e3Gy5cvr4MHD+a4TWJiYo71iYmJOdanp6crPT3dtpySkiJJSk5OltVqvZ32XS4tTbJYXN0FAAAAAABwlrQ0KTnZ1V3cntTUVEnSzR7Oc2koZYaYmBhFR0dnGw8KCnJBNwAAAAAAALlr187VHThPWlqafHx8cl3v0lCqXLlycnd316lTp+zGT506pYCAgBy3CQgIyFP9uHHjFBUVZVu2Wq06d+6cypYtKwu3GQEAgAIgNTVVgYGB+v333wv8nJgAAKDwMwxDaWlpqlix4g3rXBpKeXh4KCQkRGvXrlX37t0lXQuN1q5dq2effTbHbcLCwrR27VqNHj3aNvbDDz8oLCwsx3pPT095enrajfn6+jqjfQAAAFN5e3sTSgEAgALhRndIXefyx/eioqI0YMAANW3aVKGhoZoyZYouXryogQMHSpL69++ve+65RzExMZKkUaNGKTw8XO+99566dOmixYsXa8eOHZozZ44rTwMAAAAAAAB54PJQqnfv3jp9+rTGjx+vxMRENWrUSKtXr7ZNZp6QkCA3t/+9JLBly5ZatGiRXnvtNb3yyiuqXr26li9frnr16rnqFAAAAAAAAJBHFuNmU6EDAADApdLT0xUTE6Nx48Zlm5YAAACgoCKUAgAAAAAAgOncbl4CAAAAAAAAOBehFAAAAAAAAExHKAUAAFAIRUZGqnv37q5uAwAAIFeEUgAAAPkoMTFRI0eOVNWqVeXp6anAwEB17dpVa9euzbH+xIkTGjx4sKpUqaJixYqpWrVqmjBhgjIyMnKsP3r0qEqVKiVfX998PAsAAADnK+LqBgAAAAqrEydOqFWrVvL19dW7776r+vXr6+rVq1qzZo1GjBihgwcPZtvm4MGDslqt+vDDD3Xvvffqt99+05AhQ3Tx4kVNnjzZrvbq1avq06eP2rRpoy1btph1WgAAAE7B2/cAAADyyYMPPqi9e/fq0KFDKlGihN265ORkh+9uevfddzVr1iwdP37cbvzll1/Wn3/+qfvuu0+jR49WcnKybV1kZKSSk5PVunVrvffee8rIyNDjjz+uKVOmqGjRord7agAAALeNx/cAAADywblz57R69WqNGDEiWyAlKU+P26WkpKhMmTJ2Y+vWrdPSpUs1Y8aMXLdbv369jh07pvXr12vBggWaP3++5s+f7/BxAQAA8hOhFAAAQD44evSoDMNQrVq1bns/06ZN09ChQ21jZ8+eVWRkpObPny9vb+9cty1durSmT5+uWrVq6aGHHlKXLl1yncsKAADAbIRSAAAA+cCRGRKGDRumkiVL2j5/98cff6hz58567LHHNGTIENv4kCFD1LdvX7Vt2/aG+69bt67c3d1tyxUqVFBSUlIezgIAACD/EEoBAADkg+rVq8tiseQ4mfl1b7zxhvbs2WP7/NWff/6p9u3bq2XLlpozZ47dunXr1mny5MkqUqSIihQposGDByslJUVFihTR3LlzbXV/nzvKYrHIarXe/skBAAA4AW/fAwAAyAdlypRRRESEZsyYoeeeey7Hic79/f3l7++fbds//vhD7du3V0hIiObNmyc3N/v/jxgbG6usrCzb8tdff61//vOf2rJli+655578OSEAAAAnI5QCAADIJzNmzFCrVq0UGhqqN954Qw0aNFBmZqZ++OEHzZo1SwcOHMi2zR9//KF27dopKChIkydP1unTp23rAgICJEm1a9e222bHjh1yc3NTvXr18veEAAAAnIhQCgAAIJ9UrVpVu3bt0ptvvqkXXnhBJ0+elJ+fn0JCQjRr1qwct/nhhx909OhRHT16VJUqVbJb58g8VQAAAAWFxeDfbgAAAAAAAGAyJjoHAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAD5ql27dho9erSr28jViRMnZLFYtGfPHle3cssiIyPVvXt3V7fhsODgYE2ZMuW29rFhwwZZLBYlJyc7pScAAGA+QikAAHBbIiMjZbFYsn2OHj3q6tYkSUePHtXAgQNVqVIleXp6qkqVKurTp4927Njh6tYcktN3+9fPxIkT9cEHH2j+/Pmm9nXhwgUVLVpUixcvtht//PHHZbFYdOLECbvx4OBgvf7665Kk7du36+mnnzarVQAAcIcilAIAALetc+fOOnnypN2nSpUqTtm3YRjKzMy8pW137NihkJAQHT58WB9++KH279+vr776SrVq1dILL7zglP7y21+/0ylTpsjb29tubMyYMfLx8ZGvr6+pfZUsWVJNmzbVhg0b7MY3bNigwMBAu/G4uDjFx8erQ4cOkiQ/Pz8VL17cxG4BAMCdiFAKAADcNk9PTwUEBNh93N3dc6z99NNP1bRpU5UqVUoBAQHq27evkpKSbOuvP5b13XffKSQkRJ6entq0aZOsVqtiYmJUpUoVFStWTA0bNtQXX3yRa0+GYSgyMlLVq1fXxo0b1aVLF1WrVk2NGjXShAkT9PXXX+e4XVZWlgYPHmw7Ts2aNfXBBx/Y1WzYsEGhoaEqUaKEfH191apVK8XHx0uSfv31V7Vv316lSpWSt7e3QkJCbuuurL9+pz4+PrJYLHZjJUuWzPb4Xrt27TRy5EiNHj1apUuXVvny5fXRRx/p4sWLGjhwoEqVKqV7771X3333nd2xfvvtNz3wwAMqWbKkypcvryeffFJnzpzJtbf27dvbhU8HDhzQlStX9Mwzz9iNb9iwQZ6engoLC5OU/fE9i8Wif//73+rRo4eKFy+u6tWra8WKFXbHWrVqlWrUqKFixYqpffv22e7EkqQvv/xSdevWlaenp4KDg/Xee+/Z1k2fPl316tWzLS9fvlwWi0WzZ8+2jXXs2FGvvfZarucLAACci1AKAACY6urVq5o0aZJ+/fVXLV++XCdOnFBkZGS2urFjx+rtt9/WgQMH1KBBA8XExOiTTz7R7NmztW/fPj3//PN64okn9NNPP+V4nD179mjfvn164YUX5OaW/V95cruzyGq1qlKlSlq6dKn279+v8ePH65VXXtHnn38uScrMzFT37t0VHh6uvXv3KjY2Vk8//bQsFoskqV+/fqpUqZK2b9+unTt3auzYsSpatOitfVm3YcGCBSpXrpy2bdumkSNH6plnntFjjz2mli1bateuXerUqZOefPJJXbp0SZKUnJysDh06qHHjxtqxY4dWr16tU6dOqVevXrkeo3379jp06JBOnjwpSVq/fr1at26tDh062IVS69evV1hYmLy8vHLdV3R0tHr16qW9e/fqwQcfVL9+/XTu3DlJ0u+//66ePXuqa9eu2rNnj5566imNHTvWbvudO3eqV69eevzxx/Xf//5XEydO1Ouvv257rDE8PFz79+/X6dOnJUk//fSTypUrZ+vz6tWrio2NVbt27fLyNQMAgNthAAAA3IYBAwYY7u7uRokSJWyfRx991LY+PDzcGDVqVK7bb9++3ZBkpKWlGYZhGOvXrzckGcuXL7fVXLlyxShevLixZcsWu20HDx5s9OnTJ8f9LlmyxJBk7Nq164b9x8XFGZKM3bt351ozYsQI45FHHjEMwzDOnj1rSDI2bNiQY22pUqWM+fPn3/CYt2revHmGj49PtvEBAwYYDz/8sG05PDzcaN26tW05MzPTKFGihPHkk0/axk6ePGlIMmJjYw3DMIxJkyYZnTp1stvv77//bkgyDh06lGM/Fy9eNDw8PIxFixYZhmEYjz32mPHOO+8YV69eNUqUKGEcP37cMAzDqFy5shEdHW3bLigoyPjXv/5lW5ZkvPbaa7blCxcuGJKM7777zjAMwxg3bpxRp04du2O//PLLhiTj/PnzhmEYRt++fY3777/frubFF1+0bWe1Wo2yZcsaS5cuNQzDMBo1amTExMQYAQEBhmEYxqZNm4yiRYsaFy9ezPFcAQCA83GnFAAAuG3t27fXnj17bJ+pU6fmWrtz50517dpVlStXVqlSpRQeHi5JSkhIsKtr2rSp7eejR4/q0qVLuv/++1WyZEnb55NPPtGxY8dyPI5hGLd8PjNmzFBISIj8/PxUsmRJzZkzx9ZfmTJlFBkZqYiICHXt2lUffPCB7U4hSYqKitJTTz2ljh076u233861P0kaNmyY3fk4U4MGDWw/u7u7q2zZsqpfv75trHz58pJke3Ty119/1fr16+36qVWrliTleg7FixdXs2bNbHcb/fTTT2rXrp2KFCmili1basOGDTp+/LgSEhLUvn17h/stUaKEvL29bb0dOHBAzZs3t6u//ijgdQcOHFCrVq3sxlq1aqUjR44oKytLFotFbdu21YYNG5ScnKz9+/dr+PDhSk9P18GDB/XTTz+pWbNmzHUFAICJCKUAAMBtK1GihO69917bp0KFCjnWXbx4UREREfL29tbChQu1fft2ffXVV5KkjIyMbPu87sKFC5KklStX2oVf+/fvz3VeqRo1akiSDh48mKdzWbx4scaMGaPBgwfr+++/1549ezRw4EC7/ubNm6fY2Fi1bNlSS5YsUY0aNbR161ZJ0sSJE7Vv3z516dJF69atU506dWzn+HdvvPGG3fk4098fGbRYLHZj1x83tFqtkq59x9cfj/vr58iRI2rbtm2ux2nfvr3Wr1+vffv26fLly2rSpImka4/LrV+/XuvXr1fx4sWzhUqO9Hu9N2dp166dNmzYoI0bN6px48by9va2BVU//fSTLSAFAADmKOLqBgAAwN3j4MGDOnv2rN5++20FBgZKkkOTgNepU0eenp5KSEhwODho1KiR6tSpo/fee0+9e/fONq9UcnJyjvNKbd68WS1bttTw4cNtYzndKdS4cWM1btxY48aNU1hYmBYtWqQWLVpIuhaI1ahRQ88//7z69OmjefPmqUePHtn24e/vL39/f4fOJ781adJEX375pYKDg1WkiOP/iti+fXv94x//0KJFi9S6dWvbBPdt27bVnDlzZBiGWrVqJQ8Pj1vurXbt2tkmPr8eAv61ZvPmzXZjmzdvVo0aNWw9hYeHa/To0Vq6dKlt7qh27drpxx9/1ObNmwvMGxkBACgsuFMKAACYpnLlyvLw8NC0adN0/PhxrVixQpMmTbrpdqVKldKYMWP0/PPPa8GCBTp27Jh27dqladOmacGCBTluY7FYNG/ePB0+fFht2rTRqlWrdPz4ce3du1dvvvmmHn744Ry3q169unbs2KE1a9bo8OHDev3117V9+3bb+ri4OI0bN06xsbGKj4/X999/ryNHjqh27dq6fPmynn32WW3YsEHx8fHavHmztm/frtq1a9/aF2aiESNG6Ny5c+rTp4+2b9+uY8eOac2aNRo4cKCysrJy3a5ly5by9PTUtGnT7ALD0NBQJSUl6euvv77po3s3M2zYMB05ckQvvviiDh06pEWLFtkmML/uhRde0Nq1azVp0iQdPnxYCxYs0PTp0zVmzBhbTYMGDVS6dGktWrTILpRavny50tPTsz3+BwAA8hehFAAAMI2fn5/mz5+vpUuXqk6dOnr77bc1efJkh7adNGmSXn/9dcXExKh27drq3LmzVq5cqSpVquS6TWhoqHbs2KF7771XQ4YMUe3atdWtWzft27dPU6ZMyXGboUOHqmfPnurdu7eaN2+us2fP2t01Vbx4cR08eFCPPPKIatSooaefflojRozQ0KFD5e7urrNnz6p///6qUaOGevXqpQceeEDR0dF5+p5coWLFitq8ebOysrLUqVMn1a9fX6NHj5avr2+Oby+8zsvLSy1atFBaWprdm+s8PT1t47cbSlWuXFlffvmlli9froYNG2r27Nl666237GqaNGmizz//XIsXL1a9evU0fvx4vfHGG3ZvdrRYLGrTpo0sFotat24t6VpQ5e3traZNm9o9MgoAAPKfxbidWUABAAAAAACAW8CdUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHT/D/nlipXCQQu7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize TSS values across different flare classes and time windows\n",
    "if all_test_results:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Extract TSS values\n",
    "    x_labels = []\n",
    "    tss_values = []\n",
    "    colors = {'C': 'blue', 'M': 'green', 'M5': 'red'}\n",
    "    \n",
    "    for tw in sorted(all_test_results.keys()):\n",
    "        for fc in sorted(all_test_results[tw].keys()):\n",
    "            if 'TSS' in all_test_results[tw][fc]:\n",
    "                x_labels.append(f\"{fc}-{tw}h\")\n",
    "                tss_values.append(all_test_results[tw][fc]['TSS'])\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = plt.bar(x_labels, tss_values)\n",
    "    \n",
    "    # Color bars based on flare class\n",
    "    for i, label in enumerate(x_labels):\n",
    "        fc = label.split('-')[0]\n",
    "        if fc in colors:\n",
    "            bars[i].set_color(colors[fc])\n",
    "    \n",
    "    plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)\n",
    "    plt.title('TSS by Flare Class and Time Window')\n",
    "    plt.xlabel('Flare Class - Time Window')\n",
    "    plt.ylabel('True Skill Statistic (TSS)')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add a legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=color, label=fc) for fc, color in colors.items()]\n",
    "    plt.legend(handles=legend_elements, title='Flare Class')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a comparison of key metrics\n",
    "    metrics = ['accuracy', 'TSS', 'precision', 'recall', 'balanced_accuracy']\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot different metrics side by side for each model\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(len(metrics), 1, i+1)\n",
    "        \n",
    "        x_labels = []\n",
    "        values = []\n",
    "        \n",
    "        for tw in sorted(all_test_results.keys()):\n",
    "            for fc in sorted(all_test_results[tw].keys()):\n",
    "                if metric in all_test_results[tw][fc]:\n",
    "                    x_labels.append(f\"{fc}-{tw}h\")\n",
    "                    values.append(all_test_results[tw][fc][metric])\n",
    "        \n",
    "        # Create bar chart\n",
    "        bars = plt.bar(x_labels, values)\n",
    "        \n",
    "        # Color bars based on flare class\n",
    "        for j, label in enumerate(x_labels):\n",
    "            fc = label.split('-')[0]\n",
    "            if fc in colors:\n",
    "                bars[j].set_color(colors[fc])\n",
    "        \n",
    "        plt.title(f'{metric.replace(\"_\", \" \").title()}')\n",
    "        plt.ylim(0, 1.0)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Only show x-labels for the bottom subplot\n",
    "        if i == len(metrics)-1:\n",
    "            plt.xlabel('Flare Class - Time Window')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No test results available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results with TensorFlow Implementation\n",
    "\n",
    "If you have saved TensorFlow model results, you can load and compare them with the PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if TensorFlow results exist and compare\n",
    "tf_results_file = \"tensorflow_results.json\"  # Change this to your TensorFlow results file name\n",
    "\n",
    "if os.path.exists(tf_results_file):\n",
    "    try:\n",
    "        # Load TensorFlow results\n",
    "        with open(tf_results_file, 'r') as f:\n",
    "            tf_results = json.load(f)\n",
    "        \n",
    "        # Prepare for comparison\n",
    "        comparison_metrics = ['TSS', 'accuracy', 'precision', 'recall']\n",
    "        frameworks = ['TensorFlow', 'PyTorch']\n",
    "        \n",
    "        # For each time window and flare class, collect and compare metrics\n",
    "        for tw in sorted(all_test_results.keys()):\n",
    "            if tw in tf_results:\n",
    "                print(f\"\\nComparison for {tw}h Time Window:\")\n",
    "                print(\"-\"*50)\n",
    "                \n",
    "                # Print header row\n",
    "                header = \"Flare Class | Metric | \" + \" | \".join(frameworks)\n",
    "                print(header)\n",
    "                print(\"-\" * len(header))\n",
    "                \n",
    "                for fc in sorted(all_test_results[tw].keys()):\n",
    "                    if fc in tf_results[tw]:\n",
    "                        for metric in comparison_metrics:\n",
    "                            if metric in tf_results[tw][fc] and metric in all_test_results[tw][fc]:\n",
    "                                # Format values for printing\n",
    "                                tf_val = tf_results[tw][fc][metric]\n",
    "                                pt_val = all_test_results[tw][fc][metric]\n",
    "                                \n",
    "                                # Calculate difference\n",
    "                                if isinstance(tf_val, (int, float)) and isinstance(pt_val, (int, float)):\n",
    "                                    diff = pt_val - tf_val\n",
    "                                    diff_str = f\"{diff:+.4f}\"\n",
    "                                else:\n",
    "                                    diff_str = \"N/A\"\n",
    "                                \n",
    "                                # Print comparison row\n",
    "                                print(f\"{fc:^10} | {metric:^12} | {tf_val:^10} | {pt_val:^10} | {diff_str:^10}\")\n",
    "                        \n",
    "                        # Add a separator between flare classes\n",
    "                        print(\"-\" * len(header))\n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing results: {e}\")\n",
    "else:\n",
    "    print(f\"TensorFlow results file '{tf_results_file}' not found. Skipping comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models (Optional)\n",
    "\n",
    "Run this cell if you want to compare different model versions after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models if requested and if models were trained\n",
    "if compare_models and trained_models:\n",
    "    print(\"\\nComparing trained models...\")\n",
    "    try:\n",
    "        from models.model_tracking import compare_models as compare_models_function\n",
    "        comparison = compare_models_function(\n",
    "            list(set(versions)),  # Unique versions\n",
    "            flare_classes,\n",
    "            time_windows\n",
    "        )\n",
    "        print(\"\\nModel Comparison:\")\n",
    "        print(comparison)\n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing models: {e}\")\n",
    "else:\n",
    "    if not compare_models:\n",
    "        print(\"Model comparison skipped (set compare_models = True to enable)\")\n",
    "    elif not trained_models:\n",
    "        print(\"No models were trained to compare\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EVEREST Environment",
   "language": "python",
   "name": "everest_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
