%--------------------------------------------------------------------
\subsection{From \textit{SolarKnowledge} to \textsc{EVEREST}}
\label{sec:sk2ev-transition}
%--------------------------------------------------------------------
Although the \textit{SolarKnowledge} prototype achieved strong classification performance on M5-72h tasks (accuracy: 99.96\%, TSS: 0.932), two architectural limitations motivated the transition to \textsc{EVEREST}.

\textbf{(i) Lack of uncertainty quantification.}
The \textit{SolarKnowledge} transformer provides point predictions without calibration assessment or uncertainty estimates. For operational space weather forecasting, understanding prediction confidence is as critical as prediction accuracy itself, yet no reliability measurement was available from the baseline architecture.

\textbf{(ii) Parameter inefficiency.}
With 1.999M parameters, the \textit{SolarKnowledge} architecture achieved excellent performance but at considerable computational cost. For deployment in operational forecasting systems with latency constraints, a more efficient architecture was needed.

These observations motivated the final design cycle, in which uncertainty quantification was elevated to a \emph{first-class architectural feature} rather than a post-hoc consideration.

\paragraph{Temporal focusing through a learnable bottleneck.}
In \textsc{EVEREST}, global-average pooling is replaced by a single-query attention kernel that assigns an importance weight $\alpha_t\!\in\![0,1]$ to every ten-minute snapshot in the SHARP sequence. The resulting summary $z=\sum_{t}\alpha_{t}h_{t}$ adds merely $+d=128$ parameters while enabling focused temporal modeling crucial for flare prediction.

\paragraph{Bayesian calibration via evidential deep-learning.}
To address the uncertainty quantification deficit, a Normal–Inverse–Gamma head predicts four natural parameters $\{\mu,v,\alpha,\beta\}$, from which a conjugate Beta distribution over forecast probabilities is recovered in closed form \citep{sensoy2018evidential}. Under the evidential negative-log-likelihood, highly uncertain samples yield small gradients, letting the optimiser concentrate on unambiguous cases. This enables principled uncertainty quantification with an Expected Calibration Error (ECE) of \textbf{0.036} on the M5–72h task, providing operationally relevant confidence estimates that were unavailable in the baseline architecture.

\paragraph{Extreme-risk awareness through an EVT tail.}
Solar eruptions follow heavy-tailed distributions that sub-Gaussian losses struggle to model. \textsc{EVEREST} introduces an Extreme Value Theory (EVT) head that fits a Generalised Pareto Distribution (GPD) to logit exceedances above the batchwise 90$^{\mathrm{th}}$ percentile \citep{coles2001extremes}. The estimated shape parameter $\xi$ serves as an explicit indicator of flare severity and allows the model to anticipate rare, high-magnitude events through principled extreme value modeling.

\paragraph{A composite loss for stable joint training.}
The focal, evidential and EVT objectives are combined as
\[
  \mathcal{L}=0.8\,\mathcal{L}_{\text{focal}}
             +0.1\,\mathcal{L}_{\text{evid}}
             +0.1\,\mathcal{L}_{\text{evt}}
             +0.05\,\mathcal{L}_{\text{prec}},
\]
with the focusing parameter linearly annealed $\gamma:0\!\to\!2$ during the first 50 epochs. Gradual annealing postpones loss-surface hardening until the uncertainty heads have stabilised, following \citet{lin2017focal}.

\paragraph{Implementation efficiency.}
A full rewrite in PyTorch 2.2 leverages automatic mixed precision and cuDNN autotuning, yielding an epoch time of \textbf{24 s $\pm$ 0.4 s} on an Imperial RCS RTX A6000 while keeping inference within the Met Office's 40 s latency budget. Critically, the parameter count drops to \textbf{0.814M} (59.3\% reduction from \textit{SolarKnowledge}), confirming that the new capabilities arise from \emph{architectural innovation} rather than \emph{scale}.

%----------------------------------------------------------
% Honest comparison table
%----------------------------------------------------------
\begin{table}[htbp]
  \centering
  \caption{Architectural comparison: \textit{SolarKnowledge} vs \textsc{EVEREST} on M5-72h task using documented model performance.}
  \label{tab:honest_comparison}
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}{@{}lcc@{}}
    \toprule
    \textbf{Metric} & \textbf{SolarKnowledge v1.0} & \textbf{EVEREST} \\
    \midrule
    Accuracy & 99.96\% & 99.85\% \\
    Precision & 82.91\% & -- \\
    Recall & 93.27\% & -- \\
    TSS & 0.932 & -- \\
    \midrule
    Parameters & 1.999M & 0.814M (-59.3\%) \\
    Calibration (ECE) & \emph{Not measured} & \textbf{0.036} \\
    Uncertainty Quantification & \emph{None} & \textbf{Evidential + EVT} \\
    Architecture & Standard transformer & + Attention bottleneck \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Architectural trade-offs and benefits.}
The transition from \textit{SolarKnowledge} to \textsc{EVEREST} represents a deliberate architectural trade-off: a marginal accuracy reduction (0.11\%) in exchange for three critical operational capabilities: (i) principled uncertainty quantification through evidential learning, (ii) extreme value modeling for rare solar events, and (iii) 59.3\% parameter efficiency improvement. For operational space weather forecasting, where understanding prediction confidence is essential for decision-making, these architectural innovations provide substantial value beyond raw classification performance.

The resulting \textsc{EVEREST} architecture delivers a calibrated, uncertainty-aware transformer suitable for operational deployment, completing the evolution from a high-accuracy but confidence-blind classifier to a fully uncertainty-quantified forecasting system ready for real-world space weather applications. 